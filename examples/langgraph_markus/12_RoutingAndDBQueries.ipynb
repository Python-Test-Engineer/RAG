{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mrcra\\AppData\\Local\\Temp\\ipykernel_11536\\1613623006.py:18: LangChainPendingDeprecationWarning: Please use JSONB instead of JSON for metadata. This change will allow for more efficient querying that involves filtering based on metadata. Please note that filtering operators have been changed when using JSONB metadata to be prefixed with a $ sign to avoid name collisions with columns. If you're using an existing database, you will need to create a db migration for your metadata column to be JSONB and update your queries to use the new operators. \n",
      "  store = PGVector(\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores.pgvector import PGVector\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_community.document_loaders.text import TextLoader\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import os\n",
    "\n",
    "\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "\n",
    "DATABASE_URL = \"postgresql+psycopg2://postgres:postgres@localhost:5432/postgres\"\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "store = PGVector(\n",
    "    collection_name=\"vectordb\",\n",
    "    connection_string=DATABASE_URL,\n",
    "    embedding_function=embeddings,\n",
    ")\n",
    "loader1 = TextLoader(\"./restaurant.txt\")\n",
    "loader2 = TextLoader(\"./founder.txt\")\n",
    "\n",
    "docs2 = loader1.load()\n",
    "docs1 = loader2.load()\n",
    "docs = docs1 + docs2\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=250, chunk_overlap=20)\n",
    "chunks = splitter.split_documents(docs)\n",
    "store.add_documents(chunks)\n",
    "retriever = store.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "model = ChatOpenAI()\n",
    "\n",
    "rag_chain = (\n",
    "    {\n",
    "        \"context\": itemgetter(\"question\") | retriever,\n",
    "        \"question\": itemgetter(\"question\"),\n",
    "    }\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Chef Amico is the owner of the restaurant.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke({\"question\": \"Who is the owner of the restaurant?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_community.utilities.sql_database import SQLDatabase\n",
    "\n",
    "template = \"\"\"Based on the table schema below, write a SQL query that would answer the user's question:\n",
    "{schema}\n",
    "\n",
    "Question: {question}\n",
    "SQL Query:\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "\n",
    "CONNECTION_STRING = \"postgresql+psycopg2://postgres:postgres@localhost:5432/postgres\"\n",
    "\n",
    "db = SQLDatabase.from_uri(CONNECTION_STRING)\n",
    "\n",
    "\n",
    "def get_schema(_):\n",
    "    schema = db.get_table_info()\n",
    "    return schema\n",
    "\n",
    "\n",
    "def run_query(query):\n",
    "    return db.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CREATE TABLE contacts (\n",
      "\tcontact_id UUID DEFAULT gen_random_uuid() NOT NULL, \n",
      "\tfirst_name VARCHAR NOT NULL, \n",
      "\tlast_name VARCHAR NOT NULL, \n",
      "\tCONSTRAINT contacts_pkey PRIMARY KEY (contact_id)\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from contacts table:\n",
      "contact_id\tfirst_name\tlast_name\n",
      "d07b7dc4-5d6a-49da-8e6a-b3c46a82e55d\tCraig\tWest\n",
      "*/\n",
      "\n",
      "\n",
      "CREATE TABLE docstore (\n",
      "\tkey VARCHAR NOT NULL, \n",
      "\tvalue JSONB, \n",
      "\tCONSTRAINT docstore_pkey PRIMARY KEY (key)\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from docstore table:\n",
      "key\tvalue\n",
      "\n",
      "*/\n",
      "\n",
      "\n",
      "CREATE TABLE document_data (\n",
      "\tdoc_id UUID NOT NULL, \n",
      "\tcontent TEXT NOT NULL, \n",
      "\tembeddings REAL[], \n",
      "\tadded TIMESTAMP WITHOUT TIME ZONE DEFAULT CURRENT_TIMESTAMP, \n",
      "\tCONSTRAINT document_data_pkey PRIMARY KEY (doc_id)\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from document_data table:\n",
      "doc_id\tcontent\tembeddings\tadded\n",
      "c3065f25-34bd-433d-b6d3-71e5f7603e42\tHere is a lot of text that we will embed\t[0.023209529, 0.023142641, 0.031168992, 0.016092831, -0.019182976, 0.026192656, 0.0064378013, -0.031\t2024-11-18 22:52:55.264561\n",
      "*/\n",
      "\n",
      "\n",
      "CREATE TABLE documents (\n",
      "\tdoc_id UUID DEFAULT gen_random_uuid() NOT NULL, \n",
      "\tfilename VARCHAR NOT NULL, \n",
      "\tadded TIMESTAMP WITHOUT TIME ZONE DEFAULT CURRENT_TIMESTAMP, \n",
      "\tis_active BOOLEAN DEFAULT true NOT NULL, \n",
      "\tCONSTRAINT documents_pkey PRIMARY KEY (doc_id)\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from documents table:\n",
      "doc_id\tfilename\tadded\tis_active\n",
      "c3065f25-34bd-433d-b6d3-71e5f7603e42\tnew_file.pdf\t2024-11-18 22:40:51.160107\tTrue\n",
      "*/\n",
      "\n",
      "\n",
      "CREATE TABLE embeddings_table (\n",
      "\tid SERIAL NOT NULL, \n",
      "\ttrack VARCHAR(255), \n",
      "\tembeddings REAL[], \n",
      "\tCONSTRAINT embeddings_table_pkey PRIMARY KEY (id)\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from embeddings_table table:\n",
      "id\ttrack\tembeddings\n",
      "1\tMay 5, 2023\t[0.023209529, 0.023142641, 0.031168992, 0.016092831, -0.019182976, 0.026192656, 0.0064378013, -0.031\n",
      "2\tTo Whom it May Concern:\t[0.055838846, -0.021927774, 0.013120603, 0.0861577, -0.005887628, -0.037947115, -0.046684936, 0.0382\n",
      "3\tThere were 20,000 bottles of water, 10,000 blankets, and 200 laptops delivered on January 23, 2023. \t[-0.00045886813, -0.0068087936, -0.008185398, 0.0072811577, -0.0027363386, -0.06461943, 0.011896831,\n",
      "*/\n",
      "\n",
      "\n",
      "CREATE TABLE employees (\n",
      "\tid SERIAL NOT NULL, \n",
      "\tname VARCHAR(100), \n",
      "\tposition VARCHAR(50), \n",
      "\tsalary NUMERIC, \n",
      "\tCONSTRAINT employees_pkey PRIMARY KEY (id)\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from employees table:\n",
      "id\tname\tposition\tsalary\n",
      "1\tJohn Doe\tSoftware Engineer\t60000\n",
      "2\tJane Smith\tProject Manager\t75000\n",
      "3\tEmily Johnson\tDesigner\t50000\n",
      "*/\n",
      "\n",
      "\n",
      "CREATE TABLE langchain_pg_collection (\n",
      "\tname VARCHAR, \n",
      "\tcmetadata JSON, \n",
      "\tuuid UUID NOT NULL, \n",
      "\tCONSTRAINT langchain_pg_collection_pkey PRIMARY KEY (uuid)\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from langchain_pg_collection table:\n",
      "name\tcmetadata\tuuid\n",
      "vectordb\tNone\tfca18967-f8b7-4720-83df-2027acf3b256\n",
      "*/\n",
      "\n",
      "\n",
      "CREATE TABLE langchain_pg_embedding (\n",
      "\tcollection_id UUID, \n",
      "\tembedding VECTOR, \n",
      "\tdocument VARCHAR, \n",
      "\tcmetadata JSON, \n",
      "\tcustom_id VARCHAR, \n",
      "\tuuid UUID NOT NULL, \n",
      "\tCONSTRAINT langchain_pg_embedding_pkey PRIMARY KEY (uuid), \n",
      "\tCONSTRAINT langchain_pg_embedding_collection_id_fkey FOREIGN KEY(collection_id) REFERENCES langchain_pg_collection (uuid) ON DELETE CASCADE\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from langchain_pg_embedding table:\n",
      "collection_id\tembedding\tdocument\tcmetadata\tcustom_id\tuuid\n",
      "fca18967-f8b7-4720-83df-2027acf3b256\t[ 0.00155501 -0.01281426  0.01164575 ... -0.00536335 -0.01794785\n",
      " -0.02891087]\tIn the heart of the old quarter of Palermo, amidst the bustling market stalls and the echoes of live\t{'source': './founder.txt'}\t4f463563-1bda-4599-aae9-438e2a971a32\t5642eafc-275f-4be8-879a-eeeb03b3ba2e\n",
      "fca18967-f8b7-4720-83df-2027acf3b256\t[ 0.01160052 -0.01364649  0.02544759 ... -0.00664606 -0.01555205\n",
      " -0.02150274]\twarmth of his Nonna Lucia's kitchen, young Amico was captivated by the symphony of flavors and aroma\t{'source': './founder.txt'}\tec32c420-eec4-4367-88ce-dfe7324858d1\t04abbc4b-9705-4903-a78b-2cfbf9f25d77\n",
      "fca18967-f8b7-4720-83df-2027acf3b256\t[ 0.01009242 -0.02428425  0.01894959 ... -0.01768719 -0.01965545\n",
      " -0.0268905 ]\tAmico's life was deeply entwined with the vibrant essence of Sicilian cuisine. In the rustic kitchen\t{'source': './founder.txt'}\t5c74fff3-8b33-4f44-b728-a69b6d8fe362\t36367e90-9df1-4ead-829b-4950805c6662\n",
      "*/\n",
      "\n",
      "\n",
      "CREATE TABLE products (\n",
      "\tid INTEGER NOT NULL, \n",
      "\tproduct_name VARCHAR(50), \n",
      "\tprice NUMERIC, \n",
      "\tCONSTRAINT products_pkey PRIMARY KEY (id)\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from products table:\n",
      "id\tproduct_name\tprice\n",
      "\n",
      "*/\n",
      "\n",
      "\n",
      "CREATE TABLE publisher (\n",
      "\tpublisher_id SERIAL NOT NULL, \n",
      "\tpublisher_name VARCHAR(255) NOT NULL, \n",
      "\tpublisher_estd INTEGER, \n",
      "\tpublsiher_location VARCHAR(255), \n",
      "\tpublsiher_type VARCHAR(255), \n",
      "\tCONSTRAINT publisher_pkey PRIMARY KEY (publisher_id)\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from publisher table:\n",
      "publisher_id\tpublisher_name\tpublisher_estd\tpublsiher_location\tpublsiher_type\n",
      "1\tPackt\t1950\tchennai\tbooks\n",
      "2\tSpringer\t1950\tchennai\tbooks\n",
      "3\tSpringer\t1950\tchennai\tarticles\n",
      "*/\n"
     ]
    }
   ],
   "source": [
    "print(get_schema(\"_\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, inspect\n",
    "from tabulate import tabulate\n",
    "\n",
    "\n",
    "def get_schema(_):\n",
    "    engine = create_engine(CONNECTION_STRING)\n",
    "\n",
    "    inspector = inspect(engine)\n",
    "    columns = inspector.get_columns(\"employees\")\n",
    "\n",
    "    column_data = [\n",
    "        {\n",
    "            \"Column Name\": col[\"name\"],\n",
    "            \"Data Type\": str(col[\"type\"]),\n",
    "            \"Nullable\": \"Yes\" if col[\"nullable\"] else \"No\",\n",
    "            \"Default\": col[\"default\"] if col[\"default\"] else \"None\",\n",
    "            \"Autoincrement\": \"Yes\" if col[\"autoincrement\"] else \"No\",\n",
    "        }\n",
    "        for col in columns\n",
    "    ]\n",
    "    schema_output = tabulate(column_data, headers=\"keys\", tablefmt=\"grid\")\n",
    "    formatted_schema = f\"Schema for 'employees' table:\\n{schema_output}\"\n",
    "\n",
    "    return formatted_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema for 'employees' table:\n",
      "+---------------+--------------+------------+---------------------------------------+-----------------+\n",
      "| Column Name   | Data Type    | Nullable   | Default                               | Autoincrement   |\n",
      "+===============+==============+============+=======================================+=================+\n",
      "| id            | INTEGER      | No         | nextval('employees_id_seq'::regclass) | Yes             |\n",
      "+---------------+--------------+------------+---------------------------------------+-----------------+\n",
      "| name          | VARCHAR(100) | Yes        | None                                  | No              |\n",
      "+---------------+--------------+------------+---------------------------------------+-----------------+\n",
      "| position      | VARCHAR(50)  | Yes        | None                                  | No              |\n",
      "+---------------+--------------+------------+---------------------------------------+-----------------+\n",
      "| salary        | NUMERIC      | Yes        | None                                  | No              |\n",
      "+---------------+--------------+------------+---------------------------------------+-----------------+\n"
     ]
    }
   ],
   "source": [
    "print(get_schema(\"_\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SELECT MAX(salary) AS largest_salary FROM employees;'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI()\n",
    "\n",
    "sql_response = (\n",
    "    RunnablePassthrough.assign(schema=get_schema)\n",
    "    | prompt\n",
    "    | model.bind(stop=[\"\\nSQLResult:\"])\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "sql_response.invoke({\"question\": \"What is the largest salary?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "template = \"\"\"Based on the table schema below, question, sql query, and sql response, write a natural language response:\n",
    "{schema}\n",
    "\n",
    "Question: {question}\n",
    "SQL Query: {query}\n",
    "SQL Response: {response}\"\"\"\n",
    "prompt_response = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "\n",
    "def debug(input):\n",
    "    print(\"SQL Output: \", input[\"query\"])\n",
    "    return input\n",
    "\n",
    "\n",
    "sql_chain = (\n",
    "    RunnablePassthrough.assign(query=sql_response).assign(\n",
    "        schema=get_schema,\n",
    "        response=lambda x: run_query(x[\"query\"]),\n",
    "    )\n",
    "    | RunnableLambda(debug)\n",
    "    | prompt_response\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL Output:  SELECT MAX(salary) AS highest_salary FROM employees;\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"The highest salary in the 'employees' table is $75,000.\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_chain.invoke({\"question\": \"Whats is the highest salary?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An unexpected error occurred\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy.exc import ProgrammingError\n",
    "from psycopg2.errors import InsufficientPrivilege\n",
    "\n",
    "try:\n",
    "    result = sql_chain.invoke({\"question\": \"Drop all rows from the employees table\"})\n",
    "except ProgrammingError as pe:\n",
    "    if isinstance(pe.orig, InsufficientPrivilege):\n",
    "        result = \"Haha nice try! Got ya!\"\n",
    "    else:\n",
    "        result = \"An unexpected error occurred\"\n",
    "except Exception as e:\n",
    "    result = \"An unexpected error occurred\"\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Routing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "\n",
    "classification_template = PromptTemplate.from_template(\n",
    "    \"\"\"You are good at classifying a question.\n",
    "    Given the user question below, classify it as either being about `Database`, `Chat` or 'Offtopic'.\n",
    "\n",
    "    <If the question is about products of the restaurant OR ordering food classify the question as 'Database'>\n",
    "    <If the question is about restaurant related topics like opening hours and similar topics, classify it as 'Chat'>\n",
    "    <If the question is about whether, football or anything not related to the restaurant or\n",
    "    products, classify the question as 'offtopic'>\n",
    "\n",
    "    <question>\n",
    "    {question}\n",
    "    </question>\n",
    "\n",
    "    Classification:\"\"\"\n",
    ")\n",
    "\n",
    "classification_chain = classification_template | ChatOpenAI() | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Offtopic'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_chain.invoke({\"question\": \"How is the wheather?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def route(info):\n",
    "    if \"database\" in info[\"topic\"].lower():\n",
    "        return sql_chain\n",
    "    elif \"chat\" in info[\"topic\"].lower():\n",
    "        return rag_chain\n",
    "    else:\n",
    "        return \"I am sorry, I am not allowed to answer about this topic.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda, RunnableParallel\n",
    "\n",
    "full_chain = RunnableParallel(\n",
    "    {\n",
    "        \"topic\": classification_chain,\n",
    "        \"question\": lambda x: x[\"question\"],\n",
    "    }\n",
    ") | RunnableLambda(route)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Based on the provided context, it is not possible to determine the number of employees at Chef Amico's Restaurant. The documents only mention the creation of the restaurant and its philosophy of hospitality.\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_chain.invoke({\"question\": \"How many employees do you have?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I am sorry, I am not allowed to answer about this topic.'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_chain.invoke({\"question\": \"How will the weather be tomorrow?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Chef Amico is the owner of the restaurant.'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_chain.invoke({\"question\": \"Who is the owner of the restaurant?\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
