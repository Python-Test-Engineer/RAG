[{"type": "Title", "element_id": "1da1e86aee0161ebb09aeb835d275739", "text": "Advancing Post-OCR Correction: A Comparative Study of Synthetic Data", "metadata": {"filetype": "application/pdf", "languages": ["eng"], "page_number": 1, "filename": "post_ocr.pdf"}},{"type": "NarrativeText", "element_id": "65d9e950ed9783c727f11dc67550c0c0", "text": "Shuhao Guan, Derek Greene", "metadata": {"filetype": "application/pdf", "languages": ["eng"], "page_number": 1, "parent_id": "1da1e86aee0161ebb09aeb835d275739", "filename": "post_ocr.pdf"}},{"type": "NarrativeText", "element_id": "010cc9498a23c8b01bf09a54d2db5c72", "text": "Insight Centre for Data Analytics, Dublin School of Computer Science, University College Dublin, Ireland shuhao.guan@ucdconnect.ie, derek.greene@ucd.ie", "metadata": {"filetype": "application/pdf", "languages": ["eng"], "page_number": 1, "parent_id": "1da1e86aee0161ebb09aeb835d275739", "filename": "post_ocr.pdf"}},{"type": "NarrativeText", "element_id": "fe5348afd281ad1a17ba2095f7bd5fcf", "text": "4 2 0 2 g u A 3 1 ] L C . s c [ 2 v 3 5 2 2 0 . 8 0 4 2 : v i X r a", "metadata": {"filetype": "application/pdf", "languages": ["eng"], "page_number": 1, "parent_id": "1da1e86aee0161ebb09aeb835d275739", "filename": "post_ocr.pdf"}},{"type": "Title", "element_id": "1f1b9b647bf8819946d0edd026c26af0", "text": "Abstract", "metadata": {"filetype": "application/pdf", "languages": ["eng"], "page_number": 1, "filename": "post_ocr.pdf"}},{"type": "NarrativeText", "element_id": "6f382e1f454d8094dc477e1776aed83b", "text": "This paper explores the application of synthetic data in the post-OCR domain on multiple fronts by conducting experiments to assess the im- pact of data volume, augmentation, and syn- thetic data generation methods on model per- formance. Furthermore, we introduce a novel algorithm that leverages computer vision fea- ture detection algorithms to calculate glyph similarity for constructing post-OCR synthetic data. Through experiments conducted across a variety of languages, including several low- resource ones, we demonstrate that models like ByT5 can significantly reduce Character Error Rates (CER) without the need for manually an- notated data, and our proposed synthetic data generation method shows advantages over tra- ditional methods, particularly in low-resource languages1.", "metadata": {"links": [{"text": ".", "url": "Hfootnote.1", "start_index": 787}], "filetype": "application/pdf", "languages": ["eng"], "page_number": 1, "parent_id": "1f1b9b647bf8819946d0edd026c26af0", "filename": "post_ocr.pdf"}},{"type": "Title", "element_id": "5bdf60f01788978c0952ee66a0906649", "text": "1 Introduction", "metadata": {"filetype": "application/pdf", "languages": ["eng"], "page_number": 1, "filename": "post_ocr.pdf"}},{"type": "NarrativeText", "element_id": "4de2bbcedd7831aac299e5d60942c9a5", "text": "Digital libraries, like the Internet Archive, offer a vast collection of historical and culturally im- portant books in image formats, including works written in low-resource and endangered languages. However, their image-only format limits content accessibility, hindering the use of these essential resources. Therefore, Optical Character Recogni- tion (OCR) technologies are evidently useful in this context. However, OCR outputs frequently contain errors, particularly when working with texts fea- turing complex styles, archaic fonts, or unconven- tional layouts. These errors may include character recognition mistakes, formatting issues, and hy- phenation problems, which are particularly promi- nent when dealing with low-resource languages (Ignat et al., 2022). Poor quality OCR can reduce the usefulness of these digital texts, adversely af- fecting downstream tasks (Linhares Pontes et al., 2019; Koudoro-Parfait et al., 2021).", "metadata": {"links": [{"text": "Ignat et al .,", "url": "cite.ignat2022ocr", "start_index": 750}, {"text": "2022", "url": "cite.ignat2022ocr", "start_index": 764}, {"text": "Linhares Pontes et al .,", "url": "cite.linhares2019impact", "start_index": 878}, {"text": "2019", "url": "cite.linhares2019impact", "start_index": 902}, {"text": "Koudoro - Parfait et al .,", "url": "cite.koudoro2021spatial", "start_index": 908}, {"text": "2021", "url": "cite.koudoro2021spatial", "start_index": 932}], "filetype": "application/pdf", "languages": ["eng"], "page_number": 1, "parent_id": "5bdf60f01788978c0952ee66a0906649", "filename": "post_ocr.pdf"}},{"type": "NarrativeText", "element_id": "7aef9cf6229f1a8157c741f3a5601ebf", "text": "1Code and data are available at https://github.com/ NikoGuan/P_OCR", "metadata": {"links": [{"text": "https :// github . com /", "url": "https://github.com/NikoGuan/P_OCR", "start_index": 32}, {"text": "NikoGuan / P _ OCR", "url": "https://github.com/NikoGuan/P_OCR", "start_index": 0}], "filetype": "application/pdf", "languages": ["eng"], "page_number": 1, "parent_id": "5bdf60f01788978c0952ee66a0906649", "filename": "post_ocr.pdf"}},{"type": "NarrativeText", "element_id": "de2f785deb0114ed9d42ed2fbafcbad8", "text": "Post-OCR correction is crucial for multiple rea- sons, including cultural heritage preservation (Jarl- brink and Snickars, 2017), expanding the accessi- bility of knowledge and information (Bazzo et al., 2020), and supporting further downstream tasks in cultural analytics (Stubbs, 1996). Additionally, ac- curate historical text data is extremely important for training large language models (LLMs) (Bubeck et al., 2023), which require high-quality data to improve their ability to handle complex queries, especially those involving history and culture.", "metadata": {"links": [{"text": "Jarl -", "url": "cite.jarlbrink2017cultural", "start_index": 97}, {"text": "brink and Snickars", "url": "cite.jarlbrink2017cultural", "start_index": 103}, {"text": "2017", "url": "cite.jarlbrink2017cultural", "start_index": 123}, {"text": "Bazzo et al .,", "url": "cite.bazzo2020assessing", "start_index": 190}, {"text": "2020", "url": "cite.bazzo2020assessing", "start_index": 204}, {"text": "Stubbs", "url": "cite.stubbs1996text", "start_index": 274}, {"text": "1996", "url": "cite.stubbs1996text", "start_index": 282}, {"text": "Bubeck", "url": "cite.bubeck2023sparks", "start_index": 401}, {"text": "et al .,", "url": "cite.bubeck2023sparks", "start_index": 408}, {"text": "2023", "url": "cite.bubeck2023sparks", "start_index": 416}], "filetype": "application/pdf", "languages": ["eng"], "page_number": 1, "parent_id": "5bdf60f01788978c0952ee66a0906649", "filename": "post_ocr.pdf"}},{"type": "NarrativeText", "element_id": "9e07417fd19528053e7a8f3cb6c3f012", "text": "Crowdsourcing has been the primary approach to acquire post-OCR training data in this domain (Clematide et al., 2016; Richter et al., 2018; Ma- heshwari et al., 2022). While this can provide highly accurate training data, the process is often time consuming and expensive. With the advent of Transformer architecture and attention mechanisms (Vaswani et al., 2017), deep learning models have emerged as the standard approach for post-OCR tasks. These models require large amounts of data for training. Thus, synthetic data has been increas- ingly adopted in this context. (D’hondt et al., 2017; Davydkin et al., 2023; Jasonarson et al., 2023). However, most existing literature on generating synthetic data relies on additional existing data for generation, and no comprehensive comparison has been made between different methods to under- stand how the synthetic data generated in various ways affects post-OCR performance.", "metadata": {"links": [{"text": "Clematide et al .,", "url": "cite.clematide2016crowdsourcing", "start_index": 94}, {"text": "2016", "url": "cite.clematide2016crowdsourcing", "start_index": 112}, {"text": "Richter et al .,", "url": "cite.richter2018low", "start_index": 118}, {"text": "2018", "url": "cite.richter2018low", "start_index": 134}, {"text": "Ma -", "url": "cite.maheshwari2022benchmark", "start_index": 140}, {"text": "heshwari et al .,", "url": "cite.maheshwari2022benchmark", "start_index": 144}, {"text": "2022", "url": "cite.maheshwari2022benchmark", "start_index": 161}, {"text": "Vaswani et al .,", "url": "cite.vaswani2017attention", "start_index": 343}, {"text": "2017", "url": "cite.vaswani2017attention", "start_index": 359}, {"text": "D ’ hondt et al .,", "url": "cite.d2017generating", "start_index": 573}, {"text": "2017", "url": "cite.d2017generating", "start_index": 589}, {"text": "Davydkin et al .,", "url": "cite.davydkin2023data", "start_index": 595}, {"text": "2023", "url": "cite.davydkin2023data", "start_index": 612}, {"text": "Jasonarson et al .,", "url": "cite.jasonarson2023generating", "start_index": 618}, {"text": "2023", "url": "cite.jasonarson2023generating", "start_index": 637}], "filetype": "application/pdf", "languages": ["eng"], "page_number": 1, "parent_id": "5bdf60f01788978c0952ee66a0906649", "filename": "post_ocr.pdf"}},{"type": "NarrativeText", "element_id": "0021435012302c21c526596fb5b0e667", "text": "To address these issues, this paper explores the impact of data volume and data augmentation meth- ods on the performance of post-OCR models. We examine several common methods for creating syn- thetic data in the post-OCR domain and propose a novel method based on feature detection algorithms from computer vision to calculate glyph similar- ity for synthetic data construction. We conduct experiments on eight languages, including several low-resource languages, achieving significant CER reductions ranging from 12.41% to 48.18%.", "metadata": {"filetype": "application/pdf", "languages": ["eng"], "page_number": 1, "parent_id": "5bdf60f01788978c0952ee66a0906649", "filename": "post_ocr.pdf"}},{"type": "Title", "element_id": "39daefe47daa7c751eaf072526233d09", "text": "2 Related Work", "metadata": {"filetype": "application/pdf", "languages": ["eng"], "page_number": 2, "filename": "post_ocr.pdf"}},{"type": "NarrativeText", "element_id": "d3e181f347d194fd92cd788a6af0bcc5", "text": "Popular OCR systems include the Google Vision API OCR system (Fujii et al., 2017) and the Tesser- act OCR engine (Smith, 2007). Jatowt et al. (2019) performed statistical analysis on the types of errors commonly produced by OCR systems.", "metadata": {"links": [{"text": "Fujii et al .,", "url": "cite.fujii2017sequence", "start_index": 62}, {"text": "2017", "url": "cite.fujii2017sequence", "start_index": 76}, {"text": "Smith", "url": "cite.smith2007overview", "start_index": 114}, {"text": "2007", "url": "cite.smith2007overview", "start_index": 121}, {"text": "Jatowt et al .", "url": "cite.jatowt2019deep", "start_index": 128}, {"text": "2019", "url": "cite.jatowt2019deep", "start_index": 143}], "filetype": "application/pdf", "languages": ["eng"], "page_number": 2, "parent_id": "39daefe47daa7c751eaf072526233d09", "filename": "post_ocr.pdf"}},{"type": "NarrativeText", "element_id": "b64b14da3fc648247825a81dd4aaa206", "text": "Post-OCR correction, while often overlooked, is an important NLP task. Lexical approaches to post- correction concentrate on character and word level inaccuracies, primarily employing dictionaries and heuristic rules. Bassil and Alwani (2012) exploited Google’s search suggestions for context-based cor- rections, circumventing the need for exhaustive dictionaries. Strategies specific to certain domains, such as those proposed by Furrer and Volk (2011), Estrella and Paliza (2014), and Kettunen (2016), highlight the necessity of tailored dictionaries for texts that possess unique features, like historical typefaces. Wemhoener et al. (2013) focused on aligning and merging outputs from various scans, including those from different editions, to rectify errors. Recent studies have framed post-OCR tasks as Seq2Seq tasks, with researchers applying both Statistical Machine Translation (SMT) and Neu- ral Machine Translation (NMT) models (Amrhein and Clematide, 2018). Nguyen et al. (2020) and Soper et al. (2021) employed BERT (Devlin et al., 2018) and BART (Lewis et al., 2019) models, re- spectively. Maheshwari et al. (2022) conducted a comparison between pre-trained models and tra- ditional Seq2Seq models, with their findings in- dicating that pre-trained models like ByT5 (Xue et al., 2022) outperform the conventional models. Ramirez-Orta et al. (2022) segmented documents into character n-grams, before aggregating their corrections into the final output via majority vot- ing (Lam and Suen, 1997), essentially acting as an ensemble of sequence models.", "metadata": {"links": [{"text": "Bassil and Alwani", "url": "cite.bassil2012ocr", "start_index": 218}, {"text": "2012", "url": "cite.bassil2012ocr", "start_index": 237}, {"text": "Furrer and Volk", "url": "cite.furrer2011reducing", "start_index": 431}, {"text": "2011", "url": "cite.furrer2011reducing", "start_index": 448}, {"text": "Estrella and Paliza", "url": "cite.estrella2014ocr", "start_index": 455}, {"text": "2014", "url": "cite.estrella2014ocr", "start_index": 476}, {"text": "Kettunen", "url": "cite.kettunen2016keep", "start_index": 487}, {"text": "2016", "url": "cite.kettunen2016keep", "start_index": 497}, {"text": "Wemhoener et al .", "url": "cite.wemhoener2013creating", "start_index": 620}, {"text": "2013", "url": "cite.wemhoener2013creating", "start_index": 638}, {"text": "Amrhein", "url": "cite.amrhein2018supervised", "start_index": 940}, {"text": "and Clematide", "url": "cite.amrhein2018supervised", "start_index": 948}, {"text": "2018", "url": "cite.amrhein2018supervised", "start_index": 963}, {"text": "Nguyen et al .", "url": "cite.nguyen2020neural", "start_index": 970}, {"text": "2020", "url": "cite.nguyen2020neural", "start_index": 985}, {"text": "Soper et al .", "url": "cite.soper2021bart", "start_index": 995}, {"text": "2021", "url": "cite.soper2021bart", "start_index": 1009}, {"text": "Devlin et al .,", "url": "cite.devlin2018bert", "start_index": 1030}, {"text": "2018", "url": "cite.devlin2018bert", "start_index": 1045}, {"text": "Lewis et al .,", "url": "cite.lewis2019bart", "start_index": 1061}, {"text": "2019", "url": "cite.lewis2019bart", "start_index": 1075}, {"text": "Maheshwari et al .", "url": "cite.maheshwari2022benchmark", "start_index": 1105}, {"text": "2022", "url": "cite.maheshwari2022benchmark", "start_index": 1124}, {"text": "Xue", "url": "cite.xue2022byt5", "start_index": 1281}, {"text": "et al .,", "url": "cite.xue2022byt5", "start_index": 1285}, {"text": "2022", "url": "cite.xue2022byt5", "start_index": 1293}, {"text": "Ramirez - Orta et al .", "url": "cite.ramirez2022post", "start_index": 1335}, {"text": "2022", "url": "cite.ramirez2022post", "start_index": 1356}, {"text": "Lam and Suen", "url": "cite.lam1997application", "start_index": 1487}, {"text": "1997", "url": "cite.lam1997application", "start_index": 1501}], "filetype": "application/pdf", "languages": ["eng"], "page_number": 2, "parent_id": "39daefe47daa7c751eaf072526233d09", "filename": "post_ocr.pdf"}},{"type": "NarrativeText", "element_id": "7b978711d1b7faa9f4795c701e2e801a", "text": "Data is fundamental to the success of deep learn- ing, as an increasing amount of research is directed towards leveraging data-driven strategies. These strategies aim to significantly improve model per- formance by optimizing data usage, rather than modifying the underlying model structure (Tarafdar et al., 2019; Mazumder et al., 2022). These efforts often involve generating large quantities of syn- thetic data (Choi and Park, 2023), involving data manipulation measures like filtering (Koehn et al., 2020), data augmentation (Shorten and Khoshgof- taar, 2019; Li et al., 2022), and noise injection (Izumi et al., 2003). Such synthetic data has been", "metadata": {"links": [{"text": "Tarafdar", "url": "cite.tarafdar2019using", "start_index": 291}, {"text": "et al .,", "url": "cite.tarafdar2019using", "start_index": 300}, {"text": "2019", "url": "cite.tarafdar2019using", "start_index": 308}, {"text": "Mazumder et al .,", "url": "cite.mazumder2022dataperf", "start_index": 314}, {"text": "2022", "url": "cite.mazumder2022dataperf", "start_index": 331}, {"text": "Choi and Park", "url": "cite.choi2023dmops", "start_index": 415}, {"text": "2023", "url": "cite.choi2023dmops", "start_index": 430}, {"text": "Koehn et al .,", "url": "cite.koehn2020findings", "start_index": 489}, {"text": "2020", "url": "cite.koehn2020findings", "start_index": 503}, {"text": "Shorten and Khoshgof -", "url": "cite.shorten2019survey", "start_index": 529}, {"text": "taar", "url": "cite.shorten2019survey", "start_index": 551}, {"text": "2019", "url": "cite.shorten2019survey", "start_index": 557}, {"text": "Li et al .,", "url": "cite.li2022data", "start_index": 563}, {"text": "2022", "url": "cite.li2022data", "start_index": 574}, {"text": "Izumi et al .,", "url": "cite.izumi2003automatic", "start_index": 602}, {"text": "2003", "url": "cite.izumi2003automatic", "start_index": 616}], "filetype": "application/pdf", "languages": ["eng"], "page_number": 2, "parent_id": "39daefe47daa7c751eaf072526233d09", "filename": "post_ocr.pdf"}},{"type": "NarrativeText", "element_id": "8ad3675978bbad9ee12a244ab500b316", "text": "widely used in various NLP tasks, such as gram- matical error correction (Ingólfsdóttir et al., 2023), language identification (Ahmadi et al., 2023), ques- tion answering (Puri et al., 2020), and named entity recognition (Liu et al., 2021).", "metadata": {"links": [{"text": "Ingólfsdóttir et al .,", "url": "cite.ingolfsdottir2023byte", "start_index": 74}, {"text": "2023", "url": "cite.ingolfsdottir2023byte", "start_index": 96}, {"text": "Ahmadi et al .,", "url": "cite.ahmadi2023pali", "start_index": 127}, {"text": "2023", "url": "cite.ahmadi2023pali", "start_index": 142}, {"text": "Puri et al .,", "url": "cite.puri2020training", "start_index": 171}, {"text": "2020", "url": "cite.puri2020training", "start_index": 184}, {"text": "Liu et al .,", "url": "cite.liu2021mulda", "start_index": 221}, {"text": "2021", "url": "cite.liu2021mulda", "start_index": 233}], "filetype": "application/pdf", "languages": ["eng"], "page_number": 2, "parent_id": "39daefe47daa7c751eaf072526233d09", "filename": "post_ocr.pdf"}},{"type": "NarrativeText", "element_id": "bea8200450cad844dda0f631d02309c1", "text": "For the task of text denoising, the primary method for constructing synthetic data is noise in- jection (Izumi et al., 2003). This technique involves inserting errors into clean text to generate training data pairs. D’hondt et al. (2017) added artificial OCR errors into sentences using a random process, while Jasonarson et al. (2023) focused on the low- resource Icelandic language for post-OCR tasks. The authors extracted OCR errors from real digi- tised documents and inserting them into clean text in similar proportions. Grundkiewicz et al. (2019) analyzed real data to create replacement sets for each word. Davydkin et al. (2023) adopted a differ- ent approach, developing a system to generate hand- written image data which were then processed with OCR. The resulting OCR outputs and the original texts were subsequently used to train a T5 model (Raffel et al., 2020) for correction purposes. Ignat et al. (2022) synthesized text image datasets by ma- nipulating parameters, like font spacing and image saturation, then compare the original text with the OCR output text, to evaluate OCR systems’ per- formance on various low-resource languages, and they enhanced Machine Translation (MT) through backtranslation (Sennrich et al., 2015).", "metadata": {"links": [{"text": "Izumi et al .,", "url": "cite.izumi2003automatic", "start_index": 73}, {"text": "2003", "url": "cite.izumi2003automatic", "start_index": 87}, {"text": "D ’ hondt et al .", "url": "cite.d2017generating", "start_index": 184}, {"text": "2017", "url": "cite.d2017generating", "start_index": 200}, {"text": "Jasonarson et al .", "url": "cite.jasonarson2023generating", "start_index": 278}, {"text": "2023", "url": "cite.jasonarson2023generating", "start_index": 297}, {"text": "Grundkiewicz et al .", "url": "cite.grundkiewicz2019neural", "start_index": 495}, {"text": "2019", "url": "cite.grundkiewicz2019neural", "start_index": 516}, {"text": "Davydkin et al .", "url": "cite.davydkin2023data", "start_index": 583}, {"text": "2023", "url": "cite.davydkin2023data", "start_index": 600}, {"text": "Raffel et al .,", "url": "cite.raffel2020exploring", "start_index": 824}, {"text": "2020", "url": "cite.raffel2020exploring", "start_index": 839}, {"text": "Ignat", "url": "cite.ignat2022ocr", "start_index": 870}, {"text": "et al .", "url": "cite.ignat2022ocr", "start_index": 876}, {"text": "2022", "url": "cite.ignat2022ocr", "start_index": 884}, {"text": "Sennrich et al .,", "url": "cite.sennrich2015improving", "start_index": 1191}, {"text": "2015", "url": "cite.sennrich2015improving", "start_index": 1208}], "filetype": "application/pdf", "languages": ["eng"], "page_number": 2, "parent_id": "39daefe47daa7c751eaf072526233d09", "filename": "post_ocr.pdf"}},{"type": "NarrativeText", "element_id": "e97f42163d4f788d669f5a79c9686df0", "text": "Some studies have explored improving post- OCR text correction by analyzing the visual forms of characters, known as glyphs. Chen and Zhou (2023) attempting to use the CharBERT model (Ma et al., 2020) for post-OCR. Their method consists of two parallel CNN encoders and a transformer decoder, taking CharBERT and glyph embedding as inputs. Amrhein and Clematide (2018)’s experi- ment included NMT models and glyph embedding, but it did not enhance model performance. Other re- search has focused on the detection of homoglyphs, with Ginsberg and Yu (2018) employing a grid method to assess the similarity of glyphs by count- ing the number of overlapping grids between char- acters. The similarity of glyphs is actually based on visual features. In the field of computer vision, feature detection and matching algorithms, such as SIFT (Ng and Henikoff, 2003), ORB (Rublee et al., 2011), and AKAZE (Alcantarilla and Solutions, 2011) can extract feature points from an image and match them with those appearing in other images.", "metadata": {"links": [{"text": "Chen and Zhou", "url": "cite.chen2023enhancing", "start_index": 125}, {"text": "2023", "url": "cite.chen2023enhancing", "start_index": 140}, {"text": "Ma", "url": "cite.ma2020charbert", "start_index": 184}, {"text": "et al .,", "url": "cite.ma2020charbert", "start_index": 187}, {"text": "2020", "url": "cite.ma2020charbert", "start_index": 195}, {"text": "Amrhein and Clematide", "url": "cite.amrhein2018supervised", "start_index": 340}, {"text": "2018", "url": "cite.amrhein2018supervised", "start_index": 363}, {"text": "Ginsberg and Yu", "url": "cite.ginsberg2018rapid", "start_index": 533}, {"text": "2018", "url": "cite.ginsberg2018rapid", "start_index": 550}, {"text": "Ng and Henikoff", "url": "cite.ng2003sift", "start_index": 835}, {"text": "2003", "url": "cite.ng2003sift", "start_index": 852}, {"text": "Rublee et al .,", "url": "cite.rublee2011orb", "start_index": 864}, {"text": "2011", "url": "cite.rublee2011orb", "start_index": 879}, {"text": "Alcantarilla and Solutions", "url": "cite.alcantarilla2011fast", "start_index": 897}, {"text": "2011", "url": "cite.alcantarilla2011fast", "start_index": 925}], "filetype": "application/pdf", "languages": ["eng"], "page_number": 2, "parent_id": "39daefe47daa7c751eaf072526233d09", "filename": "post_ocr.pdf"}},{"type": "Title", "element_id": "a72812d810744bd76fca9b8ff6d2acc4", "text": "3 Methods", "metadata": {"filetype": "application/pdf", "languages": ["eng"], "page_number": 3, "filename": "post_ocr.pdf"}},{"type": "NarrativeText", "element_id": "99905be54dad614807cb88ce30478d3e", "text": "We now describe three common methods for gen- erating synthetic data in the post-OCR domain, be- fore introducing a new method based on glyph sim- ilarity in Section 3.4. Each method makes use of a clean corpus A. As a common preprocessing step, we segment A into multiple chunks by initially di- viding sentences based on punctuation marks and then concatenating these sentences, ensuring that the total length of each chunk does not exceed a fixed limit of 230 characters, with the exception of Russian and Telugu, where the limits are 140 and 90 characters, respectively.", "metadata": {"links": [{"text": "3 . 4", "url": "subsection.3.4", "start_index": 166}], "filetype": "application/pdf", "languages": ["eng"], "page_number": 3, "parent_id": "a72812d810744bd76fca9b8ff6d2acc4", "filename": "post_ocr.pdf"}},