{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PostgreSQL as Vector Database: Getting Started With pgvector\n",
    "\n",
    "Pgvector is a PostgreSQL extension that provides the database with essential capabilities needed for a vector database. With pgvector, you can efficiently store vectors/embeddings in PostgreSQL, perform vector similarity searches, optimize data access with IVFFlat and HNSW indexes, and much more.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "* [Docker](https://www.docker.com)\n",
    "* Python and pip.\n",
    "* [OpenAI API key](https://platform.openai.com).\n",
    "\n",
    "## Install Required Modules\n",
    "\n",
    "The notebook uses the following libraries:\n",
    "\n",
    "* `openai` - provides access to the OpenAI Embedding API.\n",
    "* `psycopg2` - PostgreSQL database driver for Python.\n",
    "* `wget` - allows for downloading files and datasets.\n",
    "\n",
    "Install the libraries with pip:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install openai psycopg2 wget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start PostgreSQL With pgvector\n",
    "\n",
    "The fastest way to begin using PostgreSQL as a vector database is by creating a database container with the pre-installed pgvector extension. Run the command below to start PostgreSQL with pgvector in Docker:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! docker compose up -d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enable the pgvector extension by connecting to the database instance from within the container with `psql` and running the `CREATE EXTENSION vector` command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait for Postgres to be ready\n",
    "! while ! docker exec -it postgres-pgvector pg_isready -U postgres; do sleep 1; done\n",
    "\n",
    "# Enable the pgvector extension\n",
    "! docker exec -it postgres-pgvector psql -U postgres -c 'CREATE EXTENSION vector'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Provide OpenAI API Key\n",
    "\n",
    "Provide your OpenAI API key by setting it as the `OPENAI_API_KEY` environment variable and run the code snippet below. If the variable is not set, you'll be prompted to enter the key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from getpass import getpass\n",
    "\n",
    "openai_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if (openai_key == None):\n",
    "    openai_key = getpass('Provide your OpenAI API key: ')\n",
    "\n",
    "if (not openai_key):\n",
    "    raise Exception('No OpenAI API key provided. Please set the OPENAI_API_KEY environment variable or provide it when prompted.')\n",
    "\n",
    "openai.api_key = openai_key\n",
    "\n",
    "print('OpenAI API key set.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Sample Dataset\n",
    "\n",
    "The notebook uses a [movies dataset](https://huggingface.co/datasets/denismagda/movies/blob/main/README.md) comprising over 45,000 movies and 26 million ratings from more than 270,000 users. The dataset includes pre-generated embeddings for the movies' overviews, which were generated with the OpenAI `text-embedding-ada-002` model.\n",
    "\n",
    "First, download the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget\n",
    "\n",
    "schema_file = \"https://huggingface.co/datasets/denismagda/movies/raw/main/movie_schema.sql\"\n",
    "data_file = \"https://huggingface.co/datasets/denismagda/movies/resolve/main/movie_data_with_openai_embeddings.sql\"\n",
    "\n",
    "print('Downloading the schema file...')\n",
    "wget.download(schema_file)\n",
    "\n",
    "# This file is 900MB, so it might take a minute to download it\n",
    "print('Downloading the data file...')\n",
    "wget.download(data_file)\n",
    "\n",
    "print('Finished downloading the files.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, open a database connection using the psycopg2 driver:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "\n",
    "print('Connecting to PostgreSQL...')\n",
    "conn = psycopg2.connect(\"host=localhost dbname=postgres user=postgres password=password\")\n",
    "    \n",
    "cursor = conn.cursor()\n",
    "\n",
    "print('Successfully connected to PostgreSQL.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, load the dataset into Postgres:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Creating the schema...')\n",
    "schema_file = open('movie_schema.sql', 'r')\n",
    "cursor.execute(schema_file.read())\n",
    "conn.commit()\n",
    "\n",
    "print('Loading the data. It might take a minute...')\n",
    "data_file = open('movie_data_with_openai_embeddings.sql', 'r')\n",
    "cursor.execute(data_file.read())\n",
    "conn.commit()\n",
    "\n",
    "cursor.execute('SELECT COUNT(*) FROM movie')\n",
    "result = cursor.fetchone()\n",
    "\n",
    "print(f'{result[0]} movies loaded.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Vector Similarity Search\n",
    "\n",
    "The dataset already stores a vectorized representation of movies' overviews in the `overview_vector` column. Each vector is a 1536-dimensional embedding generated with the OpenAI `text-embedding-ada-002` model.\n",
    "\n",
    "First, define several functions that generate vectors for user prompts and configure the matching threshold and count parameters for the similarity search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the prompt to the pgvector embedding\n",
    "def get_embedding(prompt):\n",
    "    response = openai.embeddings.create(\n",
    "        input=prompt,\n",
    "        model='text-embedding-ada-002')\n",
    "\n",
    "    embedding = response.data[0].embedding\n",
    "\n",
    "    # Converting the embedding to the pgvector and returning it\n",
    "    return '[' + ','.join(map(str, embedding)) + ']'\n",
    "\n",
    "# Getting the matching threshold for the similarity search\n",
    "def get_matching_threshold():\n",
    "    return 0.7\n",
    "\n",
    "# Getting the number of matching movies to return\n",
    "def get_matching_count():\n",
    "    return 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, find the most relevant movies for a provided user prompt by calculating the cosine distance (`<=>`) between the prompt's and movies' embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = 'A movie about a space adventure.'\n",
    "\n",
    "prompt_vector = get_embedding(user_prompt)\n",
    "\n",
    "cursor.execute(\n",
    "    'SELECT title, overview '\n",
    "    'FROM movie WHERE 1 - (overview_vector <=> %(prompt_vector)s) >= %(match_threshold)s '\n",
    "    'ORDER BY overview_vector <=> %(prompt_vector)s LIMIT %(match_cnt)s',\n",
    "    {'prompt_vector': prompt_vector, 'match_threshold': get_matching_threshold(), 'match_cnt': get_matching_count()}\n",
    "    )\n",
    "\n",
    "result = cursor.fetchall()\n",
    "\n",
    "for row in result:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Filter Data Before Similarity Search\n",
    "\n",
    "As a general-purpose relational database, PostgreSQL allows you to pre-filter data before a vector search is started. You can pre-filter by specifying a condition on non-vector columns in the `WHERE` clause of a query statement.\n",
    "\n",
    "For instance, imagine the user selecting the `Science Fiction` category and asking to suggest movies with a rating of `7` or higher. Then, the user prompts for `A movie about a space adventure`. The final SQL query can look as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = 'A movie about a space adventure.'\n",
    "\n",
    "prompt_vector = get_embedding(user_prompt)\n",
    "\n",
    "cursor.execute(\n",
    "    'SELECT title, vote_average, genres '\n",
    "    'FROM movie WHERE vote_average >= 7 '\n",
    "    'AND genres @> \\'[{\"name\": \"Science Fiction\"}]\\' '\n",
    "    'AND 1 - (overview_vector <=> %(prompt_vector)s) >= %(match_threshold)s '\n",
    "    'ORDER BY overview_vector <=> %(prompt_vector)s LIMIT %(match_cnt)s',\n",
    "    {'prompt_vector': prompt_vector, 'match_threshold': get_matching_threshold(), 'match_cnt': get_matching_count()}\n",
    "    )\n",
    "\n",
    "result = cursor.fetchall()\n",
    "\n",
    "for row in result:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PostgreSQL will pre-filter data using the following columns:\n",
    "\n",
    "* The `vote_average` column stores a rank from `1` through `10`. \n",
    "* The `genres` column is an array of JSON objects stored in the JSONB format. A movie can be categorized by several genres, with a sample value looking as follows - `[{'id': 12, 'name': 'Adventure'}, {'id': 18, 'name': 'Drama'}, {'id': 878, 'name': 'Science Fiction'}])`\n",
    "\n",
    "Run the `EXPLAIN` statement if you'd like to see the actual execution plan:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = 'A movie about a space adventure.'\n",
    "\n",
    "prompt_vector = get_embedding(user_prompt)\n",
    "\n",
    "cursor.execute(\n",
    "    'EXPLAIN (costs off) SELECT title, vote_average, genres '\n",
    "    'FROM movie WHERE vote_average >= 7 '\n",
    "    'AND genres @> \\'[{\"name\": \"Science Fiction\"}]\\' '\n",
    "    'AND 1 - (overview_vector <=> %(prompt_vector)s) >= %(match_threshold)s '\n",
    "    'ORDER BY overview_vector <=> %(prompt_vector)s LIMIT %(match_cnt)s',\n",
    "    {'prompt_vector': prompt_vector, 'match_threshold': get_matching_threshold(), 'match_cnt': get_matching_count()}\n",
    "    )\n",
    "\n",
    "result = cursor.fetchall()\n",
    "\n",
    "for row in result:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The generated plan should look as follows:\n",
    "```sql\n",
    "('Limit',)\n",
    "('  ->  Sort',)\n",
    "(\"        Sort Key: ((overview_vector <=> '[0.015902195,-0.03861236,-0.02809557,...]'::vector))\",)\n",
    "('        ->  Seq Scan on movie',)\n",
    "('              Filter: ((vote_average >= \\'7\\'::numeric) AND (genres @> \\'[{\"name\": \"Science Fiction\"}]\\'::jsonb) AND ((\\'1\\'::double precision - (overview_vector <=> \\'[0.015902195,-0.03861236,-0.02809557,...]\\'::vector)) >= \\'0.7\\'::double precision))',)\n",
    "\n",
    "```\n",
    "\n",
    "The plan indicates that the data is initially filtered by the `vote_average` and `genres` columns, followed by the similarity search on the `overview_vector` column. Note that PostgreSQL may use a different plan if you create an index for any of the columns or if other conditions change."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize Vector Search With HNSW Index\n",
    "\n",
    "Currently, the embeddings stored in the `overview_vector` column are not indexed. This means that the database performs an exact nearest neighbor search by comparing a user prompt's vector to all the movies' overview embeddings. You can confirm this by checking the execution plan, which will show the `Seq Scan` (full table scan) access method on the `movie` table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = 'A movie about a space adventure.'\n",
    "\n",
    "prompt_vector = get_embedding(user_prompt)\n",
    "\n",
    "cursor.execute(\n",
    "    'EXPLAIN (costs off) SELECT title, overview '\n",
    "    'FROM movie WHERE 1 - (overview_vector <=> %(prompt_vector)s) >= %(match_threshold)s '\n",
    "    'ORDER BY overview_vector <=> %(prompt_vector)s LIMIT %(match_cnt)s',\n",
    "    {'prompt_vector': prompt_vector, 'match_threshold': get_matching_threshold(), 'match_cnt': get_matching_count()}\n",
    "    )\n",
    "\n",
    "result = cursor.fetchall()\n",
    "\n",
    "for row in result:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Postgres pgvector supports the IVFFlat and HNSW indexes, which are two of the most widespread index types across vector databases.\n",
    "\n",
    "Let's create an HNSW index on the embeddings stored in the `overview_vector` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Building the index. It might take a minute...')\n",
    "\n",
    "# Build the index\n",
    "cursor.execute(\n",
    "    'CREATE INDEX movie_overview_hnsw_idx ON movie '\n",
    "    'USING hnsw (overview_vector vector_cosine_ops) '\n",
    "    'WITH (m = 4, ef_construction = 10)')\n",
    "conn.commit()\n",
    "\n",
    "# Update the statistics for the query planner\n",
    "# to ensure that the index is used for the vector similarity search\n",
    "conn.autocommit = True\n",
    "cursor.execute(\n",
    "    'VACUUM ANALYZE movie')\n",
    "conn.autocommit = False\n",
    "\n",
    "print('HNSW Index created.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the execution plan once more for the previous query to ensure that Postgres now expedites the similarity search with the newly created index. You will see the `Index Scan` access method on the `movie` table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = 'A movie about a space adventure.'\n",
    "\n",
    "prompt_vector = get_embedding(user_prompt)\n",
    "\n",
    "cursor.execute(\n",
    "    'EXPLAIN (costs off) SELECT title, overview '\n",
    "    'FROM movie WHERE 1 - (overview_vector <=> %(prompt_vector)s) >= %(match_threshold)s '\n",
    "    'ORDER BY overview_vector <=> %(prompt_vector)s LIMIT %(match_cnt)s',\n",
    "    {'prompt_vector': prompt_vector, 'match_threshold': get_matching_threshold(), 'match_cnt': get_matching_count()}\n",
    "    )\n",
    "\n",
    "result = cursor.fetchall()\n",
    "\n",
    "for row in result:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learn More\n",
    "\n",
    "Deepen and broaden your knowledge about Postgres pgvector by checking the following resources by PostgreSQL community members:\n",
    "\n",
    "* pgvector hands-on video tutorial - [Building scalable generative AI apps with PostgreSQL pgvector](https://www.youtube.com/playlist?list=PLYlSOAEcOZ-V2uEJ_nyk32z70YAj4kR5K).\n",
    "* HNSW index deep dive - [HNSW Indexes with Postgres and pgvector](https://www.crunchydata.com/blog/hnsw-indexes-with-postgres-and-pgvector)  \n",
    "* pgvector performance tips - [Performance Tips Using Postgres and pgvector](https://www.crunchydata.com/blog/pgvector-performance-for-developers)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
