[
  {
    "type": "CompositeElement",
    "element_id": "407fdb177b837b5782b651e244dce65d",
    "text": "Advancing Post-OCR Correction: A Comparative Study of Synthetic Data\n\nShuhao Guan, Derek Greene Insight Centre for Data Analytics, Dublin School of Computer Science, University College Dublin, Ireland shuhao.guan@ucdconnect.ie, derek.greene@ucd.ie\n\n4 2 0 2\n\ng u A 3 1\n\n] L C . s c [\n\n2 v 3 5 2 2 0 . 8 0 4 2 : v i X r a\n\nAbstract\n\nThis paper explores the application of synthetic data in the post-OCR domain on multiple fronts by conducting experiments to assess the im- pact of data volume, augmentation, and syn- thetic data generation methods on model per- formance. Furthermore, we introduce a novel algorithm that leverages computer vision fea- ture detection algorithms to calculate glyph similarity for constructing post-OCR synthetic data. Through experiments conducted across a variety of languages, including several low- resource ones, we demonstrate that models like ByT5 can significantly reduce Character Error Rates (CER) without the need for manually an- notated data, and our proposed synthetic data generation method shows advantages over tra- ditional methods, particularly in low-resource languages1.\n\n1",
    "metadata": {
      "data_source": {
        "record_locator": {
          "path": "C:\\Users\\mrcra\\Desktop\\RAG\\test_files\\post_ocr.pdf"
        },
        "date_created": "1729365233.159691",
        "date_modified": "1727326976.0",
        "date_processed": "1729365755.923535",
        "permissions_data": [
          {
            "mode": 33206
          }
        ]
      },
      "filename": "post_ocr.pdf",
      "filetype": "application/pdf",
      "languages": [
        "eng"
      ],
      "page_number": 1,
      "orig_elements": "eJztWG1v2zYQ/isHfdoA25NEvTmflrldN2DYhiQFBtSFQZEnWQhFCiSV1Cvy33eUXdfpNrT5sAUF/CWRyOO9Pnfi4zfvI1TYo/abTkYXECWSJ1gVHDFOigTrOl5yrCuWy7TMS7aMZhD16LnknpP8+yg8bJwZrcAP77gRFunfXmGZLlmRp4wtknxZLJOgYRLqjeya7ihVsrRYlsUiPgoM1gh07pGeMs8Xy5TlLA9iA9q+c64z2m0OHr15H5Hi4AtjaVw8vCUxi8JYuVFGcG/s5ObA/TaoXV2s168dWrde91ZYvl6/QHfrzbBeX12+Wq89Or9pOoUkMBh6NsIuBtlEDw+kOGxo3gdr0aPdw57fDdMeHwbVkXFy9LvDtuK6HXmLLvgcoW6j4OlAKxs99jUGN5Ngw+M7H3RcyjuuRadb+J0szX9bXcHKWAotaL2AS3rrB27JyB3CtR/lDkwD1zvtt+g7AS9CfoK+g083nVcYkYVPIdAUJRZ1JZHVspRxzhNZITJRijhZNiw7Q+D/hMC0Yp/QoKeYud6OW27g1cj1DF6gxVt4ZRE1ws/ade3Ww4o0W4TG2AkgcKm52hFcHMmPteo0XIutMSpgKQBs9GhpqUMtcAavNYHNus7vaFMpbPFwagY/W6T4JLjJhQUFqr8fhRRGa4LsoqPTMji0aCeHwh4tngL0taZ0YWts9yfKmxDRP4A1q6qiypOsLMpUVDHLEl7EWIomKXjOijNYvx6wZpBCDOmTIZAIWTeVyKqiwCwtBTKMa0zzGDN6KuUZAl8NBFoY6UPGIDkFwa/c7r9q/wYAxjGvc0xE08SsKuIqzlKWllhWKQ2FsjoD4LnuLG/hF1jBAhwIOvAllw9eY5wWOctSAkeSLSuU2TKt8yYu6qIR5bmWz9nMn+200+KncEetnNNUD3N9ARX9DTP+gtY7+AMs8KfP+mWTxUKUeV2haKqMvvAZFSWJ4yor4yY9w+PZ6EntvOXCf1GXS5lTlmqeF1gLXidMspTHZcbrushljOcy/qdlpAv6rdtH4Ty3VBUt8R0tlFlxUtIZUPMTFxgVt2rXaWXuYQ5HlVOOR6uC6E+NMV4bj4skeviSW8Hn+vgUWjfbzpErVAbAd4MyFh0QqYWTeAM9cUeqG4oERF2C0PCBLEvTc1oj2X5UvhsUsR5rtHdQ74BoiRyJSRO7JhNouwBWsmKAEzTc3l7Xz8kN4YOxycSdUWNPRIaPbZCfPKG3wHp2eg6n3rTEcezeVQL21kg3eUIYUkD25oGB9cTvcQE/jpZO2p7inME9mSWGZsg7Chi0uaMDXIUx6bc9meAeFBIJCxWhMA4M7a4LcIUGObkxEsGT6Pe/FHw8PIUnuAr19Qit2g1bcF3fUbkDowuckPJCbX3IzDGVjzO9gJutNWO7fZS6Q0ZRAhfWUAYpXaSXwBrSdwTRjMITapRBv5viUEA4mwMVeWp3SlOQug8h9JM3wdkp7il7DlR3i/DD7ianYDQF0GpqeHr0akdapsSttjzMJkrMS2sprCvS4eCb1curb+GecmFGP1VYI/kb4qZSjFyRAk51JFyHOTMFuy8veQY0NyghKD/F3d8qTRTY3FP84fcbP5WJimiBApmD7IIgxXwAxeOWCxgOyTjm4mPvLZ50Q64ky7O6KnmeNCxmXC4TliaiYkWZF2mcn+fts1KkpwzD5DN3prd/ATZS/OE="
    }
  },
  {
    "type": "CompositeElement",
    "element_id": "0d1b60ce7a95816b5311c8d7e53677ee",
    "text": "Introduction\n\nDigital libraries, like the Internet Archive, offer a vast collection of historical and culturally im- portant books in image formats, including works written in low-resource and endangered languages. However, their image-only format limits content accessibility, hindering the use of these essential resources. Therefore, Optical Character Recogni- tion (OCR) technologies are evidently useful in this context. However, OCR outputs frequently contain errors, particularly when working with texts fea- turing complex styles, archaic fonts, or unconven- tional layouts. These errors may include character recognition mistakes, formatting issues, and hy- phenation problems, which are particularly promi- nent when dealing with low-resource languages (Ignat et al., 2022). Poor quality OCR can reduce the usefulness of these digital texts, adversely af- fecting downstream tasks (Linhares Pontes et al., 2019; Koudoro-Parfait et al., 2021).\n\n1Code and data are available at https://github.com/",
    "metadata": {
      "data_source": {
        "record_locator": {
          "path": "C:\\Users\\mrcra\\Desktop\\RAG\\test_files\\post_ocr.pdf"
        },
        "date_created": "1729365233.159691",
        "date_modified": "1727326976.0",
        "date_processed": "1729365755.923535",
        "permissions_data": [
          {
            "mode": 33206
          }
        ]
      },
      "filename": "post_ocr.pdf",
      "filetype": "application/pdf",
      "languages": [
        "eng"
      ],
      "page_number": 1,
      "orig_elements": "eJztVU1v4zYQ/SuETglgO5Zk2VZ6WmSBbdFiNwjS03phUNTIIkyRWpKyYwT57/soOa4TpEW3aNHLnkxzRm/evPng58eIFDWk/VqW0TWLqnm2yItpypfZnNJ4tphNc16Veb6cZeUsj6MRixryvOSew/8xCoe1M50V9Pyf1sISfnrAeJHk6TxL0nQSZ/l8QOidGlPKSp68FmkyzxfzyfTk0FojyLkXOIssm+RJmqVZcGvJNtI5abRbHxl9fowAHLikaTKdP32BmyVhbLlWRnBvbE+z5b4OsDfXq9XvjqxbrRorLF+t3pPbetOuVnfvPqxWnpxfV1IRHFqDsxF20pZV9PQE4GDQvAnRohfWo80f2t7G21ZJBAfRq6NZcb3p+IZc4ByR3kSBaYubte6aggLNOMTw9OADxi/aW1N2IoAEgGfse+kVRfB8XcrpvCiXyyxOygWlVVkW8SzL+JxmWZUn2fRHKf/bUiqpt27IwnluURVd0gMuFtn0vKwbDYE8V2wyCmCdVeFaSE8TGWzJNEnAZajwK6T57AwpOH4vwnKxPEP4TeqaW3K3RkOsQOo1njp6JNM4l03LhX8LNZ8mL3jF+T/FOWf3q+lKYw0bs1tuKy7/TLXt4IesY4fekMjiLez0Jcck/js4b8xof2O/Y4OeD/V7uZEhCyULy60kN8JxS8zXxDDwZDV59s6KWu5oxExVkWWc7bjzTBilqN8GuGe1dJgHNKZiXJdMdMp3lit1YLIZs9ZYz7VnhTFbx6TGJZJglbEN94gptVBdKfWG7Y2Fx95K70kHT2X2YxSq3wo9NOkS/U6WSnZq/An72expR3YUmEs74I+NRvwhCNJqpHdgjazAhIuwD2QhlfSHEeijLDYQCJl3jkJOOOIQ1oYO6rNnGgh3X4MAkCHKp9b3ad+godBHEOgOO2Kj5Zj14lx8urm7ZJ5ErY0yG2jMUC5GO1kCFwQRrepUyNVDxYHhgz9LCQDMdL7twL+y9LUbvguOHF+RtcZCRHQBmHSKWxj3NeQLYvaiSl+zAIrviYNX16cqTNMqemDOH1SoPEeduRRQTIeiGMs6jSA70kMqoU/4AUwGAYI2fWjW8MOxhMTESQY7yNCLgNXq+TYEGcrhQ3ys266Pi6rWB3QJOPeLjWFdF3hLYNvXUtS9YC/Sg0MDgXUoZZ9qSVydUn3RM6cmYRf9rmPoaK4mIxbW0uWE3Rok+rXjoRF6qQXX4I6Xjp6bAeXRaIM/eqI8jk2vKRIoUSdH4MWrMSQWfXql2Wvn8Xw1zHOHrr543m9sWHBnTOL8J3bcL+PjdjnnGV9Ozp/cj9xaCLWj+zDGbzy9MS0XaTEr8MRVPMVzWPC8FNVSLAXHyi1+PL3/z9ObLs527/XVFUMb1V3BJmEWz/Z/7X3rYB/MExivPsqt+dBxfXW7RpP++y9BfAO9+1EMJegnju+4VByDyDA1b1D6i5b88g3GZOKK"
    }
  },
  {
    "type": "CompositeElement",
    "element_id": "20ae4255a37bcfd313efc4ebf8c8e353",
    "text": "NikoGuan/P_OCR\n\nPost-OCR correction is crucial for multiple rea- sons, including cultural heritage preservation (Jarl- brink and Snickars, 2017), expanding the accessi- bility of knowledge and information (Bazzo et al., 2020), and supporting further downstream tasks in cultural analytics (Stubbs, 1996). Additionally, ac- curate historical text data is extremely important for training large language models (LLMs) (Bubeck et al., 2023), which require high-quality data to improve their ability to handle complex queries, especially those involving history and culture.\n\nCrowdsourcing has been the primary approach to acquire post-OCR training data in this domain (Clematide et al., 2016; Richter et al., 2018; Ma- heshwari et al., 2022). While this can provide highly accurate training data, the process is often time consuming and expensive. With the advent of Transformer architecture and attention mechanisms (Vaswani et al., 2017), deep learning models have emerged as the standard approach for post-OCR tasks. These models require large amounts of data for training. Thus, synthetic data has been increas- ingly adopted in this context. (D\u2019hondt et al., 2017; Davydkin et al., 2023; Jasonarson et al., 2023). However, most existing literature on generating synthetic data relies on additional existing data for generation, and no comprehensive comparison has been made between different methods to under- stand how the synthetic data generated in various ways affects post-OCR performance.",
    "metadata": {
      "data_source": {
        "record_locator": {
          "path": "C:\\Users\\mrcra\\Desktop\\RAG\\test_files\\post_ocr.pdf"
        },
        "date_created": "1729365233.159691",
        "date_modified": "1727326976.0",
        "date_processed": "1729365755.923535",
        "permissions_data": [
          {
            "mode": 33206
          }
        ]
      },
      "filename": "post_ocr.pdf",
      "filetype": "application/pdf",
      "languages": [
        "eng"
      ],
      "page_number": 1,
      "orig_elements": "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"
    }
  },
  {
    "type": "CompositeElement",
    "element_id": "5c3f3e84c23b112f06a9499f2cb9bb47",
    "text": "To address these issues, this paper explores the impact of data volume and data augmentation meth- ods on the performance of post-OCR models. We examine several common methods for creating syn- thetic data in the post-OCR domain and propose a novel method based on feature detection algorithms from computer vision to calculate glyph similar- ity for synthetic data construction. We conduct experiments on eight languages, including several low-resource languages, achieving significant CER reductions ranging from 12.41% to 48.18%.\n\n2 Related Work\n\nPopular OCR systems include the Google Vision API OCR system (Fujii et al., 2017) and the Tesser- act OCR engine (Smith, 2007). Jatowt et al. (2019) performed statistical analysis on the types of errors commonly produced by OCR systems.",
    "metadata": {
      "data_source": {
        "record_locator": {
          "path": "C:\\Users\\mrcra\\Desktop\\RAG\\test_files\\post_ocr.pdf"
        },
        "date_created": "1729365233.159691",
        "date_modified": "1727326976.0",
        "date_processed": "1729365755.923535",
        "permissions_data": [
          {
            "mode": 33206
          }
        ]
      },
      "filename": "post_ocr.pdf",
      "filetype": "application/pdf",
      "languages": [
        "eng"
      ],
      "page_number": 1,
      "orig_elements": "eJztVd9v2zYQ/lcOBgokQKLqhyVZfSuyrdgetiLL1oe6MGjyZLOhRI2knBhB/vfd0U6qZME6DNie+mKL5PHjd/cd+X28m6HBDvuw0mr2Bmb1XIl1lclClmtZLiqxlmkrUZSlXDSqWc/OYNZhEEoEQfF3M/5YeTs6iQ9jXEmH9BcBszpviqrMiyLJyqZqMkaIQZ1VutWPUXWRV01dJeljwOCsRO+f4NRlmTR5URYlhw3oOu29tr1fHRl9vJsRMHMpijyt7j9RmENpnVoZK0WwLtIcRNgy7MWb5fI3j84vl52TTiyX36G/DnZYLi/fvlsuA/qwarVBChgsfVvpkkG1s/t7AuaFXnR82uzJ6nEt7Ie4JobBaDqciL4+LhvRb0axQc+cZ9hvZsx0oJlVP3ZrZJpZnHFf1JGLelG3aZbNK9FURUW/WVVk+RrLIlUVsaIdAW8DB19ZEEo5qiCELXoEqtSI/oxG2sMgqHiAt4OxFMIRoLtByAC2Ba4l7KwZOwTRq8NYjBtulJgFUA9sz8EqDzTgzYTWWteJXiIjcDXOf7m4BBbD+AQ+IB0mOt0jeNyhEwak7bojFAPRdoiNo/sN+H1/zrhBy8Pp+njMA66ynaA5Zkd9QtPEFHq7Q3MEhLWg1mF6LWGODkFhQBnZC7OxTodtR6c62zGTYQxUj53mZoJgQQojR0NtCBuzH7bgdaeNcOegwz5SJYZTfpJ6MLgx4sdsaULRkEuMTnPlYq1Qb7YBHtU/o8SkGVXM+VgXY2/OSZN4p6aRQm417mKk3vR0d6ToA1x8fwkO1eFkD47iOSTmleXJPHvF6cwXSbZ4lXDnPTTlz8I5KvYOr7hhqHOevwVFowS2OK+VELWsywxFm9Z5mVd0m1XafHsL/se3IJ9e7RwukXtTwQfrrqeiXulg8CUxVYHZImsLUjNr5q1qcqnqxUJUpOlayvKbmP+pmEb31/6QhQ/CkSq9wluaqPKJrj+Mn7UmEQwkZ4w1OhOffR0waXktT7Pa4x8j0jN7UPkpWl1Nu4SC/xUK+csE5teOXsrnOJ4n8zSt6cV1O403L+Lk2RM66V/o/EOYxQTmJ5L6JnCRnoN9jiuUXKMQhxeR5sXT+jRfw3jhIj435a8+k9Ob+94O5CoO2ML83gckCzo4AEZ/e2ftxiD8fvCht+9/nETCSewPwEAGlpwBy3gaHZB3XvGNIn9iC+c9yD6AcBLl4+C0Pk3gUL0jBJxwoqcP3k3PiWd792Rq1IKiF2bv9aPDc8979nZ0zjp/tG+zZ/8l+6Hd6/00r78zm09/AofPZZU="
    }
  },
  {
    "type": "CompositeElement",
    "element_id": "e52c0fed76f06692ad99da67f29339bd",
    "text": "Post-OCR correction, while often overlooked, is an important NLP task. Lexical approaches to post- correction concentrate on character and word level inaccuracies, primarily employing dictionaries and heuristic rules. Bassil and Alwani (2012) exploited Google\u2019s search suggestions for context-based cor- rections, circumventing the need for exhaustive dictionaries. Strategies specific to certain domains, such as those proposed by Furrer and Volk (2011), Estrella and Paliza (2014), and Kettunen (2016), highlight the necessity of tailored dictionaries for texts that possess unique features, like historical typefaces. Wemhoener et al. (2013) focused on aligning and merging outputs from various scans, including those from different editions, to rectify errors. Recent studies have framed post-OCR tasks as Seq2Seq tasks, with researchers applying both Statistical Machine Translation (SMT) and Neu- ral Machine Translation (NMT) models (Amrhein and Clematide, 2018). Nguyen et al. (2020) and Soper et al. (2021) employed BERT (Devlin et al., 2018) and BART (Lewis et al., 2019) models, re- spectively. Maheshwari et al. (2022) conducted a comparison between pre-trained models and tra- ditional Seq2Seq models, with their findings in- dicating that pre-trained models like ByT5 (Xue et al., 2022) outperform the conventional models. Ramirez-Orta et al. (2022) segmented documents into character n-grams, before aggregating their corrections into the final output via majority vot- ing (Lam and",
    "metadata": {
      "data_source": {
        "record_locator": {
          "path": "C:\\Users\\mrcra\\Desktop\\RAG\\test_files\\post_ocr.pdf"
        },
        "date_created": "1729365233.159691",
        "date_modified": "1727326976.0",
        "date_processed": "1729365755.923535",
        "permissions_data": [
          {
            "mode": 33206
          }
        ]
      },
      "filename": "post_ocr.pdf",
      "filetype": "application/pdf",
      "languages": [
        "eng"
      ],
      "page_number": 2,
      "orig_elements": "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"
    }
  },
  {
    "type": "CompositeElement",
    "element_id": "6b9e20226739ccc4fdaaecb00972d92f",
    "text": "a et al. (2022) segmented documents into character n-grams, before aggregating their corrections into the final output via majority vot- ing (Lam and Suen, 1997), essentially acting as an ensemble of sequence models.",
    "metadata": {
      "data_source": {
        "record_locator": {
          "path": "C:\\Users\\mrcra\\Desktop\\RAG\\test_files\\post_ocr.pdf"
        },
        "date_created": "1729365233.159691",
        "date_modified": "1727326976.0",
        "date_processed": "1729365755.923535",
        "permissions_data": [
          {
            "mode": 33206
          }
        ]
      },
      "filename": "post_ocr.pdf",
      "filetype": "application/pdf",
      "languages": [
        "eng"
      ],
      "page_number": 2,
      "orig_elements": "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",
      "is_continuation": true
    }
  },
  {
    "type": "CompositeElement",
    "element_id": "87a4c719db459ab852b00d6d6b5e22f6",
    "text": "Data is fundamental to the success of deep learn- ing, as an increasing amount of research is directed towards leveraging data-driven strategies. These strategies aim to significantly improve model per- formance by optimizing data usage, rather than modifying the underlying model structure (Tarafdar et al., 2019; Mazumder et al., 2022). These efforts often involve generating large quantities of syn- thetic data (Choi and Park, 2023), involving data manipulation measures like filtering (Koehn et al., 2020), data augmentation (Shorten and Khoshgof- taar, 2019; Li et al., 2022), and noise injection (Izumi et al., 2003). Such synthetic data has been\n\nwidely used in various NLP tasks, such as gram- matical error correction (Ing\u00f3lfsd\u00f3ttir et al., 2023), language identification (Ahmadi et al., 2023), ques- tion answering (Puri et al., 2020), and named entity recognition (Liu et al., 2021).",
    "metadata": {
      "data_source": {
        "record_locator": {
          "path": "C:\\Users\\mrcra\\Desktop\\RAG\\test_files\\post_ocr.pdf"
        },
        "date_created": "1729365233.159691",
        "date_modified": "1727326976.0",
        "date_processed": "1729365755.923535",
        "permissions_data": [
          {
            "mode": 33206
          }
        ]
      },
      "filename": "post_ocr.pdf",
      "filetype": "application/pdf",
      "languages": [
        "eng"
      ],
      "page_number": 2,
      "orig_elements": "eJztVk2P2zYQ/SuET7uA15Uoy7LSU5AARZBtEDTbUxwYtDiS2JVIhR9OnMX+987I9q7s2Ml2UaCXniyTw8c3w+F7/Hg3ggZa0H6p5OgFG2WrPJtncSzjVVYKkZfTLE+LLIqBwzyKxWjMRi14IYUXGH83oo+lM8EWsP8Py8IC/vSAccbzZJbyJJnEaT7LY0Log1ojVakeorKEz/JsNokeAjprCnDuACdL00nOkzRJKawD2yrnlNFuuWP08W6EwMQlSXg0u/+EYRYKY+WyMYXwxvY0O+Frgn31YrH404F1i0VrCysWi9fgbr3pFos/Xv62WHhwflmqBjCgM/htCjvpZDm6v0dgmtCipd1GB7O7Ob/p+jnRdY3CzZHoL7vpRugqiAoccR6BrkbEtFH61m2zcF5YPBUt4SsO8DzCaQ9fPeFdMDyChk3GjEdxzn5lv4tvoZVgH4c5Z5cTZkoPWum1adZQgQaLHHTVCFvB5yC0V16BM6XbaOIUbEPohfIwwd1FKYWlDYLDRSNM+JhVEg1Z7TZ/JtJ8gEShz4OJpwOYo6ocI7a7aSoWdQ92U3kSNIkPuHH+XKRpnA6QXtVGCS3fC3t7DFjgFIIlsjWdO4mURIeckn8OMc8HEG8N1JoKdYxzSxMIFJW4EMt+EiuNkkM60fNg+JDSh9pYbF8s0dvauLoy5TGo20ZQS7hg17A5CZoOj88LYZ8Jk/2kQ58GMxtW6lqd6c1G7XvpJEg2/UlH/nj9LOKD9W+wec/xUDTHoygRwZsW1aM4iRfPDvhE33XjKRwSvA4lcKlDuwLSZd6P2Ec7SnIpoIRpJoXIiiyNQZRRxlM+Q0ORUU5kHvZ9jdky5VgZtBTkaZiRN8zXwFwoyEpQD5kE6FgDwuorhn04ZsIxofGTTIt0hYnWBO0p1oLDwKImVKnQRtDUEPKLsNIhxhr1tKIVVOcradUaNHMeRRYq1NUJu6kRYDDChGqJklOVRu8rUIGbDVMtOt0aGPlWw1A7rlhpbCt0AWy1YabzqlXf9vuw4LBmY4aYNVjMDsn3VrqhCEoW0wfb9H+3kEggFD5YYBc3OxVFA2Gi2RnIo38Mhjm/3CcAJfLxbusmbGcn7NFPWG8o7NFRqHboKVdEB496y/uC9A5LLRkpXr9FcjnewT1kh2mrLjS9V7IWTwRpY63VLTB0VA+WIi96tRqSjRCpXy9C1R99v/5iJyH9rnsRQVaoAfvMr9VhzuM+VhuFeSv9Fx55D9TfkUFklGB1PgRsDcxzmGWN7bQC6P10b//vhKVCreGGOrW/P4evrrmQySxL8em1WgmZA8Rc8OlUrNIoWiXx7P9X13/z6jqQ2Te6WoQoKpOmdHL75b0697jANjUUaCiGWn218XBKO/ND6fzeyJ+MFPOhQ72sWyHPybroJwmsE406CTblP+H1BIxs6Lzvgz1Hp8MpusQolEqfedrF8yPP++6J8RQUzoeUrlU4678BoeI2NPKkg+LNOmQT/xjh3/a6LwqFfYNegIakNFsLq0xw7N31e1Q3d+vGZHk1eVtlRXvFesvFTMFaYxleTPugbKfbeqiKJNP7m8NwY1T5cnex2MW2z47DPwdwKLQUIbT7spNtaoFj1e7lFm+zZITrN4x0A+1xi44nNFwQX05+IKyf/gZv+rZ5"
    }
  },
  {
    "type": "CompositeElement",
    "element_id": "34dfb1b4fc570018364a2fbde5ab00a3",
    "text": "the primary method for constructing synthetic data is noise in- jection (Izumi et al., 2003). This technique involves inserting errors into clean text to generate training data pairs. D\u2019hondt et al. (2017) added artificial OCR errors into sentences using a random process, while Jasonarson et al. (2023) focused on the low- resource Icelandic language for post-OCR tasks. The authors extracted OCR errors from real digi- tised documents and inserting them into clean text in similar proportions. Grundkiewicz et al. (2019) analyzed real data to create replacement sets for each word. Davydkin et al. (2023) adopted a differ- ent approach, developing a system to generate hand- written image data which were then processed with OCR. The resulting OCR outputs and the original texts were subsequently used to train a T5 model (Raffel et al., 2020) for correction purposes. Ignat et al. (2022) synthesized text image datasets by ma- nipulating parameters, like font spacing and image saturation, then compare the original text with the OCR output text, to evaluate OCR systems\u2019 per- formance on various low-resource languages, and they enhanced Machine Translation (MT) through backtranslation (Sennrich et al., 2015).\n\nFor the task of text denoising,",
    "metadata": {
      "data_source": {
        "record_locator": {
          "path": "C:\\Users\\mrcra\\Desktop\\RAG\\test_files\\post_ocr.pdf"
        },
        "date_created": "1729365233.159691",
        "date_modified": "1727326976.0",
        "date_processed": "1729365755.923535",
        "permissions_data": [
          {
            "mode": 33206
          }
        ]
      },
      "filename": "post_ocr.pdf",
      "filetype": "application/pdf",
      "languages": [
        "eng"
      ],
      "page_number": 2,
      "orig_elements": "eJztV9+P2zYM/leIPF2AXBbbcRz3behhRQdsA7rrU1MEisQk6tmSJ8m5pkX/95GyL3XuUvTHtre93CWm/In8SH5k3nwcYYU1mrDWavQMRtkyV1k5T5ONQiWX5XKZS8xFpuabOX1QowmMagxCiSDo/McRf1h72zqJD99xLR3SvwiYFGmZLfI0y6ZJXi7KhBHiodoqvdWnU0WWLspiMZ2dDjTOSvT+DKfI82mZZnmW87EGXa2919b4de/Rm48jAmZfsiydLT69pWMOpXVqXVkpgnXRzUaEPcM+f7Zavfbo/GpVO+nEanWD/i7YZrV69fOL1SqgD+utrpAONJY+W+mmjdqOPn0iYDYYUfNtozNrbwvHJtpE01SaLidHf+rNlTC7VuzQs88jNLsRe1ppc+e7KHwQjrJiFL6nB0VG1oDvA8O9/NDWmpJQwXTCWK2r+LHUAaeabelslok22JqulCPy9DHcshjA8ekfg0mW8wHODazadJaUsLdGBfbvMaoic7FDg44QKeQLkHTnmWtJ8SMgRToAud9TKn4V3hrh6M8lx96drOkszb4CXp6Tlz4h73vQ5mU+QHvhWqPuNN5r+eGSn7uBnak22Do6dQE3TxbnPJb/AGs5rL4bcTjSexd5VL2N444NeQFt8SjDT/n7FpRlOiy9V2K7JSG73BIuGglshu+byrovZGKZled+zX4UaLEcAE2hc+uKSjtNYQz+aMIevf6Ais/omlSAo/QY/OZYiyetuDMi8LskLpd7eZjpS1n5KsJZG/PB70VIkjIZQPyJxjgt919IiO/NVHW5rknmD19gMklny/Mqzr8Ri8W0IWLXpq03yJqfxiduMOpKJXCL80IJUcgiT1BsZ0WapwsaVmpWskOnqylj0DjKlTsCzb+9VbC1DiRNnuBayd3dJ5akEjidoD0Yqz2CNtfwDiWrP1xF7aaSAFFNJ6x22XgKt3s6HFDujf6r5RcOtjqgpw80miI2OmcdPwgWZIXCAHsG9K2XF4TghDZ8Nt7eCO38FG46SY6K3N8KVyygYxCKRjwQ3TSFpaZE/fH81dk9RG1AQyMYWs+4ApwwytbQD+YJRGWFz9I6uCHNxsSQbGl8AxmYv8reX4PDblmAlxJpBipi62EURkZ5jF6zJ9QQd56pQaAZtGevKGInJC0WQ1e3jjyifaMCpXf6GoLmKxVdzWuNB7pjwCP5UT9hURvwutaVcBxaYx2niu4eqvGQvJLIM6I6Ugf3NzPjjBn3HnrWVELGtQq4q2NgKOQe7mkPoaT0+vaILqFsw8EJioSExl0DA9Du4Cy9OwGFB6xs06XCH32gUIYFsKdQr+He6UBpg6grnWeUJr4bHXL8Bk6LFdzrsGcyO54pN20VaWJ+bRuatieQ00d6t9MUduTMd3C+3XikkjWhOkLMNTkUC5FcvM2BV7EKrjp5HlR9Ohv3/eNc3xlN6yj3SLS/ZLEZcpOeiWafs1N4keENtaW4BqObtoqzlhrA0WYWaLWbQKXvuLo4HY2QkUCuigjhRWhdXM0mHTvS1qwTT2Pu2OLHn+mJhglHjQdRtZwGNnbZ8f0+1HAuKdxaUDdxNxyE07b1sSNODXHaCCcPlB+pAPb8joLfqAJo5MIttaCvRKclv92O6Ziz7W4PGyHvwtD4oMED1pN8PGX9fFhLfxeOIz/gLatc1N/zXwNFkW6FTISaFUspSClVIudyntGvgmSRIP7/a+A//TXwbw6wX6jbuHRZVsFuu4JWyBOK+mEyLIvXhpzDHdU+dVtXGm//BivIoyE="
    }
  },
  {
    "type": "CompositeElement",
    "element_id": "814e7b732931b3f21103f4df3251eb7c",
    "text": "Some studies have explored improving post- OCR text correction by analyzing the visual forms of characters, known as glyphs. Chen and Zhou (2023) attempting to use the CharBERT model (Ma et al., 2020) for post-OCR. Their method consists of two parallel CNN encoders and a transformer decoder, taking CharBERT and glyph embedding as inputs. Amrhein and Clematide (2018)\u2019s experi- ment included NMT models and glyph embedding, but it did not enhance model performance. Other re- search has focused on the detection of homoglyphs, with Ginsberg and Yu (2018) employing a grid method to assess the similarity of glyphs by count- ing the number of overlapping grids between char- acters. The similarity of glyphs is actually based on visual features. In the field of computer vision, feature detection and matching algorithms, such as SIFT (Ng and Henikoff, 2003), ORB (Rublee et al., 2011), and AKAZE (Alcantarilla and Solutions, 2011) can extract feature points from an image and match them with those appearing in other images.",
    "metadata": {
      "data_source": {
        "record_locator": {
          "path": "C:\\Users\\mrcra\\Desktop\\RAG\\test_files\\post_ocr.pdf"
        },
        "date_created": "1729365233.159691",
        "date_modified": "1727326976.0",
        "date_processed": "1729365755.923535",
        "permissions_data": [
          {
            "mode": 33206
          }
        ]
      },
      "filename": "post_ocr.pdf",
      "filetype": "application/pdf",
      "languages": [
        "eng"
      ],
      "page_number": 2,
      "orig_elements": "eJydVsFu2zgQ/ZWBTw7geGUpsq3eUm+3WyzqAEn20NaFQUsjiwhFCiSVxA3y7zsjya6cGMi2pziamcc3M49P+vY0QIUlar+W2eAdDCZJnCebqQgxCUUoLuZpEmbRPMznKKZJHgxGMCjRi0x4QflPA/6xdqa2Ke7/x3Vqkf60gLMwiaZxGEXjSZxMkwkjNEmlyWQuD1mzKJwms+k4OCRU1qTo3BHOLI7HSRjFUcxpFdpSOieNduuO0benAQEzlygKg+nzd0qzmBqbrZVJhTe2oVkJXzDs4t1q9a9D61ar0qZWrFZ/orvzplqtri8/rlYenV/nUiElVIZ+m9SOqywfPD8TMAe0KPm0wVG0i/ld1cREVSlJhxPRP7qwEnpbiy065jxAvR0wUyX1nWu7cF5Y2orO8JEeTMKIwh4fPeONYQhhEEZwBsJ7LCsv9dab2qEvcFEI+/7D9S2PQcGQD6ut4rJUehynBWquRV0InVLdgDp5ddxF0DuO038PZt5n/YpKKQghSInvBq0/DTDrAZDuFIxHvwGTxMftBL+OER2N5LK0BUotdLag+0ObJcm9gBRtShhM5q4mpd5LlvIp5Gl0xG4y/22oOJz3oB6kLz5K7ailLTH9Ur/E3XZBBraikqcx4+ANev8LZh71d7BkQn+jlncmz1/iaUIKIifzk4uYx+ERn+CVNt+on1706q/rjUJkZb1EsU2EepoYuzkJNEuOBzP5dYikr+9LlQpNcamUoPHcGFWzZbhXcujlMXgu3MlOkzB+g+BpJHaiirxpreuS9krZYfPE/nxPREkmMMeLWSbELJ3FExR5MAvjcEpOnwUJ0zmcfGNKBOfrTKKDQtwj4GOljMUMZEkuf0/2Aeyf53C1uAYuA3Jssm1uHzY7EFqo3Q9OI4MDkn9NTpAbWzowOfC1FaknFx/BnTYPGoSDrdpVhRvDgoyK6jP4WpgahuxZfdcEb4B8s8HdOyd01vlZAHoQajxitw3O+MSWJ9Ecwy3dSQv0NixMRny1k843fPyDAZqWUIpQFssloE4J0bqGhwBvhXbMHi1k2IRG4MUd0zlw4NSmB0BaQpZxkNqSuqo9tdUZUJN2sCBubzI/W9X0J3E8ZbTyHPj9ToWpqjMa+fJz16A7dcYINjUle8hkBtp4aA0eu5kQIBPnJ2O4oqFZsHgODoVNC9qtoxmlNM8MaHE80wx9t0YaTGFK0+5lBGxOsHenhsmXuuNPbEgeu6Zj2Foi0g2ZdiXog8C5BtrJUirSrt8xdovLYklNrUlKe7W0IuYUc49W0buYIwxL2egfkPTBCjqHVkPNYk+DS8c5pD21g43outyrkT55aotU/qntnL5tVNbI05S0M6JAmTSI0T61Nxtun1aYFk3Pamvo4KKkKbmaxkpTvfn01y0Ml+2g9r7JsgyisxFcXb+HYetkPcVOJhTi/Mt/Lr9+gGHfXprnB4PpsoHiJBrPl+lAsjJSk6xza0oqogtLxvCTL3datrukDdE9ovGSFrgNEqdpBNKUuDF7z/6DaCmsJcXe4y1bxPP3/wD9H24X"
    }
  },
  {
    "type": "CompositeElement",
    "element_id": "8eac651dd5fc1d4a3824a53b84a38188",
    "text": "3 Methods\n\nWe now describe three common methods for gen- erating synthetic data in the post-OCR domain, be- fore introducing a new method based on glyph sim- ilarity in Section 3.4. Each method makes use of a clean corpus A. As a common preprocessing step, we segment A into multiple chunks by initially di- viding sentences based on punctuation marks and then concatenating these sentences, ensuring that the total length of each chunk does not exceed a fixed limit of 230 characters, with the exception of Russian and Telugu, where the limits are 140 and 90 characters, respectively.",
    "metadata": {
      "data_source": {
        "record_locator": {
          "path": "C:\\Users\\mrcra\\Desktop\\RAG\\test_files\\post_ocr.pdf"
        },
        "date_created": "1729365233.159691",
        "date_modified": "1727326976.0",
        "date_processed": "1729365755.923535",
        "permissions_data": [
          {
            "mode": 33206
          }
        ]
      },
      "filename": "post_ocr.pdf",
      "filetype": "application/pdf",
      "languages": [
        "eng"
      ],
      "page_number": 3,
      "orig_elements": "eJztVMFu2zgQ/ZWBzrFqS7Zk9RZ0F3tqC6QpeqgKgyJHEhGKJEgqiRH43zsjO21S9NJDb3uSxHnz5s3Mo74+ZWhwQpsOWmVvIRN1sd8Uar9Z19ttp+qql6Lp9n1fqUJIuc2uIJswCSWSIPxTxi+H6OYg8fkbDzIgPRbCTV00ZbUryjLf7Jqq2TDDApqc0r3+garLomrqKl//APjgJMb4iqfe7fKmKHfljmEew6Rj1M7Gw0XR16eMiFlLWRbr6vSNYAGlC+pgnBTJhUWmF2lk2ndv2/ZzxBDbdgoyiLb9B+Ndcr5tb67/a9uEMR16bZAA3tG7kyH3qs9OJyLmgBUTV8teRS+xdPRLTHhvNBUnoW8uYSPsMIsBI2vO0A4ZK/V0crDz1CHLLLlGwsfEHCW8xzQ6FTn7mfhWJ4MZwX7dY9M0612Hu60Sqtps9+tadvu9xHK9rfeqxP/3+Ff3aLS9i+cuYhKBtmIVPtLBpqpf7DSH5ULNwfBXnLuIksnzMt9mp98YYjkJf3BdXzroC4J1D6AwyqA7hDQGRJBumpyF6Wwu6F2AAe0KMFCfdoB4tGnEpCXwZkBbykPgKa0+vrsB5Sah7RV0uOJcJEAKTs2ScwVYfLhQQyfIAkClBnP0I0Q9rUAbEXQ6Muunc+tArefwr5Djc94k7jDCHBFcT4zSoLCkOvg5wnUO15EPz034gBezLcoT+it4QIg48NWAaxbnYJpN0t5Q6+NMa4KO6+ukhTFHUHoF91ot+ZSDlth+SvezlWleDEC6AiULq3ggrMiSM8hGy9ToKOJPhitAG+dwjoi0jDC5JAyQ8YY0cmvIPS+SaKhU1LoE+CiRKgvo9SM9jZ50YmxRrgkqgpCJPE9NauJgUk7wizxC3cw0CBoWa7xFMw8zIUcMuEAXMmqAPjfb9QJqXrMGjJ63co/mmL/87XwQgd1xj7dsrdO379rHDyc="
    }
  },
  {
    "type": "CompositeElement",
    "element_id": "945e82f994b9d01184c4851a68e9182e",
    "text": "3.1 Method 1\u20dd Random Injection\n\nThe random injection method (D\u2019hondt et al., 2017) generates a synthetic OCR corpus \u02c6A by randomly inserting errors into an existing clean corpus A.\n\nFirst, we filter out infrequently occurring char- acters in A, as the corpus may inevitably contain some noise. The remaining characters are used for replacements and insertions. Next, for each chunk from A, we randomly select a target error rate p \u2208 [0, 15], which controls the level of noise to be introduced. According to the analysis by Ja- towt et al. (2019), the average rate of OCR errors involving substitution, insertion, and deletion is approximately 5:1:1. Therefore, in our implemen- tation, each character has a probability of 5 7 \u00d7 p of being replaced by a random character and a proba- bility of 1 7 \u00d7 p of being deleted. Additionally, any two characters have a probability of 1 7 \u00d7p of having a random character inserted between them.",
    "metadata": {
      "data_source": {
        "record_locator": {
          "path": "C:\\Users\\mrcra\\Desktop\\RAG\\test_files\\post_ocr.pdf"
        },
        "date_created": "1729365233.159691",
        "date_modified": "1727326976.0",
        "date_processed": "1729365755.923535",
        "permissions_data": [
          {
            "mode": 33206
          }
        ]
      },
      "filename": "post_ocr.pdf",
      "filetype": "application/pdf",
      "languages": [
        "eng"
      ],
      "page_number": 3,
      "orig_elements": "eJztVU1v20YQ/SsDnhKAVvkhSqJvQowWDdAUMNyTFQjL3aG4Mclld5eSBcP/vTMkZcmp0aBFi15yErk7fPNm5r3R/VOANTbY+q1WwTUEZSqyVTFfJWqZLparORYYF3MlVYrpXBbzIISgQS+U8ILinwJ+2DrTW4mnd9xKi/QzAMbLJE8XWZKmszjLF3nMCENQY5Qu9UvUMk0W+XIxi14COmskOvcKZ5llszxJszTjsA5to53TpnXbidH9U0DAzCVNk2jx/JnCLEpj1bY2UnhjB5qd8BXDfrjebH5zaN1m01hpxWZzg+7Bm26zuV3/tNl4dH5b6hopoDP0bKSddaoMnp8JmC9a0XC24NXtdOeP3XAnuq7WlJyI/jBd16Ld9WKHjjkH2O4CZtrRybbtmwKZZso5PD56xqD+wS/oK6Mg3vRJpBTcilaZBn5uv6BkbMY9pbzTvsaAAL6e8DxfYLYqV2W8EnlcZhlGmBZJmWZFtFBCfp/wfzrhWrcPbqzCeWFpKq3CRzpI8oth3wCPOM6hMq3yNI0aZiGD9rbme6k9zhRFLHfYoqW8BD8M+zXoPLsA5fBvYryhwuHE/o0dcSnbuwrBjjrVJ51CM+r43c1Y5VAkoAdRz0JgRu9h4oQOBLhj6yv0WsKvH26BJt31jhoUJXKxhuI44ddHykCD5joArTXW0YE3IFrAR+2Gc1kjvU4Q69mlYz4Jy03Y4x1Tf8M5JGBUkSrLLM+iVIm8SOfFMlqssqzIqRXfnfP/OCdeJReCC0FWfftQWtOsIQTWUMduSqLVPUR0EmdAcN4USOqwRvUSFcxgLbkRpBFvSGyiFfXRaVccP4qvPfOFOnXwLFyF2L1lu3Q+v2DE0Wzhf4CTLV/7N/8Wxr9t3x+1dT6EAwLNzKMF03tyVWnx954gyXNGyt7awVuVsFcgJIWx82AdgnBAzTz5rRFsUdxrLwr6UprWC4pzpkFojXY4g2FdYEPHJ8QJjyqAnvQOpbEU0dVCDt6km1adjE9an8Enoh4OYShkNaoBWA5M6IDnbeHI3pKWDlDPd7R9hp0xCAZOioH7iAVDXT1UmsEMS6Yeq6pxjzWYcuROioIC4aypC0nxHX9xUhUvrY/iCnh2096DdzzE9+EYt6fdt8ORCyXgtfey0fam3jOm6wvaab7nssNzB8KhIYpqG1YtJSOHWfOoGwKjqrPr+DoeGm2RmoT8KU3Vgm66Yd0RLTECTf2bZgCV4GVMWIUodK39kallsORVHKklNY3e2VW704AUFypO+/+MxAwnpCs4Y8VvYg2lDO1USjMxUddHrvII/mAuNVJR3/7M8Iw6gFIQo77Bamwhk0Z/QGx5FM1f/UV8/gO3HaYE"
    }
  },
  {
    "type": "CompositeElement",
    "element_id": "17818758053279aa92138c87d927f0bf",
    "text": "3.2 Method 2\u20dd Image Creation\n\nFollowing some OCR-related studies that add noise to text images (Jaderberg et al., 2014; Krishna et al., 2018; Boros et al., 2022), we also investigate the simulation of real-world correction scenarios by creating synthetic text images. Specifically, each chunk from corpus A is used to create a separate image which is manipulated to add OCR-like noise. These images are then processed through a standard OCR system to obtain \u02c6A.\n\nThe complete procedure is as follows. Initially, for every text chunk, a random font from the set F , which matches the language of corpus A, is chosen. Then, the text from each chunk is converted into an image. These images are subjected to random rotations of \u00b15 degrees, followed by the insertion of random noise pixels. Following this, the images\n\nFigure 1: Examples of synthetic OCR images in various languages, generated using the process in Section 3.2.\n\nundergo random dilation and erosion to simulate text variability, and their resolution are randomly reduced within a range of 0 to 50%. At the end of this process, the chosen OCR system is applied for text recognition, resulting in the output \u02c6A.",
    "metadata": {
      "data_source": {
        "record_locator": {
          "path": "C:\\Users\\mrcra\\Desktop\\RAG\\test_files\\post_ocr.pdf"
        },
        "date_created": "1729365233.159691",
        "date_modified": "1727326976.0",
        "date_processed": "1729365755.923535",
        "permissions_data": [
          {
            "mode": 33206
          }
        ]
      },
      "filename": "post_ocr.pdf",
      "filetype": "application/pdf",
      "languages": [
        "eng"
      ],
      "page_number": 3,
      "orig_elements": "eJztVmFv2zYQ/SuEgQEb4GoSZUlW+inr1qEbtgFt9qkuDIo82WwkUiCpJEbR/747ynaVIgPaDt0wIF9siTw9HnnvvePrdwvooAcTtlotLtiibqVarbMCmgoqUE3R5FnRtFCsi5xXUi2WbNFDEEoEgfHvFvSw9XZ0Ek7vsJUO8C8CZhWv87LgeZ5kRV3WGSHEoN4q3epzVJXzsq7KJD0HDM5K8P4eTlUUSc3zIi8obADXa++1NX57zOj1uwUCUy55ztPy/RsMcyCtU9vOShGsi2kOIuwJ9tnFZvOnB+c3m95JJzabH8FfBztsNi8vf95sAviwbXUHGDBYfLbSJYNqF+/fIzBNGNHTaot7s8e5cBjinBiGTuPimOj3x+lOmN0oduAp5wWY3YIyHXBka8a+AUozpzUC3AXCyBPOfoOwt4rxzchTpdiLHsPZMzpsRCbU04JXOnSwwM8/rm+1qouGVxVfq7Qp23y1FqqGRmG9S8FV8Vjfr1rfTptrP+3CB+GwKkbBHQ6U5azUvwgFDimww0J0LFkS3ug6mpI6QPL2NM/TbOUPJuwhaDmV+z7sejWDpegvh6rTGdSvTvu9EZTfx4jX0xTircdBHuSJh/fRsrS8n9n6C3EyPsP5wTrr/+bQGprjKecCKYecwoo8hMfv58X5p+A8IN044j7DWOdaf267zt4iNPO2B/bHs5dPHHQkOebDqDR4FvYiMIEmYKz2wIJl9DHTZAmefXumEAMM65IlowI/ZcfCzUfXT1k8t9kY598t2S3gq7dMmxsUid7h8rgqMK/7sYtcZ7Zl6ATdk1vrOsVQhKjEOOEl6sZpBG0OLLpF3MyJX/NcE/ZqAIlOIUXXHZYMhNwzuR/NNWud7Ql1GD27ZNqzEc2Ctjr5DxPMAx4yPUYsdrvX+DEG9sLoYZxODOPpnOgQO30N04El7GoPHk7nhZWivRl29iR8dXbc7WmRIIwSLkLgHnyAnkBtE4Q2bDOmXJaXydx+fxcOs9I3cEUFfciG63Itq7xCR0T7bdeylrAuU7RhKfMslY82/G+22X+kVeQRcrQfMA2Y6KNGZBOSUHjWRiEjx18YHfRE8NY6BjfgDpMKItWXSDOHLEO+t9aEiflRbCjK52x5ZHYvgtxH8QM77YxEeNLIkpaVe/RAEwluljE0rhMhZ+KiSIvSdqQRbUglZpLDA9rwY/MWpT2p6ZiosyEetacMUAVpkxVMwc4B+OVx5/gBGgDloA2W/2waE8JkXYO+gw6P6IPphb32U+ZTCp8lrVRCXRarSqhi1aaZ4msh6oKXALxdodQepfXf3HCytJipJmHzxor08lPnSPCa+xX6qd6RJrML9tOdIKlGzn5oR2TsR7ajo99Q50I5nTe4ZDsw4GI3Gf3EUDi1Cvri1bHtYfKf1wdyVQiZq1RlxapORdUURQNV0+b4w9vysQ/8f/rAiDx3u7M7Kn28I+ErA7xe0TOa5/H2dDRloppodKcDNgaKRGJph5cqb7tx+hx5O0F2BxxXI/YXdqvRIs3UM6YOkBJ2kX6TsMsQ2QkIhuNkpSemTpY6tYf5XYZaFZ0YAlNviolRDXfUsyz2EExn7OINDhclDDuGYQyfcvV58xeFJU/3"
    }
  },
  {
    "type": "CompositeElement",
    "element_id": "c68d52467f8c30ef36f249e1b811442e",
    "text": "Figure 1 shows sample synthesized images with noise generated using this process, for several dif- ferent languages. Although synthetic images are used, this method simulates the OCR process un- der real-world conditions, the output text is derived from the OCR system, hence we consider it to be representative of authentic OCR text.The corpora A and \u02c6A can be used to construct test sets, training sets, or to extract distributions of OCR errors.",
    "metadata": {
      "data_source": {
        "record_locator": {
          "path": "C:\\Users\\mrcra\\Desktop\\RAG\\test_files\\post_ocr.pdf"
        },
        "date_created": "1729365233.159691",
        "date_modified": "1727326976.0",
        "date_processed": "1729365755.923535",
        "permissions_data": [
          {
            "mode": 33206
          }
        ]
      },
      "filename": "post_ocr.pdf",
      "filetype": "application/pdf",
      "languages": [
        "eng"
      ],
      "page_number": 3,
      "orig_elements": "eJxVkk1v2zAMhv8K4XPqxXZsL70FHbbbBhTdqS4CWaJjobZkiHLTrsh/H+km2XqyLL56+PLj8T3BAUd0cW9NcgtJvd6U2OqiLaqqNuvNuty22Klqk7dFnudFsoJkxKiMior174kc9uTnoPHyj3sdkD8LMKvzbVGVeVGkWbmttpkQFtHoje3sVVUXebWtq3R9FUzBayT6xKnLMt3mRVmUIpswjJbIekf7s6PH94TB4qUo8nV1emJZQO2D2Q9eq+jDYnNSsRfs3W3T/CYM1DRj0EE1zTek5+inprnf/WiaiBT3nR2QBZPns9chnUyXnE4MloBTo2RLPkXPsfg2LTE1TYPl5Gz0yzk8KHeY1QFJPCfoDok4Hax7po8qKKrAU3EGX/kiy0oOR3yNwkuFMIdBzp09zAFTrSbBp1mylDwxeu/msUWpt1huwr8xbzttNl8zHnWNNZq2bIusbDssv5ZFXmuTnP7L9n3JABlQ748EpMZpQKA3F3sk+wcN2FEqgaONPThvCeGADoPsAMxk3QFibwnOA11B5wMQvrBiAF6CG+hQzMG1KSnshtj7+dCf80SrL1m4DoaiWX1AeRt7b4DsOA+ckPgW4dfd/SUbzO4GDAbgnRxujj4MBrR3xkq7aLXI/RynOYIUDIxktX1h613w4xVHbxRxXEGPTiMcUSBkBWz5pYcWOcMUkLgQnvQLUztQMz93Yl4Qwk8fenkaJh8U7EA5A828znW1A62cUKQ2AQo/hlmLL4rcryhug7JOGvrxy31kJWODYp2x/MC281KZpJekGIIPtGzMZR1/qhAWiw8y4dPTX2HYV7I="
    }
  },
  {
    "type": "CompositeElement",
    "element_id": "d382a02fcc1896c8abb4fab9dc274f0e",
    "text": "3.3 Method 3\u20dd Real-World Injection\n\nSeveral studies have considered the generation of synthetic data through the analysis of error distri- butions in existing datasets. The primary approach involves embedding OCR errors into the data at rates mirroring their occurrence in real-world set- tings (D\u2019hondt et al., 2017; Grundkiewicz et al., 2019; Jasonarson et al., 2023). This strategy ad- dresses the discrepancies between existing datasets and actual application domains, offering more con- trol over the quality of the generated text.\n\nTo obtain a realistic OCR error distribution, in this work we use additional clean corpus C com- ing from the same domain and apply the method described in Section 3.2 to obtain OCR-processed corpus \u02c6C. Subsequently, the Recursive Text Align- ment Scheme (RETAS) (Yalniz and Manmatha, 2011) is employed to perform the automatic align- ment of the OCR text and the original clean text, allowing us to extract the probabilities for character substitution, deletion, and insertion. By adjusting the probability of these errors, we can control the CER of the synthetic data. For instance, if the CER between text C and its corresponding OCR version",
    "metadata": {
      "data_source": {
        "record_locator": {
          "path": "C:\\Users\\mrcra\\Desktop\\RAG\\test_files\\post_ocr.pdf"
        },
        "date_created": "1729365233.159691",
        "date_modified": "1727326976.0",
        "date_processed": "1729365755.923535",
        "permissions_data": [
          {
            "mode": 33206
          }
        ]
      },
      "filename": "post_ocr.pdf",
      "filetype": "application/pdf",
      "languages": [
        "eng"
      ],
      "page_number": 3,
      "orig_elements": "eJztVm1v2zYQ/isHf2oBR7NFS4raT1naFRvQFXAyDENdGJR4stlIokpSSdyg/313lJ3IQfa+YV8KA7HCOz738tw98vu7CdbYYOvXWk1ewKQQM4HVAkWRLLJKFiLJVXwaizkuFnlcZpMpTBr0Ukkvyf9uwg9rZ3pb4uF/XJcW6SsAzrM4F2kSCxHNkzzN54wQnBqjdKXvvTIRp3mWRrN7h86aEp07wsmSJMpjkYiE3Tq0jXZOm9at9xm9v5sQMOciRDxLv3wgN4ulsWpdm1J6Y0OanfRbhj1/sVr95NC61aqxpZWr1St0V950q9Xy7M1q5dH5daVrJIfO0LMpbdSpavLlCwGzoZUNR5scWfc2v+uCTXZdrSk4JfrN3lzLdtPLDTrOeYLtZsKZdnSybvumQE5TcAyPt54xRCTgLfqtUSBWfTxTCpYo65Ofja0VfN9+xJLxGfsQ9lL7GicE8pjlOK7SRU6fmTgtUnl6WmRJVuRZIWWiRJJ8Zfk/ZbnW7ZUbqnBeWmKlVXhLB3E6GzH+CpjneQ5b0ypPdNQQTRm1tzXbS+0xUuSRbbBFS4EJP7D9CDVLR6js/3dATuMRyBvbt+pK440uP3NijwE3IzuX0GJvyesJXNKb4+Tyf4KVj7B+kM600tKf32jdx3uHeBaL3y9fxKdHacbiz6M9sdjhxP4F2R0rwQVeE3YNzvdKo4OtvEYoaTu0QosK/BbhEN+0YCpwu5YOvS6B94ccrOk32+AoW1nvnHbshtYaC0o7b/UJFD1fd6BbwFs6o1rCdYfeRXBJdzurG2l3QINvjSy35Hpt6mtKCalQpfjGu/PlgMtA3oSYIQnpgRIk30azmX3Jpi2Ysuwt9aZEDm1Z426CxlHgE+A0HDx7NaxG2AxAD7KOpsBT/BLGszk25S/hYSRGhlg853KoBVQ3ZbShgtQJKMuq5IaEtSOx62Rbcr8L9DeIT3SFmqlAlr4nckZiAMo0UrduSj2uMFTaGBsoo3qsqcEQoSHQJ7qq/Y7JGLHInBL30Vjbf5SW+b3GS56KJzS+KtRsLrKqSlFWIs6rJFUikynG8WIxT+OvGv//aPw8TUa7HI1kxPWFG17ikYjiJ0U4XYzu/iLrVn+mmXsr24a6IB9L0i440OjPK+n806qeHKvv/I8w/m0xuzRgCk/rATLsOq9U+aAaezUatGjKguB5U0kQruAGoXekYCQ0bKWlK2uULe2V7XoH5/TQnACvW2VNExbKEcX7dRyWlejcBUsz/LRSSJuuSbw41MXABhAb4O/zpNxO7gf6EGzVz+IyPY/ggkn81FM36t00IC+R9MzRpgKvKpzVekN7z5sKF+WWVhaeLV9fnl08h2cDoyGzA6dBuubPQbOodrXZsRgYoH2pjB2Kkr2nirhtcoS9lxDuJPc6gPIBSe1GPzSLbVO6WJsb7hSVQuh0ZknHgj+VWshCkyyx9lFQKLeSrSRZPLFe+z05igRoeOJYJHhowzDDt6yoH/tBLI8xD1JHPA5viSnTWgYW26CN7H/+enmo5/hVFsF3lBCF8qTNSPNR3fsfVDoUfz6kRBJNfJGwd/TeOLydSHvdox/Oj8T1w6+3Kk4M"
    }
  },
  {
    "type": "CompositeElement",
    "element_id": "2ae0243e3f991ffaa41f307f62862ab2",
    "text": "Figure 2: Visualizations of feature matching using ORB for fonts from different character sets, where matched feature points connected by colored lines. For each pair of characters, two numbers are displayed: the upper number represents the Jaccard Index J of overlapping feature points, and the lower number indicates the average distance D.\n\n\u02c6C is p, then doubling all of the error probabili- ties would result in an expected CER of 2p for the newly generated synthetic text. In practice, we set the expected CER for each chunk in A to a random value \u2208 [0, 15] to generate the synthetic data in \u02c6A.",
    "metadata": {
      "data_source": {
        "record_locator": {
          "path": "C:\\Users\\mrcra\\Desktop\\RAG\\test_files\\post_ocr.pdf"
        },
        "date_created": "1729365233.159691",
        "date_modified": "1727326976.0",
        "date_processed": "1729365755.923535",
        "permissions_data": [
          {
            "mode": 33206
          }
        ]
      },
      "filename": "post_ocr.pdf",
      "filetype": "application/pdf",
      "languages": [
        "eng"
      ],
      "page_number": 4,
      "orig_elements": "eJztU8Fu4zYQ/ZWBzl6vRVmylVs22y26hy4QtL1EgUGRI5tYiiRIKo4b5N87I8dJs4e9F+jBsqR5fPM0897dU4EWR3R5Z3RxBYXaDnXZ1Ju1KNttpZVsamx71FJq1daDKBZQjJilllkS/qngm13yU1R4ecadikh/M2G5EW3V1KKqlmXdNm3JDDNo9NoM5hW1qUTTbprl6hUQoleY0jueTV0vW1HVVc2wgHE0KRnv0u5F0d1TQcSsparEqnm+J1hE5aPeWa9k9nGWGWQ+MO3NVdf9mTCmrhujirLrPmP6nn3outvrX7suY8q7wVgkQPB071VcBj0Uz89EzAUnR+5WvKu+1PIpzDUZgjXUnIR+fClb6faT3GNizQW6fcFKA73ZuWnskWWu5zfxbTt9tapwWGPV1+vNIPuqbrXYiqrE9boValOwqIyPmcFfzH6KCOIK/jJpktb8PQtI4AcYaD9cHGVWB+P2MCW+frv9BIOP9HM5wRD9CLSjAVkCqIOMUmWMkDCnBRwPeGFA/coYvOGzyjuHBNbQn+jB+ki31jhMS/hCHVCqAwRpIqt5ZSbWfPRwHkAC+nTqn4KVJ9RXkA8IU6CdvwAgYoiYkPtx7atUSkYNvzmNj/CVmf0DRkvT5497r3AB0un5mPXHN0rjNC8Kz4ySjtNGWESWTiF8XvLuLmv9XcZIM33AP3jkNPsf09RW9VqV/VaV2GKvWhSVFrJuZNv0Za/0/2n6z6Spm1ZCNTdgEoQFm8OB9lNv2VnSWjYbOwZjJHfTrHvZG2s+QDbkpaOfrCa7pslmshhZD/AxnPNx88stHxZhTh5zODzaE+zRkfkYkU6OXmejgMUsyd/UgPJiFFIKkeN47v1vyuESMnWY3Hdueg3Zg4RIvqdcP0g7IXSTEKst3K0WUNb3DLi0nRnfOrMfmOQ8huufxeD+H2iiE94="
    }
  },
  {
    "type": "CompositeElement",
    "element_id": "4ff05d2cc7b99b1c00ea1365e93ea6a1",
    "text": "3.4 Method 4\u20dd Glyph Similarity\n\nGiven that OCR replacement errors frequently hap- pen between characters with visually similar glyphs (Jatowt et al., 2019), we can also use the informa- tion from glyph similarities to construct synthetic data. Specifically, we apply the following proce- dure. Firstly, we filter infrequently appearing char- acters from the input corpus A to form a definitive character set. Based on the analysis of the IC- DAR2017 (Chiron et al., 2017) and ICDAR2019 (Rigaud et al., 2019) datasets, 1:1 mapping errors, where a single character is incorrectly identified as another character, accounted for 87.9% of all 1:n mapping errors. Here 1:n mapping error refers to cases where a single character be incorrectly recognized as n characters. To enhance the compu- tational efficiency of the implementation proposed in this paper, we focus solely on 1:1 errors. Note that simulations of 1:n (n > 1) errors could be achieved through random insertion.",
    "metadata": {
      "data_source": {
        "record_locator": {
          "path": "C:\\Users\\mrcra\\Desktop\\RAG\\test_files\\post_ocr.pdf"
        },
        "date_created": "1729365233.159691",
        "date_modified": "1727326976.0",
        "date_processed": "1729365755.923535",
        "permissions_data": [
          {
            "mode": 33206
          }
        ]
      },
      "filename": "post_ocr.pdf",
      "filetype": "application/pdf",
      "languages": [
        "eng"
      ],
      "page_number": 4,
      "orig_elements": "eJztVd9vnEYQ/ldGSJVs6UwPOMD4oZLrqG4rNZUc9ylEp73d4dgGdunuYudi+X/vDPjis2OrSqW+9QnYmf3m++YX7+8i7LBHE9ZaRWcQrVQlKpklRbnKV4USIsnEaYFNtVJitcxVtICoxyCUCIL87yJ+WXs7Oon7b1xLh/SYAJMyrbIiT7MsTvKqqBJGmJx6q3Sjv3iVWVpUZREvvzgMzkr0/glOmedxlWZ5lrPbgK7X3mtr/PqB0fu7iICZS5aly+L+A7k5lNapdWelCNZNNAcRWoa9OKvrPzw6X9e9k07U9Rv0H4Md6vrq/LKuA/qwbnSH5DBYerfSxYNqovt7AmaDET1Hi55YH2xhN0w2MQydpuBE9PsHcyfMdhRb9Mw5QrONmOlAJ2sz9htkmiuOEfBTYIwsXsFvGFqrYFWP6VIpuOx2QwvvdK874XTYMe4+5LUOHUYE8LzCSabyNMkLLrLKsySrSllgKjfFZpkm1eb/Cv+nFe60+ehnFT4IR1UxCj/RQbLMDqr9K+m4DVSGDuIFo42u43OpA8Z/TsZ0mVQKcZiL/AwsOT0AY89vx1glxQHGRaudNa8QkpORwEotlXD88iJiljxlVf5boDw9ALrSWzGqV6i5ycg6J8QX0YryH5L1FcgLszqduG/YpIfDfalv0EBoRYDfL67A4dAJOU0toHPWeWgc/jXSd7eDVgwnMJD/BsMt0lO2wgkZqMfhVocWbrQfRUeefl4NsOVF4eFo7irAAKKLF8CCjhdwiyCFoSNvYfRINBC0aazrxQlwR1Nw288ge0gdNHoIFiRNZnCjDOB3hm4GLYEHNYZ3A0oaf8lMpiA8I7sJvbFdZ2+12cK0AU5AjQ5j+Ek7Hx6cabhIEPN4FE4ASKHpGis+gQfNE7uZ9DAGYuSG0cM5s2MRIEBhow1RvsHHXIHHEMOPgrYPWDPdF0Z0O6892Gb6/uXiBN6cX3EXwtE8AIe5K4/phiKv2aeCo7kTn+Z3ygbF8gtIzhLoSQQrmMtKUlt0FJnyarbdIT2ioQ1podXG2rWiHEzbFISnuJYIukf3BSVD2tHQTmbRcFrG1Xesg7JPcc2zuDH8zGG/MlDnNZxSLiyR9q/T2+ATeryAt0Z/nukdtmQM1xbQtMLIubWk7YeRGmtaljSz2FCTaDRyt8+77of5lzW5cI/Q6iVkzWWivAxiYMXcJVZSqb3tkDiQK2d4r/CtDTiPFPXs2E1YU2lZ9ZGBHyA53k8Xpa5TrEnQBsIbihVaZ8dtC45KTO2lDf1CGCE+/Mm+Fc4JbqtrnuP7D38DZBQJeg=="
    }
  },
  {
    "type": "CompositeElement",
    "element_id": "574531e9698469d1fef671dcbf380f1e",
    "text": "For each language, we select a set of appropri- ate fonts F , which includes a variety of historical and modern fonts, and employ a set of vision fea- ture detection algorithms Q to extract and match image features. In our experiments we consider ORB (Rublee et al., 2011), AKAZE (Alcantarilla and Solutions, 2011) and SIFT (Ng and Henikoff, 2003). For each character i in the character set, we calculate its glyph similarity with every other char- acter j by creating their images using fonts f from the font set F . We then calculate their similarity under detector q as:\n\nS(i, j, q) =\n\n1 |F |\n\n(cid:88)\n\nf \u2208F",
    "metadata": {
      "data_source": {
        "record_locator": {
          "path": "C:\\Users\\mrcra\\Desktop\\RAG\\test_files\\post_ocr.pdf"
        },
        "date_created": "1729365233.159691",
        "date_modified": "1727326976.0",
        "date_processed": "1729365755.923535",
        "permissions_data": [
          {
            "mode": 33206
          }
        ]
      },
      "filename": "post_ocr.pdf",
      "filetype": "application/pdf",
      "languages": [
        "eng"
      ],
      "page_number": 4,
      "orig_elements": "eJztVm1v2zYQ/isHfXIA16Op9wD7kL14KwZ0WJpiwKrBoMSjzYZ6KUklzdL89x3lJFW2rluLbUCBADZMHe+ee3j3HOWX1xEabLHzWy2jY4iKmCF9eZKjzBEVpklSZ5hkqNK0TptoCVGLXkjhBflfR2Gxdf1oG7x7xm1jkX4mwHXOyzhLeRyv1mmZleuAMDm1vdRK33vlMc/KPFuxe4fB9g069wAnT9NVyeM0ToPbgLbVzum+c9tbRi+vIwIOXOKYs+zmV3Kz2PRWbk3fCN/bieYg/D7Afn1cVS8cWldVrW2sqKpv0J37fqiq05Pvqsqj81ulDZLD0NO6b+xqkCq6uSHgsNGJNmSLHuze7vmrYdoTw2A0JSeiX9xuG9HtRrFDFzhH2O2iwNTo7twdTuG8sNSVTuIbMvCU07bHNz7gnY61QaQ2GFgtA9poTbA32uPKTpucrde9rSOi+SesLJ9hBcePhyjYDGIBopPPezOGAzpYQoiEo8n6dHMGC3i2o/X32OnzXqk/ZhOmER3Ba2NEiFTC+fcmLZNZ0nnKT0WMWfk3lfjHSDydIX3wuN2OMxY7rd4PlPAHlFj8ofigmYFUtO3GtsYg7WSy2HcTnchSlE28zvIkTTIpxDoWBY1zmUiRsFQGEvf5Nr0FFM0e7uS5hEsER3dE40HQwkOvgORs+8HqJ0BjCqrvvIMNtf1yrylUd40ZJTryv6DC0RCEmL12NHs0BCbIAsKM2u4Qu5ws2A6mv3qX5EKHuQaF4gn40SJI9MQi2ITZEZTftw5+At8DkbciEAzAwgcOLXEPsSHSreBpB3RFkSPdGDpcdy6cqyHpaOIBP55+BYvDUAFlF2Z10PDREk5+OPnlW1iczHQw5bnX3q3nwTip/dluerjrf3Bg8dEK7ovb7EXgS4k1VQv8HmcmOv5UdKpUM5pQYE1sd+Zq2IPTrTZEgkp6SecHvEBL1SUAOyFQQyaMV1BfwXQJ624X8LU9lMTB6ILp0DMFyvbtlD8YpspvYAU/Y7B1MwoHiFn6sQt1O7SEjvUahDsOQr278Z4Jayn7BZ4FZU06f/iiyZRUSaqkzMqUScZZXrOGJ0XBsgzLdfn4ovlPXzT/5qXxfKGX8GoJr4/gy7kGXnTEBMOo/obyr3QgWcobyVTGSy6pjjFmZSkLltZxoyjbow4+Gx2s4e0G3n6CAhgrCswZ1nEueJaVdRI+slQFYl0/KuCzUcCi0fK4KI4+WgMlp0u/FohxLWuV1LVSOa855cVinar0UQP/pwbmLVVQjZyzYjPv6Zn2Bunf5++AKYHv"
    }
  },
  {
    "type": "CompositeElement",
    "element_id": "b169a87e8d6d8103be639b5761961036",
    "text": "J(i, j, f, q) D(i, j, f, q)\n\nFigure 3: Visualization of a glyph similarity matrix for English-language characters (52 letters only). The saturation of each cell represents the value Snorm(i, j) between each pair of characters i and j.\n\nwhere D(i, j, f, q) is the average distance between matching point pairs for character i and j, using font f and feature detector q. The degree of over- lap for feature matching points J(i, j, f, q) is calcu- lated using the Jaccard Index (Jaccard, 1912). This is defined as the ratio of the number of matching points relative to the combined number of feature points in i and j minus the number of matching points. A number of matching examples are shown in Figure 2. We see that, as glyphs become more similar, J increases and D decreases.\n\nNext, we perform min-max normalization for different mapping types and characters to obtain the normalized score \u2208 [0, 1]\n\nSnorm(i, j) =\n\n1 |Q|\n\n(cid:88)",
    "metadata": {
      "data_source": {
        "record_locator": {
          "path": "C:\\Users\\mrcra\\Desktop\\RAG\\test_files\\post_ocr.pdf"
        },
        "date_created": "1729365233.159691",
        "date_modified": "1727326976.0",
        "date_processed": "1729365755.923535",
        "permissions_data": [
          {
            "mode": 33206
          }
        ]
      },
      "filename": "post_ocr.pdf",
      "filetype": "application/pdf",
      "languages": [
        "eng"
      ],
      "page_number": 4,
      "orig_elements": "eJztVt9v2zYQ/lcIPSWAo5nUD0sB9lAs27A8FNiWbg9xYJyoo81UElWSapKl+d93lO1UCbp1AbYVBQwYsEjefXfkfd+Rl/cRNthi51e6jk5ZBLnKAVQ1L0VRl2ma8EWVi7qUFS/LRIloxqIWPdTggezvo/CxcmawEvdjXEmL9DcC8oUokzwTSRLzrMxLHhBGo9bUWulHq0Ui8nKRx/NHg94aic49wVlkWVyKJEuyYNajbbVz2nRutcvo8j4i4JBLkoh5/nBFZhalsfWqMRK8sWOaPfhNgP3udLl849C65bK10sJyeYburTf9cvnLqx+XS4/Or5RukAx6Q99G2rivVfTwQMBhoYM2RIuerO7W/F0/rkHfN5qCU6Lf7JYb6NYDrNGFnCPs1lHItKeZVTe0FYY00xDD460PGOdHesauZ0zN2LtjdjYdBbx9qAvtG4zI8Xlls7qoqkrwPJMypcMGKOdCSp4VeYKyWBwq+39WdpyxL9DdlAo/6PVgkSWn7DftBmj0H2MCzCgGbN3c9RvmdKsbsNrfsRa81bdMGcu+79aNdpuTfYpMbsCC9HRK7CgTjPY1fpuuuTuO2cUGmQM/2Ed4BLlhEpuGWewtOtqAY57M3kMzIPu1M7YdmXnMKvQ3iN3WpQdtg/8knmbQ1ew6npL3NdgQ6z1ehJ1+gsSpUHkuRJmiKOcgZJlAxesEs6TiIuMHEv+3JG5099Ztd+E8WKpKV+MtTYh0Pm1VICXYOuAMtgkzUnuMr7fTXGy9xvI+hyknMLzk4uUYaZ5PMOIJgBplE0vow05j0tS/LcybDZIun/RmprcCgfdog+JqTel2Eh/1QfKUG92tWW9050eluFGsj1rZS2XGBhcMlSE7Nc4pDPIkVPQoiTzs3Va1Na4tYlCcobgnrIF+xNzbPw3q2PnzlCU0cgh+pJNd2LCLXWXZT+Gw2dFuOGOhVGPDIFf61ah0R46w3fvYP0IyYbA96jB6noTFZhQ/82a0lKatRpiPLvv8dx66258Na3U3uL8PELNXn1rEW2h7UhCjsjO3MTddwN31WBGz32mWztJvwM/CjsYG66h+lB+dpAle2247Y+fkGrqLC3CU1xkdxW78skaXL0DVc4REcSgV3dmJKDioUlS8KoQ6NLqv57Z+Tf8zdkOkRUsabANVT1q4ZeGy/Hh5B3lSIRSGOMTOvh9FR5lvqTS5OkkfpvJALB35voMhoTgZ2LgchJgX7JJaMr96GesUFSulqvJqoQSfq7yoeUE3bTGvsixJD6z7Uq//6cvq23/03odiUfNUFRXneZpIhchFAnVKr6ZMYXGo5RftIJ9V2rT4nH34+cO06G86SgHXxgbV/5WYBc4TCSpJsQAArFWeFnldpBXNlXRvHwjw1RDgSOr6tCiOP8OBqz8BbAKpYQ=="
    }
  },
  {
    "type": "CompositeElement",
    "element_id": "9db255e2b11da4e07912e3ff6b7fbef0",
    "text": "q\u2208Q\n\nS(i, j, q) \u2212 min(Siq) max(Siq) \u2212 min(Siq)\n\nwhere Siq is the set of similarity scores between character i and other characters using feature detec- tor q. Figure 3 presents an example of Snorm(i, j) for English-language characters.\n\nThe technique of embedding OCR errors by ex- ploiting glyph similarity shares some common as- pects with the random injection method described previously. Firstly, we randomly select a target er- ror rate p \u2208 [0, 15] for each chunk from A, where each character i in A has a probability of 5 7 \u00d7 p to be replaced with another character. The choice of replacement is based on Snorm(i, j), with higher- weighted pairs being more likely to be chosen. Af- ter replacement, each character has a probability of 1 7 \u00d7 p to be deleted. Any two characters have a probability of 1 7 \u00d7 p of having a random character inserted between them.\n\n4 Datasets\n\nIn this paper, we undertake post-OCR experi- ments involving English, Frisian, German, Ice- landic, Irish, Russian, Spanish, and Telugu texts. Clean corpora A for these languages were obtained as follows: data for Icelandic, Irish, and Frisian were sourced from the CC-100 corpus (Conneau et al., 2019). Telugu2 and Russian3 datasets were obtained from Kaggle, while English, Spanish, and German were sourced from Project Gutenberg. Summary statistics for the corpora are given in Ta- ble 1. The amount of data selected simulates the real-world rarity of these languages to some extent.\n\nLanguage\n\nLength Source",
    "metadata": {
      "data_source": {
        "record_locator": {
          "path": "C:\\Users\\mrcra\\Desktop\\RAG\\test_files\\post_ocr.pdf"
        },
        "date_created": "1729365233.159691",
        "date_modified": "1727326976.0",
        "date_processed": "1729365755.923535",
        "permissions_data": [
          {
            "mode": 33206
          }
        ]
      },
      "filename": "post_ocr.pdf",
      "filetype": "application/pdf",
      "languages": [
        "eng"
      ],
      "page_number": 4,
      "orig_elements": "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"
    }
  },
  {
    "type": "CompositeElement",
    "element_id": "1bb8ddacdb7f19cff1b5f719f3a12373",
    "text": "English Frisian German Icelandic Irish Russian Spanish Telugu\n\n27,883,394 Gutenberg 3,426,499 CC100 3,758,352 Gutenberg 3,147,864 CC100 5,090,436 CC100 6,613,093 Kaggle 7,813,245 Gutenberg 5,777,551 Kaggle\n\nTable 1: Corpus character counts and sources.\n\nAll training, validation, and test datasets are generated from these clean corpora. The training data is created using the four different methods de- scribed in Section 3, with the aim of comparing the synthetic data generation techniques. To imple- ment the method presented in Section 3.3, 20% of the text from each language corpus is used as C for extracting OCR error distributions. The remaining\n\n2https://www.kaggle.com/datasets/\n\nsudalairajkumar/telugu-nlp\n\n3https://www.kaggle.com/datasets/d0rj3228/\n\nrussian-literature/data\n\n80% of the corpus is divided in a 8:1:1 ratio to generate training, validation, and test sets.\n\nThe test datasets are generated using a method similar to that described in Section 3.2, employing the Tesseract OCR system (Smith, 2007) to convert synthetic images into OCR text. Since the methods described in Sections 3.2 and 3.3 involve using an OCR system to either generate OCR text directly or to extract OCR errors, the Google Vision API OCR system (Fujii et al., 2017) is used when creating training and validation datasets.",
    "metadata": {
      "data_source": {
        "record_locator": {
          "path": "C:\\Users\\mrcra\\Desktop\\RAG\\test_files\\post_ocr.pdf"
        },
        "date_created": "1729365233.159691",
        "date_modified": "1727326976.0",
        "date_processed": "1729365755.923535",
        "permissions_data": [
          {
            "mode": 33206
          }
        ]
      },
      "filename": "post_ocr.pdf",
      "filetype": "application/pdf",
      "languages": [
        "eng"
      ],
      "page_number": 5,
      "orig_elements": "eJztWN1v2zYQ/1cIAwM2QJElUl/MW5GtQTFgG9p0L3VhUNTJZqOvkVTSrMj/vqNkJ3LqJu6wNX2wXyyR98n73VF37z7NoIIaGrtUxeyUzGQayjLkkEKalFESMpGUQgRJmYZpJsp85pFZDVYUwgqk/zRzD0vT9lrC9h2WUgP+DQLDlHKWxJQxP4x5wkMnYSCq20KV6o4qZTThaeIHdwSdbiUYsyMnjWOfUxaz2JF1oGtljGobs9xY9O7TDAU7WxijQXL7Hsk0yFYXy6qVwrZ6MLMTdu3Enp0uFm8NaLNY1FpqsVj8DObStt1i8frF+WJhwdhlqSpAgq7F51ZqvyvK2e0tCnYbjaidttnO7mbP3nTDnui6SqFyNHS+2a5Es+rFCoyzeQbNauYs7XBl2fR1Ds7M2Omw8NE6Gb80q0qZNXmplVGiIefoO/69koCiCiXJK+22X/dm2H7Tica9X0DVr3qncWvMhbIVzFD0w9gzQSMoi0IkHCJ8SuMsjmgocl5GEcLhGPtvGfthRX9FZk7BQlMvy5jHeETOewsNylwR5kU08SLOydlZGAT4jhH2WEx3aMIIeZNoQxN7AQ+8iCWb98RDzbjGyK9itaqAIDEu0CieCIm9NE29OA43RFP0vW3wLGDVavU3FBfO3D1ILAqIsjJLOU0ynjIWBkkMZVgWiQx4LOIjEp+rCl2IHIMenpKzVne9IXIttJAWNJFt31hDsBaRMRDGP6jqxJwFeKCIbPwrsyzJBMszJvF4eZqx443z/8a6Us2lGb0wVmiMSlPAR1wI02ASd89J6HXlng1IJ9dnYzh32WiWTdh8wqaMfX7H67gPqHpPVoIpOF9UFbFaqEY1K49ciUoVwwl4AyrdwRIXMwMOpxrIChrQDjak1G1N7BoMEFkBXp8Yvq7VwicXa7iTOXAThagf0UZ641aRj5SIR4LoKsEZTxCw67YwpIATYqRWORIrvJRH77HKkmtl1wOnUDVpS1RYo+NbceamwT+Lt/qgcmOoY7Ug1436q8f0IhctUXVXoQ6XTwPjqJh0Gl1p7AOtPuqlwQ9OnaN1xzZ6DkKuyRYfg++Y2uhnj6lAhCFn6J8mSO5y3dn4+9lrAlq3zmdj0b/eaTDjcWmox/Oa5v9vQjsPruBLNT+WGQ8LWkZxwktaxGWeRJkMaBYkgcipPNaB56kD0ypA19Z2hpzO5+T6+pr45HL8CPAdfMn8LrsmOT9wIAPS+yO1j7TzLeXc9IWohNLiw2VfCz23w/fqSVN1e+vD7WfWPCL7oPsn45lMAybyGG8bFosgB0rjIkrxQ1jkZXjE3fPj7gFIEGkjTMjJt0HaI6yHQEwUAc+AF0Eg45RlLI4g5CULy0jmwKMjxL4DiLEDS5t7DPQHRmn2Fdjbssz12J6fVMq6G73XMBA9iUB2sIaDEAlBJrNQCl4gDmXKAsC2T4SBiAoep/z40f0dIHIDFXJC7sFC5t8SdF/iO6jmZSIrAX9hUeY0SaEMaCKx4vE0ZwlPjgh7zmHSk/k/hUF23zLctwaFulLF2F8Ikp2GpyEZOhRi27u+6qlmzKF0Z0jwZJMQJgGDIhecJ6lMGORJypIsYiWwJI8lO6LqeepWFu80/fRLTT/dNzII6ZT7TY2d8YRfYvHxjVukQZC2V6CvFFzvlcPotDtA6n8lhtKpGP+rXKEsOIR37+SExdPJycv+g1KI5Ir43kM3SrdHgzA18FcPjYS94tLd0wg/O409Yv7r0jFMTx6Zu4wDFLEdWxhVqwq/77GG2LVALtg3PPHRMai7qr3ZjksuXB662cQwmDA3xkJNfhyQ5CYeQfqTEynbBsNuJ8MVVTuIo3DcdZzObJ+8UXgWk2mK2WuHcYYMtQzjietXbXUFW4eaqSEoHNAS0PeFcasMyyhmv61uSDt4vRmx3M9XjDcYct627mP0T+WKCXnxx6sdRwesELBEVL7zN0R/t9Ob6zU047xqOKztJMvZfV+T78LzWDV+/w+Fpfl8"
    }
  },
  {
    "type": "CompositeElement",
    "element_id": "a8f8794444b65497c026314c052500ce",
    "text": "5 Models\n\nIn our experiments, we compare the performance of various models which have been previously adopted for post-OCR tasks, including models that operate at the subword-level, character-level, and byte-level tokenizers. Additionally, we evaluate current SOTA models which is based on n-gram and majority voting. This comparison encompasses both pre-trained models and those trained from scratch. Training parameters are in Appendix A.\n\n5.1 mT5\n\nThe mT5 model (Xue et al., 2020) is an extension of the T5 model (Raffel et al., 2020), which is pre-trained on a multilingual dataset. This model leverages the original T5\u2019s text-to-text framework, where every natural language processing task is reframed as a text generation problem, allowing for consistent and flexible handling of a wide range of tasks across languages. The version we use in our experiments is mT5-base.",
    "metadata": {
      "data_source": {
        "record_locator": {
          "path": "C:\\Users\\mrcra\\Desktop\\RAG\\test_files\\post_ocr.pdf"
        },
        "date_created": "1729365233.159691",
        "date_modified": "1727326976.0",
        "date_processed": "1729365755.923535",
        "permissions_data": [
          {
            "mode": 33206
          }
        ]
      },
      "filename": "post_ocr.pdf",
      "filetype": "application/pdf",
      "languages": [
        "eng"
      ],
      "page_number": 5,
      "orig_elements": "eJztVstu4zYU/ZULrVrAVvWwJHt2xhQoumgHSDNAgfHAoMgrm41ECiTl2BPk3+de2U6cwC0w6GuTlSTyvs8hjz49RNhihyastYreQVRVuUwzLItkkTZJnqrFDMt8Xsp6hk0t8mgCUYdBKBEE2T9E/LL2dnASz9+4lg7pMQZMq2yRl0WW53FaLMpFyhFGo84q3egnqyrPykVVxsmTQe+sRO9fxKmKIl5keZEXbNaj67T32hq/PlX06SGiwFxLnmdJ+fiZzBxK69S6tVIE68YyexG2HPb9u9Xqo0fnV6vOSSdWqx/R3wXbr1Y3y59Wq4A+rBvdIhn0lt6tdHGvmujxkQLzhhEdZ4te7J72wqEf90Tft5qSU6E/nLZbYTaD2KDnmiM0m4gr7WllbYauRi6z4BwB94FjFPAL9dV6dj7HvdWhxYisXsMoZqpciFTN5lLJBguV4SzPqnJWJfM6LeQbjP8qjK02d/7YhQ/CESpG4Z4Wsnl6AekUhFGd+MM6HQ47G7TZQAy1DdveIUzBUydBbmnt1gltaLsXjuoM1KhwqM2y79EovV9yKYNrT0WOa/EyerxCqXHFfcOBv+TgzwaIIoB7Qkwz3fwE7hGk7TgmhC0C7TTWdcJIBNvATjhtBw/dyF2432rqZyt2CDWiAepzx/vtAYSyPZENyBsYhOmH9zcQhL+jHNrIdlA8nlOcsBUBLOUiggG9cmY/1PfEj2mLO2wnILc0K0mjOi/QrKE+BDx+Q7B3aPQXGmUMS6U0oyra9jB2hDvRDhxbDo6HBb99uF2+bEJ7qAWxGqwBM90QLmOGM5xwxJOg25LlcULaky2a8YMOhB+h5hlMA+NLsU4ZOFDYWk8jPW00znZnPjzTAZ75AAyANnCmBCzjy5viV+HIV+/wlqG8cmOk8wYXxSxVSa6ETBI6xI1ayAqTvEhlXb3dGP/lxf+3TmkRp9DdFpfwfzRUBG6ImV9Q/RkF8oqwl6XK57kq5UwKJQtV1g2WaT4rxeyNAv+PaKTFBbi/D0gQtBBPLu58qQPG+wGzJEu6UBzBfaU81UUQtvs297K8cL8RTUPUuV6GGzc5FMlES4yj9q4EfCGE1+q5GuefPiq3pBt0VI73LnxHwwUMINp4Apz5e77lBd3Z+4CGqcaSxlrz7HKcxUuvybNEXF7u5C6gG9qgCWoiQAvMW4/hJBLHiKxOjskxJqK+N5p0iTKuhixJF7RM1UyDnfKTdIEoSLJ3xznRsXKhO4ARYXDkdWYanM4TawZrKpfmcHRWIKjHMSps0LCkcqPkUNPtQLLZtvae/ViYJZ027QMrImtU0+JekxkpulHcFM9HwL1WCI5Sj78Ao4aDkM56/1SQ554RqNhxrCS5gx/169X/BRdKAE1Zav9K0D5/BRoUJiY="
    }
  },
  {
    "type": "CompositeElement",
    "element_id": "9a8284eda3023ed65831f70159efe56e",
    "text": "5.2 mBART\n\nThe mBART model (Tang et al., 2020) is a multi- lingual extension of the BART architecture (Lewis et al., 2019). Developed by Facebook AI, its pre- training approach involves corrupting text with an arbitrary noising function and then learning to re- construct the original text. mBART is also pre- trained on a large corpus of text in multiple lan- guages, making it adept at both high-resource and low-resource language translation, as well as a vari- ety of other language processing tasks. The version we use in our experiments is mBART-large-50.\n\n5.3 ByT5\n\nThe ByT5 model (Xue et al., 2022) is designed to address the limitations of traditional subword to- kenization methods by working at the byte level.\n\nFigure 4: The structure of the CharBERT post-OCR model incorporates glyph embeddings as inputs. It con- sists of two CNN encoders and one transformer decoder.\n\nThis approach allows ByT5 to handle any language or writing system with Unicode representation, making it naturally multilingual and adaptable for handling a wide variety of text data. By operating on bytes, ByT5 avoids the complexities and biases associated with subword vocabularies, enabling more equitable and accurate processing across lan- guages. ByT5 was pre-trained on the same dataset as mT5. The model demonstrates robust perfor- mance across a wide range of tasks (Stankevi\u02c7cius et al., 2022; Jentoft, 2023). The version we use in our experiments is ByT5-base.",
    "metadata": {
      "data_source": {
        "record_locator": {
          "path": "C:\\Users\\mrcra\\Desktop\\RAG\\test_files\\post_ocr.pdf"
        },
        "date_created": "1729365233.159691",
        "date_modified": "1727326976.0",
        "date_processed": "1729365755.923535",
        "permissions_data": [
          {
            "mode": 33206
          }
        ]
      },
      "filename": "post_ocr.pdf",
      "filetype": "application/pdf",
      "languages": [
        "eng"
      ],
      "page_number": 5,
      "orig_elements": "eJztWG1v2zYQ/iuEP6VA7OmNeuk+pek2dBg6oHOBAXURUNTJ5iKJGknZcYv+991RTiMHSbusa/slX2JbpJ57eLx77i5v3s+ggRY6d6Gq2VM2q2RcJVlVcEjDKAvKrIigLqCGKk9ymQazUzZrwYlKOIH738/oy4XVg5Fw/RsupAH88IBhFhVxyqM4XoS8SIuQEPymVleqVh93ZXGUFlm6CD5u6I2WYO0RTsb5oohiHnPa1oNplbVKd/biwOjN+xkCE5c4joL0w1vcZkBqU100WgqnjafZC7ch2POnq9VrC8auVq2RRqxWz8FeOt2vVq/OflmtHFh3UasGcEOv8buWZtFX9ezDBwSmhU60ZG12tHpYc/ver4m+bxQaR6I/HJYb0a0HsQZLnGfQrWfEtMcnF93QlkA0OdlwcOUIgy8i1j47e7Wkt6+Bl8o1MMNtt+8xTkVUAFQZFBCnYZ7VeZGWUVJGcZ4KUT3e41e9x0Z1l3Y8hXXC4K10FVzhgzCbXOkS38U7aNjilKAG09BTqRwsHC5FQRS0Q+MUoqGNZrznY7w4mODRC/8VqAgnQCfsQItFQViwJwv2HLbQ6B6qcv+zkFBqfXn2gp0y5Wxv4LbRBnbK0qslmrjTWj6xdo8LPgsSBunR4cPiMxB3ZJh/Yh6gf9OUXG5gTElGodqwE7pQdB0TjXddFDxhyjLBvPPn7OB+hq9DR9HOdM0cgngMYeQGSUs3GGAnvxH1CVZYTG+BlXt2fQ/s7IW/B4YXMWfOCNWhHYaxarSQG6a6rW62YBkmjxl6R4t0ArZTbsNEh4ZLha+ZPeu0srRcD52kIMfVigh2rAFhPKzTjMxITFVnBuk8f23UWnV4MsJdHHxCJ2+sntBC3oTJGmHWQHT6wXoXEBvVjW7qG8AN3ZyNaXXKWnFJhhW6ooIe/zpWamS+UevN3MCoWZ5po3c3D64Tk0x3tvFJe8qEZTtoGvoUbCsM3gpmN5FASDA3bx1Eyx9Z2Eu7YHTbW1QY8ssO2GCBOKMxvE8UMEXqa+nU/vhzf8g5DxZTvX4pjEEmW1hSCN2h21DwMJdJxEWY8yDJEy6yTBZ1UgdJVhf1o25/y/r7RerAFzF7tl/y6f2/7pAFrDFf3kF1XwwEUZbKMg1KkYokTCDkOS9EVoR1zauAP/Zg36t2T8vNnwPcU7euBkDpj8q943dVrSg/KlpR9Mn3v0bJoqC8rlh4jGnBinzBqsCqNak1ir2oKpRU62W+Ua1y3oOjbBtRKfqFbrBDucP7xTfm7BI69c5vYximG11ZKle47HVcjCUDj4eAVM8eJpBhwnmSlllV57yuRZ6mePpUJgGkHMqofEyObyiQ6RfF4s9qTa1O8tSX1rGdoAeHpuh8I8yzn7CRIOLz389fHWJWddQ5aAwT7GnWzb7fMEA+VYXRZamwq64fHBbsF47alDmzyroxYHeanb98yQARKnSpbxp0d2gRam1a7AAq8IsPLNsxCJ7wSEZBEItExiLnoSxynoYiyXn+GJXfR7KTbKrZJ7elFjd3l7BVW6kGS/JHLTJ24BhJd0l3cjQk3SP/D8YsPlMPHgjIAz4B/BVjVNfuNuZf42NEi9dGtC36WN49F/IwOeYX/1us/1sulhuaKK6nGtFgt2/HWoZlaoOp3NAUsL9p4bVhO6P8vGP31kE7TjyvO0UZjmMMTiYWyRxGg5s5oxOoQ2hgz6ZTs1cLzODeiRJNoVyMVn1RQ2iEpIHiME74mYaSa4EcGc5sJCC4E4silT6cazx1sdWqGqur1C3OPldIGEZlKpWw9NVaLRUJw8j/utRuMS/LoSGTiIYJVXoqrUYJhb8HNdL0pKUcSC6nQ42QRmNZn0xai5HRToyT5GRiI3YW89Wfx1K7gEPOko8j0SjKFbR+IvSibHQ5WMfwzOikOTq2owFtNHjwlKF/fXg/0XDFTv44BPlqCCKZUaQftSU/skMg+5/xkwdMY3SoeYm0P6Xob/8BTEzJdw=="
    }
  },
  {
    "type": "CompositeElement",
    "element_id": "974170bf22312244a00666c344b25e0d",
    "text": "5.4 CharBERT + Glyph Embedding\n\nTo verify the effectiveness of glyph embedding as proposed by Chen and Zhou (2023), we also conducted some experiments using their model. CharBERT (Ma et al., 2020) is a char-level model. In the pre-training phase of CharBERT, one of the tasks involves text denoising which is closely aligns with the objectives of post-OCR correction tasks. Building on the original model, Chen and Zhou (2023) introduced glyph embedding to CharBERT by using a ResNet50 model (He et al., 2016). This supports the extraction of visual information from characters and serves as one of the inputs to the post-OCR correction model. The structure of this model is shown in Figure 4. In our experiments we use the same structure and fine-tuning settings cor- responding to the optimal configurations reported in the original work. Since the CharBERT model was pre-trained on the English Wikipedia dataset (Foundation, 2024), we conduct experiments only in English with this model.",
    "metadata": {
      "data_source": {
        "record_locator": {
          "path": "C:\\Users\\mrcra\\Desktop\\RAG\\test_files\\post_ocr.pdf"
        },
        "date_created": "1729365233.159691",
        "date_modified": "1727326976.0",
        "date_processed": "1729365755.923535",
        "permissions_data": [
          {
            "mode": 33206
          }
        ]
      },
      "filename": "post_ocr.pdf",
      "filetype": "application/pdf",
      "languages": [
        "eng"
      ],
      "page_number": 6,
      "orig_elements": "eJztVk1v4zYQ/SsDnRLUUW192nvrptndHnYLpC4W2PXCoMWRxUYiBZKyYwT57x1SciKnXqAp2ltPksmZxzfvDUf++hBgjQ1KuxY8eAPBrCyTZJMuZjyP51kasTjd5Byz+SJJ+TTaBBMIGrSMM8so/iFwL2ujOl3g8TeuC4306AHzaBETUByHs3SRLWYOwQc1iotSPEXlcZQt8iycPgW0WhVozAlOnqbhIorTOHVhLepGGCOUNOuB0deHgIAdlziOptnjNwrTWCjN17UqmFXa02yZrRzs9ZvV6neD2qxWjS40W61+RnNnVbta3f70frWyaOy6FDVSQKvoXRU6bHkZPD4SsNuQrHGnBSe7w549tH6PtW0t6HAi+uOwXTO57dgWjeMcoNwGjmlLK2vZNRt0NDN3hsV76zDSMIHrium3N7dL+AHe14e2ghuK5FxQtoscTlsKW2NAuS/NjficJRu+mWclztiGPMWcnJknZVlukiT/39z/1NxayDvTV2Es0+SK5HhPC7NkPjL6IyMLagfT6dotFMJiWFQoo2kUo6yYLJzj3uBToDwf4bjof4Ryjg6Ek5dYDSOkaUEtSd1qzwKli1M+09djxHk0wvgLib9VUDxf/Bu6JNlsBPMBv6NLhdF0lnHE9izIST0u8nX5WTYd5Yej5FJsO02lsNa1Ypiey57Px6e/U53kvnFfctiLO8G75iwDGhunaibfzz4z0/yKfsUXZzwElwp2qEV5AFshYFliYcUOJU0SUCVs/VDE41AEZoDmDF1e5LA50PhECUxy+FKpDi6c4ZcT2COw2igolORdQZMNjGoI/J4GkHDT00BnHBodKTS4AVSHz6P44iMDtAQRTsA18yUIAwxcT1/VuMP6mPGL9KRbjVdWMyEdZFsxg475EW4CSvoFF2qZuTMg5E7VOzTgRACOUglPZ1+JonKHFTUVWB+IgthKA3thK5+uNn/08nht3Ai7+vX6lurU2q0r2R8QwttO1F4v1VNUWmyFZAPzyVndiJbVigQjvV7KbtWzPCR7rx6DWzSf0KbTHhYuPuBIuFl2GcKyonJM17ZKk+re4nvSqidLNeyE6YiWkKXSjW9cKLVqvNgURZPe06SR74om90diCtl2DlT1LpxRY/BpSdvGamoFuk59NrHqOTt6ldpLQoN3/r5B4p2lb+RJx1BTdeSsO8rQN2QE6AiWQlITdL4FDFpLT+OYXIFG01IfDip6M+g6N1Q0tae/4b5sQ4FOJBJfvPBsr/RdCL8JWfTHPznRV7D3d2JoQUofLL+R21qYCj7T1W2RCwbuk0vc4OJ5SvgGT/orM9yWk6KVpC4kPkewoROP6oXjPymfmHal7HDprvbjtz8B/69qaQ=="
    }
  },
  {
    "type": "CompositeElement",
    "element_id": "b8538f65624db68dbbce4c4cce60f48f",
    "text": "5.5 Non-pre-trained Models\n\nThe method proposed by Ramirez-Orta et al. (2022) achieved SOTA results in 5 out of 9 languages on\n\nthe ICDAR2019 dataset. In this study, we also compare this model with other models using the configuration: window type as n-grams, window size of 60, decoding method as beam, weighting as uniform. We refer to as the ENSEMBLE model.\n\nAdditionally, we have defined a more conven- tional Seq2Seq model, referred to as SCRATCH. The SCRATCH model is designed with an embed- ding size of 512, feed-forward network embeddings of 2048, 4 attention heads, 5 encoder layers, 5 de- coder layers, a SentencePiece tokenizer (Kudo and Richardson, 2018), and a vocabulary size of 3000.",
    "metadata": {
      "data_source": {
        "record_locator": {
          "path": "C:\\Users\\mrcra\\Desktop\\RAG\\test_files\\post_ocr.pdf"
        },
        "date_created": "1729365233.159691",
        "date_modified": "1727326976.0",
        "date_processed": "1729365755.923535",
        "permissions_data": [
          {
            "mode": 33206
          }
        ]
      },
      "filename": "post_ocr.pdf",
      "filetype": "application/pdf",
      "languages": [
        "eng"
      ],
      "page_number": 6,
      "orig_elements": "eJztVttu20YQ/ZUBnxxAYnkRb35zHaMN2jiF7aIPUSCsuENpYXKX3V1acQz/e2dI2ZEDo216ffGDIHJ2eObMzJkh398F2GKH2q+UDI4hWMd1FolmjeVCZGJdZqKsojjBRkaLWpRZMIOgQy+k8IL87wK+WDkz2Bof7nFVW6S/ETAukirNsyRNwzir8ipmhNGpM1I16tGrSJO8KvIwenToranRuSc4RZaFVZJm6cikR9sp55TRbrVn9P4uIGDmkqZJlN9/IDeLtbFy1ZpaeGNHmr3wW4Y9PV4uf3Zo3XLZ2dqK5fI1umtv+uXy4uS75dKj86tGtUgOvaFrU9uwl01wf0/AfKBFx9GCJ6f7M3/bj2ei71tFwYnoN/vjVujNIDbomHOAehMw054sKz10a2SaOcfw+NEzRhZmcG70vLc491YojRLeUqatY7iHSFfKtxjQc182NqEuNmlRVSKJ1k2SlpiUDRaJqCqZV1Hz0th/tbGt0tduysJ5YakrWuJHTiY66PEc3lkvqAstIw22ZWOtPIZWdMripyRKEuYzdfgp0mJxgMSOf4jxjOJGi/2KfXAo0astAmloayRQiykGSXR9CxdT3DnnBuhBtCEcMYtXIOqtwhtyu3x3dQIW3dB6B0pDBmbwYBqo4LGgYPSh1M+FtVT5G7zi8M9IvigWRY5RJitRlBLjpiqyRR7XkWzyIo7iF8n/l7vsbynLk7LenL4+uaA1VgGXx6EP4Y0Gv1UOnB/k7Qx2SNpyBmrTcajpjCvYwk75LRiCsZPBweCU3gAD10Y3ajPYMadjctXS7IDzBeFAzzc0OG72YHfqE7IwcxpcSc2QDLNXPbmvUXTMRG22nk/INGjVGNuF8AuSxBui4A3bOfbZ+eXZ229/PJtYhV+n7ybLUZTrNM5jXCeybhbxAoUsspLULV/0/T+t9KQoDqR7BBeq3gorndEwAxJwCa9mILQUN5TkemiFvWVRmSaNoujLpX09SMPPOOo76hp7hTU+t/6T8jDq55h/HbCqnrxQ4vJPQv3Tw38ipeJ2iLadhnwrbpBmrxm/gQSNjh2H+Ab1HCZHuMRfE/pNYzWbxs6S9zR5l6cXJ1en34fAb6z9zX5R0MaQ6NSGocelITQgpSHnME76w/hncTKDBslOs72jUoNGvzP2evJmX8d+SbQoZ7AA4alETA62NKK0TjKgklFISy+4WxI1WyTO4alNUCZTcX/i4hL/a9REwcLRD1R9ltGBviZ5TeqiRz/r65E2S+z3tsyH3wDwetjn"
    }
  },
  {
    "type": "CompositeElement",
    "element_id": "516190fffa5c82835781601d074b5a0a",
    "text": "6 Experiments\n\nThe primary objective of our empirical analysis in this paper is to explore the key factors affecting the performance of models in post-OCR tasks, aiming to identify the most appropriate settings for such tasks. We conduct three different experiments:\n\nExperiment 1: We investigate how data vol- ume impacts on model performance, aiming to identify a generally applicable data aug- mentation setting that balances performance and training time.\n\nExperiment 2: We seek identify the best method for constructing synthetic data and the best-performing model. Using the findings from Experiment 1, we apply augmentation and generate different datasets using the four methods from Section 3, in combination with multiple post-OCR models.\n\nExperiment 3: We extend the best settings identified in the first two experiments to a wider set of languages for post-OCR tasks, verifying the applicability and effectiveness of these settings in a broader linguistic context.",
    "metadata": {
      "data_source": {
        "record_locator": {
          "path": "C:\\Users\\mrcra\\Desktop\\RAG\\test_files\\post_ocr.pdf"
        },
        "date_created": "1729365233.159691",
        "date_modified": "1727326976.0",
        "date_processed": "1729365755.923535",
        "permissions_data": [
          {
            "mode": 33206
          }
        ]
      },
      "filename": "post_ocr.pdf",
      "filetype": "application/pdf",
      "languages": [
        "eng"
      ],
      "page_number": 6,
      "orig_elements": "eJztVk1v4zYQ/SsDnRNX1rdyK7ZFUaBogW0WPawXxoga2WwkUiCpJEaQ/94ZyU6cbQp0D7vAAjlZJoeP8/HeDD8+RNTTQCZsdRtdQaTKMi1LbPO8iisqU0zqOlVp12StUk22ji4gGihgiwHZ/iGSj623k1N0+k9b5Yh/ZsB1mdRpkSdpulrndVHPCLPRYFvd6SerMk2KuixW8ZPB6Kwi71/glHm+qpM0T3MxG8kN2nttjd8ePfr4EDGw+JKmSVw8fmIzR8q6dttbhcG62c0Rw15g311tNh88Ob/ZDE453Gx+In8T7LjZvP/xl80mkA/bTvfEBqPlb6vcamy76PGRgWXD4CC3RS92j3vhMM57OI695svZ0R+O2z2a3YQ78uJzRGYXiacjr2zNNDQkbhZyR6D7IBgF/HzP8WoplheEE/i1Dj1FbPqvWlYJV23dZVgVFWalquJMpdU6SZB4sX6r5bes5bzivkBp58W/3hOMXHt0B7DN36SCviWwHXCxgIZRO3apBzTYH7z2oA2EPf+OyGkF/ggW6H7srSPeILihA3SoOIMesOsEz+zmHbbvrBvQqBlf8t/PeJKTyz/evYeA/sZfAOphPmNBtxyV7g7z+YHNgHPkLPvLlQdPQcA9MCz4Se0XgBX8RaCsaScV+KAjAqZQR5IhcfXE9Ktzqv+OzqGEfi15eYXyWVOqplpjxbmNU+Y6p3VdNXWBTdckSfxG+e+G8s/dDtZXQhZtbjkavRNS7e0dSMbg1vaXMA28O4zMZw/WLJw9J/KrZEXYkSGHfX+AY4BNTwsqTrtLkKvnmE8UZppigAZ7wfQvlIKmheBQm9mMvV6d0/Y37cOvgYbXGFslnfALs3VX5VWXVVkbY96UZVwU1HbJG2O/KmN7bW78EoUP6LgqpqV7Xkiy+IyMF4IwuV6+vXRLa1Zp9PgVOZ/MnPdENy/7a8P5YWqGvW3njsot1Ac3LQ3cHwzbBK2ONBZWHs9cHukqZrNAVvDBn5p+x1EvPdrZAc6VdwF3NMvjIKJ4loRAL/oJ541brmW1eJiesWVELQ4f8f9cEgjphcwVZYdGmwX1Toc9DFMf9MhSfJo4yxD635JKmwbzNo/LOCsrXCdZV3ZJ3sR1Tm2e1m9D4LscAuksCF6nM1Y/vy6OIuFaLI8fIbVjg3Bnz58TMgKQedbys4jPyhPnKYpZT58/c275ZHc4kfk0KHSvw2EWAS2vp1vWgvcCx2b+7NXDziA0zqLcyN1mNzFzWaCsWwnyP0j96R+zB25G"
    }
  },
  {
    "type": "CompositeElement",
    "element_id": "97fae6b0f0650e7db731542fba95b072",
    "text": "6.1 Experiment 1\n\nThe process of generating OCR synthetic data is highly stochastic, so the same clean text can yield different synthetic text versions when OCR errors are inserted. This variability can potentially enrich the model\u2019s learning process. In this experiment, we investigate the impact of data augmentation techniques (by replicating the clean text data mul- tiple times to increase the volume of data) and the quantity of original clean text data used on model performance. We examine whether increasing the diversity of data via this method can enhance the model\u2019s ability to correct OCR errors.\n\nEnglish\n\nIcelandic\n\nRussian\n\nTelugu\n\nCER\n\n4.96\n\n10.09\n\n4.13\n\n34.12\n\nModel\n\nmT5\n\nData\n\n1\u00d7 2\u00d7 4\u00d7 8\u00d7\n\n1 6 4.56 4.32 4.24 4.24\n\n1 3 4.29 4.10 3.71 3.68\n\n2 3 3.77 3.52 3.13 3.05\n\n1\n\n3.42 3.24 3.00 2.93\n\n1 6 9.68 9.44 9.35 9.32\n\n1 3 9.33 9.12 9.00 8.90\n\n2 3 9.02 8.83 8.60 8.54\n\n1\n\n8.87 8.49 8.31 8.29\n\n1 6 3.78 3.63 3.54 3.55\n\n1 3 3.33 3.15 3.05 3.02\n\n2 3 2.99 2.63 2.40 2.39\n\n1\n\n2.74 2.51 2.33 2.36\n\n1 6 31.44 29.83 29.31 29.22\n\n1 3 29.80 28.69 28.45 28.44\n\n2 3 28.35 27.83 27.12 27.23",
    "metadata": {
      "data_source": {
        "record_locator": {
          "path": "C:\\Users\\mrcra\\Desktop\\RAG\\test_files\\post_ocr.pdf"
        },
        "date_created": "1729365233.159691",
        "date_modified": "1727326976.0",
        "date_processed": "1729365755.923535",
        "permissions_data": [
          {
            "mode": 33206
          }
        ]
      },
      "filename": "post_ocr.pdf",
      "filetype": "application/pdf",
      "languages": [
        "eng"
      ],
      "page_number": 6,
      "orig_elements": "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"
    }
  },
  {
    "type": "CompositeElement",
    "element_id": "a06ec474499aa1f857b759b2a09ab1d8",
    "text": "ENSEMBLE\n\n1\u00d7 2\u00d7 4\u00d7 8\u00d7\n\n4.84 4.80 4.75 4.79\n\n4.69 4.63 4.53 4.48\n\n4.51 4.44 4.23 4.24\n\n4.46 4.30 4.19 4.22\n\n10.18 10.09 10.14 10.11\n\n10.09 10.03 9.94 9.97\n\n10.00 9.88 9.83 9.80\n\n9.88 9.74 9.64 9.69\n\n4.09 4.06 4.02 4.00\n\n4.00 3.85 3.72 3.74\n\n3.90 3.80 3.69 3.63\n\n3.83 3.71 3.52 3.60\n\n40.23 38.99 38.78 38.65\n\n38.47 38.65 38.17 37.75\n\n38.02 38.21 37.43 36.54\n\nTable 2: Results showing the effects of data volume and augmentation on mT5 and ENSEMBLE model CER on English, Icelandic, and Russian texts.\n\n1\n\n27.70 26.89 26.31 26.32\n\n37.71 36.60 35.66 35.59\n\nThe experiment is conducted on English, Ice- landic, Russian and Telugu texts. These languages were chosen as they include both rich-resource and low-resource languages and belong to different language families, and have different grammatical structures and character sets. This diversity makes them representative for assessing different models and methods for generating synthetic data.",
    "metadata": {
      "data_source": {
        "record_locator": {
          "path": "C:\\Users\\mrcra\\Desktop\\RAG\\test_files\\post_ocr.pdf"
        },
        "date_created": "1729365233.159691",
        "date_modified": "1727326976.0",
        "date_processed": "1729365755.923535",
        "permissions_data": [
          {
            "mode": 33206
          }
        ]
      },
      "filename": "post_ocr.pdf",
      "filetype": "application/pdf",
      "languages": [
        "eng"
      ],
      "page_number": 7,
      "orig_elements": "eJztmtuO2zYQhl+F8HXi8nzIXZsuigJtLrbbqzhYDMmhLUS2DElOsg3y7h3KuzmhLaCbAgIELH7J4mg4Ej9TP+V9/XGDLR7xNN43efOCbXhEWwSqFLxOyXgQ4LkyrmgbOY9q84xtjjhChhEo/uOm7twP3aVP+PQZ71OPtJkSCieDskYqtRUm2CBqhino2OWmNJ+jnJI2OLvlnwPOfZdwGL7J44zZBqmMMjXsjP2xGYamOw33jxW9/rihxLUWpSS3n95QWI+p6/N92yUYu34q8wzjoaZ9+WK3+3PAftjtjn3qYbf7GYe3Y3fe7W5//GW3G3EY70vTIgWcO9rvUr8957L59IkS14YTHGtvm29aH9vGh/PUBudz21DnVOgPj80tnPYX2ONQa97gab+plZ7pyP3pcoxYy3S1jxE/jDXHzas/bn7/6bebevJT3rtmbHFDUd8PYxCJO8NTCqANZgnalewtKF7AZavXYfw/h3E60s/4kn097mJ34Tw7Jh+3+nHrr9uvcfjzRMXhvuubvzDf1fP/AQ0ti0djCi/OZlNklpkLKY1IRnBxTbiisQg09NZrRsJJnKkSZuOQMGrjYnEhJh+0tlZpUyAA1yBU4SsOC8LBBoLAKhJTRfvZOARQdR6giSAX0Fm4hNYHWVxSyaNecVgSDkZUCOoUISsOUs/GAZJQ3OTkuRPOeZRc6JxMEKCstRpXHBaEg7YEgaoPC1HnCSln41AHTqJBogHBhhyD5ehBAXBpgNsVh8XgIPhWeEbKQ1WhJxWzkZBW2myT0wm4CSnKmByNlNJcBYSyLhgXhcQVBq5Y2AZdZf76wrosipRCeMwgLBYhLESnDZSCKNal57KA4ESB91UqFJ7P5iGDAw1SJV0il5igBKO4T4ZnlSRPKw+L4eGRBFdnBjvJ/PWmwOwcl8E7X5Ssz4rAQRXjEL1Am1ccFoODro8Lkmoruawyf3ZIMtKEADTyJQprlJCuWJ6zysKrCOvbqEXhwJnaekPiZJX5683gJXclOgXFWsWjFI77ApwbnzSa1TwsBwe1DRMOVWyoombjwGMs1BNX2jnqLSlIVIPxPojItYQVhwXhQAaS5gRBYursYOc/LCJPyJNOuSRVIJaUwAufIwpA5LiuNZeDg+b1naTy2xCqOl/VmtlIKDDaSeWMA5e8l2iKJBq481GBXl8/LAgJAkC7KwZVBe27rZuPBBgMjoPgdd0pkinJhECdcnqImGDWFcaikKCFBakUFQZNM4bdmvm2UlKPUfEUi8xaSlSuhAyBm1B8UCGuSCwGiTuILTL5gt3icGnHgQ2H7n1z2rPxgAxLwUTHusLqjWPvuvZyRAanzOCyr0BM1TL6O96Z6fjTv9Wwen9b9vLmtrbenPZtMxyesV8T0jXlJj2bom8vNC5wYrWaYfs1h6+g7yn5O/zX96IhBQ2FF+usL0rF4hyVS+sbzRFVWBlcDIPzfyXhlMeoTA5FR5lQS2MTGVdvcrLOpXVdu5zBl2RKOJN260NVJSad/1tq9CL6JJx3ERF81FJ7BCeCDoAO1vlgOUhUnyqqNbGcKbO1tqqZ/248F9QqgEJvvbAmRE2IAHVqyNJGs9qU5SBxV93IB7pFTR1f1gwsdad8STQw3/uL5+zJYTy5i+o07rC97C+PRoNRugHZ57LZe+yRpUM3IEUP1fs8sOaU2ktGFrvxwPomHZ73eGVjSth2778c+JKpNkVsu+qgOkZQFKzX/DmCFTg2bYPD1QAd4B1+FbXv4XikW5ugZcPY0/Vd+sek6QA90PX2bMDrJdBNyGSQ+qEZH9gR3uJU+JH1eKaTruaMspeup2saCL5q6770NRm0a276Ehy6PEyhezxhdV4UOzycKCFVM7m//7Jnb/4Guk6M+Q=="
    }
  },
  {
    "type": "CompositeElement",
    "element_id": "eac0486749424bf3a518546329846947",
    "text": "To explore the impact of the original data vol- ume, we experiment with datasets of different sizes: the full dataset size, 2 3 size, 1 6 size, as in post-OCR correction tasks, the training data often need to be from the same domain as the text need to be fixed, so the settings of 1, 2 6 were designed to simulate the scenarios within differ- ent domains under one language environment with varying amounts of clean texts. And to examine the effect of data augmentation techniques, these will be further expanded to 1\u00d7, 2\u00d7, 4\u00d7 and 8\u00d7 their original sizes. This approach will yield multiple versions of dataset A, and since Method 3\u20dd is the most commonly used, we will employ it to generate the training data for this experiment. The exper- iments are conducted using both the pre-trained mT5-base model and ENSEMBLE model.\n\n3 size, and 1\n\n3 , 1",
    "metadata": {
      "data_source": {
        "record_locator": {
          "path": "C:\\Users\\mrcra\\Desktop\\RAG\\test_files\\post_ocr.pdf"
        },
        "date_created": "1729365233.159691",
        "date_modified": "1727326976.0",
        "date_processed": "1729365755.923535",
        "permissions_data": [
          {
            "mode": 33206
          }
        ]
      },
      "filename": "post_ocr.pdf",
      "filetype": "application/pdf",
      "languages": [
        "eng"
      ],
      "page_number": 7,
      "orig_elements": "eJztVU2P2zYQ/SsDnW1X37L2tkkXvTQpkDqnKDAocmQTEUmVpLzrLPa/d0jZ2bgo0Ftzyck0OfPmzbyZ0afnBEdUqP1eiuQOEl7Wg6jLvsC+GoYqTUusqjIvOJZpmRZlsoJEoWeCeUb2z0k47J2ZLcfrf9xzi/QTAbMmb4u6yotik1Vt3WYBIRopI+Qgv1k1RV63Tb1JvxlM1nB07ganqapNmxdVUQWzCa2Szkmj3f7C6NNzQsCBS1Hkaf3ymcwscmPFfjSceWMjzYn5Y4B9e9d1Hx1a13XKcsu67ld0X7yZuu7D/W9d59H5/SBHJIPJ0Nlwu5nEkLy8EHB40EyFaMnN6+XNn6f4xqZplBSciP5yeR6ZPszsgC5wTlAfksB0opu9nlWPgWYTb+yrOmmP9ZBhwdttyXm1ZRnbpkXVDGXdp2lfJIGUxycfjHcG8GkajUXwRwSpJsY9mCH+M1YepGYjhLLByYxrmBWu4BGDE1oZegIepT9GC4feBVdSbMBACJz8iu4uYg3zOF6t4v0Kcigupwzqy4k5kBpCmdZ/vP0AJAnpEkoC5PnFrSKWt0xqqQ8LLzN41KARBXgDPYWyRkU7R1UHYRRZB+DoSnnf2MonFCtwZnFA7wk3ZpEFgjXlSqUR6ORBL05OqnmkzlscOElrpXGxChRmyX0NIfslsoNZC7RgNMJVT3o+SWv0a/1OzJ5DRkyZWS9l5CMyHQm7DdzrGByfmJJ6iY0UadEqloHNhwDHlmIhP2r514xLxRxSFKp/SHi2dGGDgIx4RdSsm9NUUCPl10O5HIBMYHs5k5u0rz0Rtd3A7igdUOtaw/hxiXKWOAqgKnk5jQgnGpwwfFemoQHuVxHaSc0R3qE/GgFFN+epECAXpRT1AOmvlNHjGWYXZHq85IGKWvYM0gf2B9Ror4LctsZgLN0S4Gu7BsaX9l1DvCH6JDE3Wsyc9hGFCv69IVUC4mRxHVHpSe2qdU8JQNgeY0zh4f2fD+/e/P6wXG3C1F4H+j2zxEuecBeGjabun3s0ZyJFbFPGMMVaNGWLWVZXWOaIzYDbn3v0/9yj36/F62IKCmffa7qTfsR/0xJTvm1E1m77qs7zihVNVvT0iWxEmrV9PfzU8kd+E/9z0m7FX92K/lETBTzQ6vuKYhnmz38DTHn3og=="
    }
  },
  {
    "type": "CompositeElement",
    "element_id": "a156dbaf77d9abf4b2734770e5badaf2",
    "text": "3 , and 1\n\nThe results in Table 2 show that mT5 outper- forms the ENSEMBLE model across the four lan- guages. Data augmentation enhances model per- formance with diminishing returns \u2013 augmenting from 1\u00d7 to 4\u00d7 effectively lowers CER, but gains from 4\u00d7 to 8\u00d7 are marginal. In our experiment, training parameters for mT5 included a learning rate of 5e-4, warm-up steps of 250, batch size of 4, dropout rate of 0.2, and 6 epochs on fp32. Training times for 4\u00d7 augmented datasets on an RTX 4090 were approximately 35, 5, 10 and 8 hours for En- glish, Icelandic, Russian and Telugu, respectively. Overall, the results suggest that 4\u00d7 augmentation provides sufficient improvement.",
    "metadata": {
      "data_source": {
        "record_locator": {
          "path": "C:\\Users\\mrcra\\Desktop\\RAG\\test_files\\post_ocr.pdf"
        },
        "date_created": "1729365233.159691",
        "date_modified": "1727326976.0",
        "date_processed": "1729365755.923535",
        "permissions_data": [
          {
            "mode": 33206
          }
        ]
      },
      "filename": "post_ocr.pdf",
      "filetype": "application/pdf",
      "languages": [
        "eng"
      ],
      "page_number": 7,
      "orig_elements": "eJztVNuOnDgQ/ZUSzwzLpYEmb9mktYqUZKXZXmmlELWMKcCKsZEvM5Md9b+nDN2TSZSXPOQtUktt6nLqcOqYD48RSpxRuZPooxcQDfuyq+s6qytWFrus3OddVnbZrkvLtEmLPIohmtGxnjlG9Y9ROJys9obj9RlP3CD9rYBZnTdFVeZFkWRlUzVZQFiLZt2LQTxV1UVeNXWVpE8Fi9Ecrf0Gpy7LpMmLsihD2YJmFtYKrezpwujDY0TAgUtR5Gl1/khlBrk2/Ulqzpw2K82FuSnAvnrRtv9aNLZtZ8MNa9vXaD85vbTt7cu/2tahdadBSKSCRdNZc5Ms/RCdzwQcEorNYVr0TfaSc5+XNceWRQoaTkT/uKQlU6NnI9rAOUI1RoHpQpGT8nOHgWYdZjh8cAGjgBiY6mEV8Ap8FE5iRGXf7xGHtCuHpk6LpmtyXu+x77KM1axkdVel9e89/tI9SqE+2e0trGOGtqJ6fKBA1uyf7RSHAbkTdyg/S31P7F8dbgOoNzKkHeskJpwtYWBSRecfWGSNmJ+4wM89dZwQDFovnQWh4BjmQQ520vfgJuZgPpagvaP93MCgzWwpjHB4/8/h3Z9vDxA2JIFxo+2WGchAQJLcwCZKAq9pncD8GLy5CgeoJqbIEJfuJ+wQhHvhJujFLJSwk1Aj0XPeKAutz9OsuCKFzGD0DFnr07SvwWnYXY7PRIVNVSBZY+i8g5EJwlo7d18795cj6QgzM6NQTCbwRkF4G3wghiIMjcEZ6g+zSXKyiwvYRH2VSSgufY89MJDIzFpmyP6gByjxZhfDPTPzjV/AOlxsCOdlSrSY4xNY8f9aSWW90Qtp/tScJvl28yvARfOJWhUMS5EncLzycURwo3J9rYtQxCdcKItubWMKbo//wY6sAKQMAjna6Acx0yySqyhjoF+WrvP2MJEAG+whrFTSTmJ4w5E23Asew62nS8vUWn1E6UcfBz8tV/0T+PsODZMyXt1xtZr1I3nDbRb7jvDmESJ1J3oMpcMguKAEiDlE149c8vwb+J4ZkormHYOrzx+/AP8ENng="
    }
  },
  {
    "type": "CompositeElement",
    "element_id": "fee98a1453af5883f4845a105bbb0ea1",
    "text": "6.2 Experiment 2\n\nNext, we explore how different methods of creating synthetic data impact on the performance of differ- ent language models. We conduct tests using sev- eral popular models: mT5-base (Xue et al., 2020), ByT5-base (Xue et al., 2022), mBART-large (Chip- man et al., 2022), SCRATCH, and ENSEMBLE. We also evaluate the approach of Chen and Zhou (2023), which combines CharBERT (Ma et al., 2020) with glyph embedding, and compare these results to CharBERT without glyph embedding.\n\nThe results of Experiment 2 are shown in Table 3. It is observed that methods 3\u20dd and 4\u20dd generally outperform 1\u20dd and 2\u20dd. Of the latter two, method 1\u20dd, which does not rely on additional data, yields slightly higher accuracy. While method 2\u20dd allows the model to learn from real OCR outputs, it fails to correct sentences with varying degrees of CER. In our experiments, the Google Vision API OCR sys- tem was used to generate training data, and Tesser- act was used for test data. Since the Vision API OCR system generally has a higher accuracy than Tesseract, models only learn to correct sentences with low CER, which is reflected in the limitations of the method 2\u20dd.",
    "metadata": {
      "data_source": {
        "record_locator": {
          "path": "C:\\Users\\mrcra\\Desktop\\RAG\\test_files\\post_ocr.pdf"
        },
        "date_created": "1729365233.159691",
        "date_modified": "1727326976.0",
        "date_processed": "1729365755.923535",
        "permissions_data": [
          {
            "mode": 33206
          }
        ]
      },
      "filename": "post_ocr.pdf",
      "filetype": "application/pdf",
      "languages": [
        "eng"
      ],
      "page_number": 7,
      "orig_elements": "eJztVt9v2zYQ/lcOfsoAR7Mly7LzlnhBV2Bpi9T7gdWFQVFniyhFCiSVxCj6v++OthvHTdZm2LCXPlkhj999vPvuY9597KHGBk1Yqqp3Br1sOi4zFGU1HMnRIM+nuZzgcCSyLBf5pEp7feg1GEQlgqD4jz3+WHrbOYn7v3EpHdJPBBwW6TQb52mWJcN8Op4OGSEGNbZSK/U5qsjS8bQYJ4PPAa2zEr1/gFPkeTJNszzLOaxF1yjvlTV+uWP07mOPgJlLlqWD8af3FOZQWlcttZUiWBdptiLUDDs7Wyx+9ej8YtE46cRi8RP6D8G2i8X1+YvFIqAPy5XSSAGtpW8rXdJWq96nTwTMG0Y0nK33YHe3FzZt3BNtqxUlJ6I/7ra1MOtOrNEz5x6adY+ZtrSyNF1TItMsOEfAu8AY4ySFyzu6seJ2QezEHn+ugsYeRR+3czSoCjkURSlKKSqZ5pNyKqthWUwnQhTF6Hs7/9N2amU++O0tfBCOumIqvKOF4SQ7aO0fHVIPNCR9huqc5kWpAiZ3HaaDdNCEfNvdI5RpfoDCgc87nw6fwyItN0/ApEc00ucCjA4BZrVqjwEkrTXCMEhT0tFHUfLhAQpFP3Gbb8IaZ1+50jehFNMDFGGqy1dvL68ufrmEE6CDGfzQh9tayVraplQG/awW7uLyek77V4Lpf5kVOWWGphZGKpLZI2mz0fAh+eyfwRSHNXicTyNYXpJok2M9WoNsMvqKRo8xHvHBuOKe8UodGucr+qU6I+Bdq61DqO0tkFetkBGB7K+2lQe7guhzVA3wGxNqDEoC2xCophUygDVAq0AutbKOei+RD22RToGx9i4A7FnaJ/A7grSm6ug0W4+Hzkd8vKEDjuTZ2rbTwu0OnEEzz09L4RFOaBwBAwid9FksA9LKxeap3ZR2m4vz6/kpgVH+Ex6iUyCSx1FvZ9fn89nPfSA5wl6PkajQ3gLeCN2RW8ebks85K2TN15yRZOKZP2vbwQmrZ69e2MsX7vV7JR6Sh1sValjrTVsDUluriuqwJUGnubmckW7m0HeaChXsPRqftV04Pp4cPoGvhHPUvBucc9sffQoLMV6N6RXBEsuVFBPEiShRyFwUk8ng+1P4/zyFo+JgVg+dKohSk1WJlsGT4t83hnl9LzdS+OE/V8CC9GQUBpSBOTOBLIGXARTFllTWG6xIseLeP7JFlw6qKkp6tPteo+Ep1xsg+e58A4YHgen2O4HXqzhxWoSADsKt7e+A9+H7WasszZmxgZgzLM0kzQJXiMyEhdKHjUJNfLxW6zpQTE2/hCmk7JyQG5r1mhq4h0/3bLS2tz6SiF7EA6hROAMrZxvKRvivZ9fxIl3wfVABVkLpOKkkQlJiIF8zAckX/Xbcb4TbsN1VuHaIscizy2sqoyEYx368KzjBceIX1q6J2W+KdQ/nb17GjH7jT8k9G7gV7J9cd7urLPuUE8rEJPHyXNQ5jxY5Mnv25zNU+mjBMS6Bt4rtm5N+mY1z3XeuJgRxXERuvdklojT9nX9TP+jEtmxPl4UKzXXYd5QU5XClKZBoqu0bo1WjQpyqWLXYlQf9+jvve/8XeWFtYw=="
    }
  },
  {
    "type": "CompositeElement",
    "element_id": "78469eb19e292d831b1e7adeb596cc16",
    "text": "Method 3\u20dd proves more effective, extracting real OCR error distributions and generating training data with various CER values, but requires addi- tional data. With a sufficient volume of data (as in the English language experiments), models trained with this method performed best. Different OCR systems, due to their unique designs, can make var- ious kinds of errors. With insufficient additional data, Method 3\u20dd can fail to extract a comprehen- sive set of OCR errors, leading to distributional shift in the data, which ultimately affects the per- formance of models that rely on it. In Experiment 2, Method 4\u20dd achieved impressive results without\n\nEnglish\n\nIcelandic\n\nRussian\n\nTelugu\n\nCER\n\n4.96\n\n10.09\n\n4.13\n\n34.12\n\nMethod\n\n1\u20dd\n\n2\u20dd\n\n3\u20dd\n\n4\u20dd\n\n1\u20dd\n\n2\u20dd\n\n3\u20dd\n\n4\u20dd\n\n1\u20dd\n\n2\u20dd\n\n3\u20dd\n\n4\u20dd\n\n1\u20dd\n\n2\u20dd\n\n3\u20dd\n\n4\u20dd\n\n3.98 4.02 4.19 4.12 4.11 ENSEMBLE 4.56 4.79 SCRATCH",
    "metadata": {
      "data_source": {
        "record_locator": {
          "path": "C:\\Users\\mrcra\\Desktop\\RAG\\test_files\\post_ocr.pdf"
        },
        "date_created": "1729365233.159691",
        "date_modified": "1727326976.0",
        "date_processed": "1729365755.923535",
        "permissions_data": [
          {
            "mode": 33206
          }
        ]
      },
      "filename": "post_ocr.pdf",
      "filetype": "application/pdf",
      "languages": [
        "eng"
      ],
      "page_number": 7,
      "orig_elements": "eJztWkuPG8cR/isNnhJAYvr98M1ZLxIDsQPIMnIwjUV1V/VyIHKGnhmuowj676nmroSVkEArHrwgMJd5sGuqquv7uqaqh7+8W9GO9tTPNx2uvhEr440K2XiXnUlIFous5EqS0hppZV69EKs9zYAwA8u/W7WLm2k4joU+3NNNGYlPJ4Uq6MTqtDFr5ZJPqmk4Ce0H7Gr3USoY7VPwa/lR4DAOhabpEz3BuXXSxhnXxA407rtp6oZ+unnw6Jd3K1bcfDFGS//+VxYbqQwj3uyGAvMwntw8wLxtaq++2Wx+nmicNpv9WEbYbL6j6c08HDabV9/+bbOZaZpvarcjFjgMfD2UcX3Aunr/nhW3gR72zdrqk9GHsfnt4TQGh8OuY+Ps6F8ehnfQ3x7hlqbm84r621Xz9MC/3PTHfabmZjj9Mj5CJ/lsCDIqW6x0LrkSSVkwxoGLqFfNqZn+PTfhH2jeDijM5qglouBo3tEk9sNIgmqlMnd39EKw8Ah83d8KBm0n/nn1StA4DqPAbprHLh+b15OAHsUt9TTCSZYf6vp20cIufu/mrbiDsRuOk7i6fsXXuyNNLwQ/zWp/O3YjmwbE7qVo6thOe24t/tUeBDEda+1KxxMVd8PuuCcx1HvNf4JJdL2YtySu+9tdN23Fh8ix64x/18g7/fmFaKjvpnvHCO9dmrcdz/g+Dixbh3HPQ5kxXYvvOg5Ci+1pytPbaaY9e4xHEvPQDHajOPbdb3yPNHW3PQ8W6MUe3lCb60txmu2brsepuXsK2vQwpa5/NKU270ezfiE+Q6ZprdDtmt0HODgmZdgfRtpS/1JMjJSYaG5mPuLD7uwI8ATG8AlYbGfadnX+ELh7o79vu7IVx93c7Xlx7d4KOJFgOolwcF6KFh7oyyn4H6K5hQYgSw+96Dhq3/fi+mPYhf44F/swFyjbju44yF3zfjp5zmc2O50gGY5zY/+HhfEjjI1Qd/S6kZbZ+3k+klSMidYQRgUanTJooUhUSaN3nHOWfPTH5aP4OL08LMfHaL7u5h39TxTBkJNBekipZNIhx6QKQ0vJGFvlguJzofh9IX4Gu/IkHE2MlEL0xmVeiIBeB18qVSimncyC43Ph+OrIE4X+SSjymqvAWRSDz4ghxhyc4eoOQq7WwLIanw3F17Q73h6fBKLiik8WI2s2KA2/DFEXH7PKOYKO1i4gPheIXP8+CUGnwFhEoySGIqXywJ0Xkowl6KIXBP9YBD9vtb64vh5DbtfJP8b85549oNth7P5D+P9KW4UWdQDPzVisWkXGPShutkGhTz7Cgv/F4K/kWqavJgCjjq6EEpKvHskRePTGyuJyCVXFhQAXQwC7Vuar8bc11eo16egtOG6KTA6WZObo82sB0oL/xeBvmAD6qwkgLbEiyFaFUBPkZHWJxhpvjNepqIUAz1XD3e9qPamMA87e0WRPzgYCMKVIKhkr2qKDQlxAfM5V/MUl9slr/H4T86vXcTIBvczeVZSaKJNKnMWLtEZhNXFpqC+HAvpMCmQPtuSQawSqBbzO1bNRfpOHkPhFslDgYihgzqQAKk8BAAKl1L7R1SRjSklahY7zQFgocDEUsGdSIHLjpqOqKeoCiNzTuVA91wRMCWOrXihwMRQ4txaA6EyQCJgxGRWI2waltE7Z+urQLbt6l0OBc2sBVFZWK3VBH7F9MNMeocoSuEQoKiz7OpdDgXNrgWrRWsoOQRLTIVrJtaDK2UiuC9PSFF4QBc6uBUIFKaujGmSCQtJqTv8aLIXknV929y6HAufWApkCliS9pARkI0G0sUoXTGDjWJaO4HIocG4tIFOKVcsQJFFSIWvdPvlyWUhaGotLFrgcCpxbC8RaavZUOBdYZ6VqNrXUGFwET2bpCC6HAufWAoy1tDGgdoWKjNwYeMjFIdaiErklC1wOBc6tBUxy0qmYkiuBMIJRmHLNNmsTieLyR+bLocC5tQB3gZCS4bbAR5tciCGTrSq76DyTYvncezkUOLcW0Am084GAqlIUuT8splYnQ0RjZF72BS6HAufWAgYialOoSsBGh0oyOw8pFpt0jUsWuBwKmHWKwq6l5oNK7XC6UuL6x5+uf/jrP675znk+hCR+unr17eurv3+BLr/+FwHK/sg="
    }
  },
  {
    "type": "CompositeElement",
    "element_id": "36a0530e26f2e6989a8ec53968c4bc5f",
    "text": "mT5 ByT5 mBART CharBERT +Glyph\n\n3.42 3.36 4.23 3.60 3.61 4.44 4.74\n\n3.00 2.96 3.63 3.39 3.42 4.19 4.52\n\n3.03 3.00 3.54 3.57 3.54 4.00 4.62\n\n9.48 9.42 9.93 - - 10.32 11.92\n\n9.53 9.45 10.26 - - 10.65 9.82\n\n8.31 8.39 9.41 - - 9.64 10.43\n\n8.38 8.28 9.30 - - 9.54 10.00\n\n3.36 3.34 3.41 - - 3.77 3.91\n\n2.98 3.13 3.33 - - 3.83 4.06\n\n2.33 2.34 2.82 - - 3.52 3.62\n\n2.27 2.14 2.78 - - 3.34 3.64\n\n30.35 30.21 31.06 - - 37.12 33.56\n\n28.24 28.14 28.49 - - 34.23 35.28\n\n26.31 25.98 25.66 - - 35.66 34.52\n\n25.85 25.28 26.00 - - 37.50 34.92\n\nTable 3: Comparison of CER results across various models and synthetic data generation methods in English, Icelandic, and Russian. The best-performing model for each dataset is highlighted in bold, and the best method for generating synthetic data for each model is underlined.\n\nEnglish\n\nGerman\n\nIrish\n\nIcelandic\n\nFrisian\n\nRussian\n\nSpanish\n\nTelugu\n\nCER WER CER WER CER WER CER WER CER WER CER WER CER WER CER WER",
    "metadata": {
      "data_source": {
        "record_locator": {
          "path": "C:\\Users\\mrcra\\Desktop\\RAG\\test_files\\post_ocr.pdf"
        },
        "date_created": "1729365233.159691",
        "date_modified": "1727326976.0",
        "date_processed": "1729365755.923535",
        "permissions_data": [
          {
            "mode": 33206
          }
        ]
      },
      "filename": "post_ocr.pdf",
      "filetype": "application/pdf",
      "languages": [
        "eng"
      ],
      "page_number": 8,
      "orig_elements": "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"
    }
  },
  {
    "type": "CompositeElement",
    "element_id": "f0c3af5f13b044d3bf987b089790d63f",
    "text": "OCR Post-OCR\n\n4.96 3.00\n\n15.43 7.74\n\n5.79 4.27\n\n19.29 11.07\n\n12.57 11.01\n\n35.99 29.97\n\n10.09 8.28\n\n30.06 24.57\n\n5.15 3.55\n\n16.20 11.03\n\n4.13 2.14\n\n8.16 5.88\n\n6.00 3.76\n\n17.38 8.92\n\n34.12 25.28\n\n90.41 66.64\n\nTable 4: Performance of the ByT5 model in terms of Character Error Rate (CER) and Word Error Rate (WER) across multiple languages, before and after post-OCR correction.\n\nrelying on additional data. By generating its own training data with varying degrees of CER encoded through glyphs alone, it successfully trained mod- els that perform well across diverse languages with different character sets.\n\nOverall, we observe that pre-trained models sig- nificantly outperformed smaller Seq2Seq models trained from scratch. mT5 and ByT5 showed sim- ilar performance, with ByT5 reducing CER val- ues by 39.5%, 17.9%, 48.2% and 25.9% on En- glish, Icelandic, Russian and Telugu datasets, re- spectively. CharBERT did not benefit from glyph embedding, consistent with the findings of Am- rhein and Clematide (2018).",
    "metadata": {
      "data_source": {
        "record_locator": {
          "path": "C:\\Users\\mrcra\\Desktop\\RAG\\test_files\\post_ocr.pdf"
        },
        "date_created": "1729365233.159691",
        "date_modified": "1727326976.0",
        "date_processed": "1729365755.923535",
        "permissions_data": [
          {
            "mode": 33206
          }
        ]
      },
      "filename": "post_ocr.pdf",
      "filetype": "application/pdf",
      "languages": [
        "eng"
      ],
      "page_number": 8,
      "orig_elements": "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"
    }
  },
  {
    "type": "CompositeElement",
    "element_id": "c2fe139c3474500d0c0c06ab1b36bbfd",
    "text": "6.3 Experiment 3\n\nIn our final experiment, we replicate the original clean text four times for augmentation. Based on our previous experiments, we select Method 4\u20dd to generate synthetic data and train the ByT5 model for post-OCR tasks on data from a wider set of languages, so that we can evaluate the chosen con- figuration in a broader linguistic context.\n\nFrom the results in Table 4, we see that the model performs well on the English, Russian, and Spanish tasks, with CER reductions of 39.52%, 48.18%, and 37.33%, respectively. This approach also achieves a CER reduction of 31.07% on the low-resource language Frisian. The performance is poorest in the cases of Irish and Icelandic, with only 12.41% and 17.94% reductions in CER, re-\n\nFigure 5: Comparative analysis of CER changes after post-OCR across multiple languages. Each bar repre- sents the distribution of CER changes categorized as Increased (red), Decreased (green), Equal (blue), and Zero (dotted green).",
    "metadata": {
      "data_source": {
        "record_locator": {
          "path": "C:\\Users\\mrcra\\Desktop\\RAG\\test_files\\post_ocr.pdf"
        },
        "date_created": "1729365233.159691",
        "date_modified": "1727326976.0",
        "date_processed": "1729365755.923535",
        "permissions_data": [
          {
            "mode": 33206
          }
        ]
      },
      "filename": "post_ocr.pdf",
      "filetype": "application/pdf",
      "languages": [
        "eng"
      ],
      "page_number": 8,
      "orig_elements": "eJztVV1rKzcQ/SvDQiAXnK33y+vNW29uUvLQFtL0pdcXo5VmbRFZ2kraJG7If+/M+qNOKYULbaGQJ8vS6MwZzTk7n18SNLhBG5daJZeQ5DIrp23WFTLPu1nVzPN507SiVKhybNssmUCywSiUiILiXxJeLIMbvMTDf1xKj/QzAmZ13hSzKi+KNKuaWTMijEEbp3Snj1F1kc+aepZOjwG9dxJDeINTV1Xa5EVVVBzWo9/oELSzYbln9PklIWDmUhT5dPb6hcI8SufV0jgpovMjzV7ENcNeXS4WPwf0YbHYeOnFYvEJw0N0/WJx9+13i0XEEJedNkgBvaO1kz7tVZe8vhIwH1ix4WzJm9P9Wdz245noe6MpORH9Zn9shF0NYoWBOSdoVwkz7WlnaYdNi0xzzjkiPkfGmKUFXD9TxZrbBQWDHPDvdTSYUPSf21nOmrwt82kuC9UoURaqzgXKpuwyrDLVvrfzv2znuOO/wmyn/b+1QG2BTlthAI9CmMATgscdIYS4RnBer8YoaVBYYADo+G6kG4GWHsSw4stjCSl8FNQVcLsEvcdH7YZwkiOMSQJJS0b4HuPaKSgXQz5VCqKDFVr0nDxsLeWPWgJ3D4SlYy+0HVl93N5XwL00IwN+34sfr+4givAQOPl4p/NuAwKetEJPGSO4Do5vO4HgCEtEpiOpNHwUZjiULdcuoAXp7AW90mrwY3VA6QW03glGNJqgdGCKFMcvk5766Afh+dYj3vOj/4WflKyrVqHo2qKrs6kSOK/ktMCsrcVUNu+fx3/XT9S+h7CrIkThqStW4TNt5PWJUyYMMHjD6yhag6kU/aj0efL6T9vyhgXL8vMYBhMD6+2ek0K5dw3uJMsxO/lTW8gBm0DHxrDy+ejarowO6wncDdQxYSejfX7qhaXdnUkIT8c1XF3fUTI1SC4psEGKJq3yswmU8zSbn+1uFnVaFLQmWj3ZljRttincr3UAem6yg1yDMOQnWmh8pO+CeIs8AmfptD47UDTu6YLgRjEfTQk3XjNfxsZDacJSBGXqnaMLEfafAEnfmZHwreeimOatREJSWu6Lc9ZsIcvTMjsbz7M6bcqz03oJi3hyYRdfZV2sRK0K6qEQoiLTKjWf1lh1pWraWYXFu3X/N6Pwhr/uCNUlXLkNwYx9J7kIsw16FBgrWa6JCOu6i3gyb4T0LgTYkFl1b/4Qckjhmk3RCs/zlORF3qXZNypX0czwuh0OxjjF57m7opn7G81QEeDWskZ4oJ6Taj9M4BMeN1Ye0dLW9a8Djefz1gz4YWfXX9A7OFcukrhgF/Z3k+nL75CRyvw="
    }
  },
  {
    "type": "CompositeElement",
    "element_id": "613f081933cfa4fc24133eb7b386e891",
    "text": "spectively. We attribute this to two main reasons. Firstly, the data for Irish and Icelandic (sourced from the CC100 dataset of web-crawled data) con- tain numerous proper nouns. These are challenging for conventional NMT models to correct due to their inability to handle out-of-vocabulary words. Secondly, although the ByT5 model was trained on a multilingual dataset, the volume of data for low-resource languages is not substantial. This dis- parity in data availability can affect the models\u2019 performance on post-OCR tasks. Table 4 also in- dicates that the Telugu test dataset has very high CER and WER, likely due to the complexity of Telugu glyphs (Negi et al., 2001). When Telugu text becomes blurred, it can be difficult for OCR systems to recognize. Thus, post-OCR processing",
    "metadata": {
      "data_source": {
        "record_locator": {
          "path": "C:\\Users\\mrcra\\Desktop\\RAG\\test_files\\post_ocr.pdf"
        },
        "date_created": "1729365233.159691",
        "date_modified": "1727326976.0",
        "date_processed": "1729365755.923535",
        "permissions_data": [
          {
            "mode": 33206
          }
        ]
      },
      "filename": "post_ocr.pdf",
      "filetype": "application/pdf",
      "languages": [
        "eng"
      ],
      "page_number": 8,
      "orig_elements": "eJx9VE2P2zYQ/SsDnRLAVvVh2VZurZsWOXQLbFzkEAUGRY0kYilSICl73cX+987IXu+mCHKyTI7evPfmjb4+RahxQBMOqok+QCTkKl1tRbLOy01T1ygT3DZyW2+wLbCp82gB0YBBNCIIqn+K+OHg7eQkvvzHg3RIPzNgusnKfF1keR6nRbkuU0aYiwbbqFbdqjZ5ti436zi5FYzOSvT+O5xNUcRllhd5wWUjukF5r6zxhyujr08RATOXPM+S9fM3KnMorWsO2koRrJtpjiL0DLv7UFX/eHS+qgYnnaiq39E/BDtW1f2vf1ZVQB8OrdJIBaOlZytdPDZt9PxMwHxhxMDdou9ur3fhPM53Yhy1ouZE9JfrtRamm0SHnjlHaLqImWplHvxFhQ/C0VRMg490UGQlXQd8DIy3F7XGldDeKsNgk9N8HPg4lmLkRvE2Ior/xyEH3+DcYadomBrixRsYqQLGhq6yJElJ0Q9xNskbHC78KQBrG0ntwUxDjTyC7XziXpOXyXSV1Gmbyyxr10W5zbZlWYtVg02GdZ0yi1tDP6IM6oj6HMMXBBGCU/UUEEKvPAQL4WRhEMoAJdFTPGL4Qzkf9HlBJQgcFmitg09O+R6EaeCTRJpJoyS8u8S5gdbZYS7f7dIkmV/yGMC2cMJ6SWk5aari4/cgrVlC4I4kEZ2dPFB+KaBg7MT99z16YuoQZC805aZTpps50KtH8oFmRpO4+2sPHGA9y6DcUngDNBPOqnpUDpQRtdIqnPmoJ84awU5hadvlkSJeT1q4M5wo8tT2M2WfKki30KG3U9fPin4774tLHzgJauWIOWmxBgQMkw6Ez/nUL6Ivth2tJnFswM1AbU9LhxfH4BZqoCkYG8BPNeWGtAnNDtBpo/wSaPBMn8yaccRRKP2iSQri0LasmltevKimLElLIDup5yAM9SKqvHLLv3f35Lt/YIs5/7ACXgwCX1IzWjpiE3pxQdujnroJeKtv4+xJ/xHJsV6RObuP93Mcvny8X4BWDxSxN+7TQIZR4yMTJReucJ0+j72Hd7xOQIgkdgGc/feUzh7Na9vHAPRNtQNxqvVEs20WoMKsuaZUqrZVktyfnWVh/uwDDnMU+CPWGfUvspGTX7yqv34naWC8gy/fnDvhnOAd2fPOPH/7D9RM+rY="
    }
  },
  {
    "type": "CompositeElement",
    "element_id": "5b0180d2266aa7fae2bc0a92498d37a8",
    "text": "for Telugu results in a 25.91% reduction in CER.\n\nFigure 5 provides a more detailed sentence- based view of CER across languages. Here we enu- merate the following categories for CER changes after post-OCR processing: \"Increased\" indicates sentences where the CER has increased, \"De- creased\" indicates the CER has decreased, \"Equal\" means that CER remained unchanged, and \"Zero\" means the CER is zero after post-OCR processing (i.e., perfect matching with the ground truth). We observe that only a small number of sentences ex- perienced an increase in CER after post-OCR pro- cessing. Specifically, 25.37% of sentences in Irish showed an increase in CER post-OCR, and only 8.66% of sentences in Russian. Notably, 59.52% of sentences in Russian had a CER of zero after post- OCR processing. For Telugu, which had the high- est CER, we saw a reduction in CER for 76.18% of sentences after post-OCR processing.",
    "metadata": {
      "data_source": {
        "record_locator": {
          "path": "C:\\Users\\mrcra\\Desktop\\RAG\\test_files\\post_ocr.pdf"
        },
        "date_created": "1729365233.159691",
        "date_modified": "1727326976.0",
        "date_processed": "1729365755.923535",
        "permissions_data": [
          {
            "mode": 33206
          }
        ]
      },
      "filename": "post_ocr.pdf",
      "filetype": "application/pdf",
      "languages": [
        "eng"
      ],
      "page_number": 9,
      "orig_elements": "eJztVMGO2zYQ/ZWBgAAtYKu2ZcnS3opN0uaSAtstAiQKDIocWUQkUiWp9W4X/vfOSLa73uweeuitJ8vkzHtv5g3ny2OELXZowlar6AoilFVaqyRZ1VVeyHqZpelisyqqLFP5Il+soxlEHQahRBAU/xjxx9bbwUk8/cetdEg/I+CSspMsXSVJvEyLrFgywhjUWaVrfY7aJKus2GTx4hzQOyvR+wucTZrGxSpJk5TDenSd9l5b47dHRV8eIwJmLVTEIjt8pTCH0jq1ba0UwbpRZi9Cw7DXV2X5h0fny7Jz0omyfIv+W7B9Wd78/EtZBvRhW+sWKaC39G2li3tVR4cDAfOFER2zRRe3x7vw0I93ou9bTeQk9KfjdSvMbhA79Kw5QrOLWGlPJ1szdBWyzII5At4Hxqitg1tsh90ADv3QBg/agIAVNWT5hs7UIJmAT6/f3cRMcuK/1aHFiNCe272QWVpXYp1XicwVqlxKtUo26021XK+XWf6/3f+p3a023/xUhQ/CkStG4T0dLJ4Y/17vBocptedOK/Sis+Q1eUKEypOVaCRCJahxdxr3tibzhXTW+zMnxPArOtwjmgFEHdCxepizsMG143SNJLEUPauOi+jwwjiOJ+5fLIvDd2VACqdCaHa5FDjVAqdi5lM1wOWArXmaYaoIziVNFcEegWqaQ4eORghCg1DbtrV7bXZADuDOOk1U/HgYRjYEwNTcBOAuzH+7voHj6FHSFZTRB8MDTQrKiB6TYicp5aTOw75hauZiyEbwQzxmzCj9LRXwEsDTBIVPEt79OYiWQjsUhsNEGOMcdkIb6sNgJtkULIyihM/o7JP4CVZ7+IvOXy8NftAxxjOgV1SjDNCJIBs+3+vQjDA7ZwciCG4IzY8xfEKwFT2WO5xEWdM+kGm+E20L01SwPf80Bu/njK75nyKt574cd9IL2qhVk7oYfu9R0oaQhP4w47WWbN5c4hPKB6d9A76x+5cZTthTq0bFeZxl3wPdDEQrTAwfbRAVM6ZFnK5eDSTbiHDkoIjnnYbLVsfw/rytZzQvWjZjPje50btmDrRnGGvGE+zFnpCfL/BxZmlBLvNnml41+GLlfxSOnoS+w1t+f4evfwMOWZsW"
    }
  },
  {
    "type": "CompositeElement",
    "element_id": "48d20fef5bfe17f9618f2292a0a23d7a",
    "text": "7 Conclusion\n\nOur experiments demonstrated that augmenting data by replicating clean text and constructing syn- thetic data based on glyph similarity significantly improves model performance for post-OCR cor- rection. Furthermore, we proposed a novel ap- proach to constructing post-OCR synthetic data based on glyph similarity, which outperforms tradi- tional noise injection methods, especially in scenar- ios with limited data volume, as it does not require additional external data. In our experiments, pre- trained models demonstrated superior performance compared to those without pre-training, with the byte-level ByT5 model achieving the best perfor- mance. For rich-resource languages, this approach can reduce the CER by approximately 45%, while for low-resource languages the reduction varies between 12.41% and 31.07%.\n\nLimitations\n\nFor the preferred Method 4\u20dd, the time complex- ity of calculating the character similarity values is O(n2). As a result, the calculation of character similarities in languages with a large array of char- acters, such as Chinese and Japanese, can be quite time consuming.\n\nAcknowledgements\n\nThis publication is part of a project that has re- ceived funding from (i) the European Research Council (ERC) under the Horizon 2020 research\n\nand innovation programme (Grant agreement No. 884951); (ii) Science Foundation Ireland (SFI) to the Insight Centre for Data Analytics under grant No 12/RC/2289 P2.",
    "metadata": {
      "data_source": {
        "record_locator": {
          "path": "C:\\Users\\mrcra\\Desktop\\RAG\\test_files\\post_ocr.pdf"
        },
        "date_created": "1729365233.159691",
        "date_modified": "1727326976.0",
        "date_processed": "1729365755.923535",
        "permissions_data": [
          {
            "mode": 33206
          }
        ]
      },
      "filename": "post_ocr.pdf",
      "filetype": "application/pdf",
      "languages": [
        "eng"
      ],
      "page_number": 9,
      "orig_elements": "eJztV11v2zYU/SuEgQIJYLv6ttQ9Ze7HOnTtkGZPdRFQ5JXNVRI9ikriFf3vO5d2sqQr1vZlwYC8JDJ5ee7HuTwk332cUEsd9f7c6MkTMSGtdFlq2VRlkTfNokpJ5rpqSq1rrRbZZComHXmppZew/zjhj/PBjk7R9W86V47wLwDGi6RKizxJ03mcV0UVM0Iw6qw2jbmxWqRJUS2KeXRjsHVW0TDcwVnk+bxK0jzN2WxLrjPDYGw/nB8ievdxAmCOJU2TqPj0HmaOlHX6vLVKeutCmFvpNwy7fLJa/TaQG1arziknV6unNHzwdrtanZ68WK08Df68MS3BYGvxbZWbb3Uz+fQJwDzRy469Te7MHub8bhvm5HbbGjhHoI8P063s16Nc08AxT6hfTzjSLUbO+7GricOs2IenK88YC7G0vWpHzpYBrrHPjG9pAsvPqSyiJiO9KGUdZyptqNaxTitVZ0lcJ1GUPlD5X1IZRtx3bLTb3L8ZnaArlMgwv4PQ1KFO3jEzwm+kF3Jc85Tp14KrJ+qdcHSIFGOqJdkLhhOy10KF1aMKc8OunwGEvFGHtRJECduLdbvbbsRgOtNKZ/wOn+seRCvZ+3YnTAdaL2gQzFIrEF5jXSd7RQIfgqs4e7M8hTc3QzSKazYXz0cHZ66zjqbikgQwYAmHUvRAa4XcznhQqo3w9m6oN5CI+ZsihoeNAZAd/SG8QaBs2iBjRCNb+DQDCdP/vo9PYEdsrB6mgoYtKSNbTrQXg0J3IA1jB3Fp/Ea08MHVD/4vbDt2SEcOwnihLWrSW4+c/xiNIyG1Ngd3YIAcf/C6uXjZI7Q73E6RO804SNMDPpT2M8KHka25wrcqrmzH/aW5ZsgAOXGYyDvgBThUcLoPHrVDh3iatcQV/3F3lh9IRNUNXXCtgw22zMHLTAQ/4A+OHWo6c7TXCnHT/1MsMgMIPNCHPkEN9AgbRls+O+W+DNNXpkMuqG2WPwoktfumae3lF4DD8oAUOLoAtxisyV8S9SJO5ln8KDR2Gs+jxaP5bX18LR3KZi7ojDfTF3SS4pqoLhMl06qkWGoqK9K1UpFSeU3Rg07e15H3ivdYgBi+7cRLiijL06KOEtI6qlWZ1nUsoyYqm5hU+cDkvZ54X9tnt6lnleFND/FqyLGu/RKEWWSrMYm0noZZD80MytfSFbQZJ5RtoDqtGtv9ucdGaiOdVJDd2yfZhWxHSAjU6s1RnxzPxQl0CxIzjK3fY9/AQHAY9Z8orEE4Gv5WqaCtEgNuDdGH7OyuV85EWAuFHEYII86J5Qb6DpVm1fpZbiX/mAbFrEng2PA32fXD2CGX7xO1LE3qpCqausBGoLKsK1rgT1XIqNBKPdzj703UTtSH3l62pNeBr29TNvCWp41ucGdMilonSdLEVaOaRQZ5y5Lqgc77VLavbrbb/J/xFWk71teeWYOA5lkqJF98+Sa6v9RvoBN8GVSEna5FM/aaRa1xthNH5jjI1LMR92e+3J9CQKSDuCzt2CvTiqNnp8tjgTW0l9KfrDN/wl8SJRErXbD+LlGJmrpUWZ3VBSWyWOSLuEgWlOkyiupKNflDF/5vupCPHdPjwbXvQVRz7WSH8+bohcPrTsi1o0C9eG3noiyzKo+Pf0DXoe3eKkP85HiORtP79S8dtQx59Pb5y+P9E4TwuMF7cePFEjBuf71/yq+lE7x/dni7DYfmXAePry0u8o9Pl4+TpKzEr8m/nXfv/wJfSB9e"
    }
  },
  {
    "type": "CompositeElement",
    "element_id": "ebf2021f9ac6c181c8ef5e2bfec056af",
    "text": "References\n\nSina Ahmadi, Milind Agarwal, and Antonios Anas- tasopoulos. 2023. Pali: A language identification benchmark for Perso-Arabic scripts. arXiv preprint arXiv:2304.01322.\n\nPablo F Alcantarilla and T Solutions. 2011. Fast ex- plicit diffusion for accelerated features in nonlinear scale spaces. IEEE Trans. Patt. Anal. Mach. Intell, 34(7):1281\u20131298.\n\nChantal Amrhein and Simon Clematide. 2018. Su- pervised OCR error detection and correction us- ing statistical and neural machine translation meth- ods. for Language Technology and Computational Linguistics, 33(1):49\u201376.",
    "metadata": {
      "data_source": {
        "record_locator": {
          "path": "C:\\Users\\mrcra\\Desktop\\RAG\\test_files\\post_ocr.pdf"
        },
        "date_created": "1729365233.159691",
        "date_modified": "1727326976.0",
        "date_processed": "1729365755.923535",
        "permissions_data": [
          {
            "mode": 33206
          }
        ]
      },
      "filename": "post_ocr.pdf",
      "filetype": "application/pdf",
      "languages": [
        "eng"
      ],
      "page_number": 9,
      "orig_elements": "eJztlG+L3DYQxr+K8KsE7lxL8p/1vlu2l1JI2uNuC4U4LGN5vCsiS0aSrwnHffeOfHchKaWQN4XAvbKkGT3zSPOz3t9naHBCG496yLYsk3Xd1LIo5VCU2DRCjFUrsYay4qIvsMwuWDZhhAEiUP59lgbH4Bav8HmOR+WRPqsgb0Qr60pImfOqrVueFNakyQ161F+yGinqtqnz4kvC7J3CEL7Raaoqb4WsZJXSZvSTDkE7G45Pjt7fZyScvEgpivrhA6V5VM4PR+MUROdXmzPEc5Ldb7vuj4A+dN3klYeu+xnDx+jmrrvZ/dJ1EUM8jtogJcyOxk75fB7G7OGBhFPAwpSqZd9En2Lx87zGYJ6NpuJk9KensAF7WuCEIXnO0J6y5HSmlaNdph6TzTbViPgpJo0bHNGjpRtJ25+VDzoazCjvn41EOYixR6iqsu9Fq0bYiJJzqKGSXJXw0sj/s5Hriv+O3+zrzt9qC2x3nmDQF+ydNtoObHcC/xeYCwZpYqOz2gUaQLhkEYKb3WJcyJkohMzZNRi9ZTv27JXpgbxQ0x6PwnriivT9RzY6z67pFt3lzkOvFQvK6zmSEvg/9R2bPc5e2/g43Qo6Q15wKUT+NZW/gfekfIeHdIR/obMY5IiyQSxkXda8HnnTFHzDe1VuqmHgL3T+MHReQ28ce8N2RoGN4LUxsFJ5YLfOLMnMyiHnOXsDITL8dMmSTx0ZdWZc0r2u3IFSRIlPLWUjdXbxGJi2zDpLzCN4ghEMsjADNSxnv15dXbGDh6R/DTHmiX+Ts3egzhS1EQ39ILJ81bzecrHh3UIuJBft5vtgbeuiwmIjeaVgKLDuRQNYVE2xqYq6lOMLrD8MrPtzYtSw3eTPSGglTm/1RADuqeVkZsCV1U3ObhfCFP2dpstmv+9vGHpPkA4YUa2PZtpLd+ifpgu9vNqeWIgkEyIdzawpFhdPw4mgJIhZTLyax2eXoDlfMjcQv4n/t8+v8wHV2TrjTp9Xhb2b5iWuW0joLRVZ1gKB4Jav+Ott2T6iTaT8B9gf/ga/XyN4"
    }
  },
  {
    "type": "CompositeElement",
    "element_id": "4b34de8bcb12f029dafb5fdb1f807ff3",
    "text": "Journal\n\nYoussef Bassil and Mohammad Alwani. 2012. OCR post-processing error correction algorithm using google online spelling suggestion. arXiv preprint arXiv:1204.0191.\n\nGuilherme Torresan Bazzo, Gustavo Acauan Lorentz, Danny Suarez Vargas, and Viviane P Moreira. 2020. Assessing the impact of OCR errors in information re- trieval. In Advances in Information Retrieval: 42nd European Conference on IR Research (ECIR 2020), pages 102\u2013109. Springer.\n\nEmanuela Boros, Nhu Khoa Nguyen, Ga\u00ebl Lejeune, and Antoine Doucet. 2022. Assessing the impact of ocr noise on multilingual event detection over digi- tised documents. International Journal on Digital Libraries, 23(3):241\u2013266.\n\nS\u00e9bastien Bubeck, Varun Chandrasekaran, Ronen El- dan, Johannes Gehrke, Eric Horvitz, Ece Kamar, Peter Lee, Yin Tat Lee, Yuanzhi Li, Scott Lund- berg, et al. 2023. Sparks of artificial general in- telligence: Early experiments with GPT-4. arXiv preprint, (2303.12712).\n\nYung-Hsin Chen and Yuli Zhou. 2023. Enhancing ocr performance through Post-OCR models: Adopting glyph embedding for improved correction. arXiv preprint arXiv:2308.15262.\n\nHugh A Chipman, Edward I George, Robert E Mc- Culloch, and Thomas S Shively. 2022. mbart: mul- tidimensional monotone bart. Bayesian Analysis, 17(2):515\u2013544.",
    "metadata": {
      "data_source": {
        "record_locator": {
          "path": "C:\\Users\\mrcra\\Desktop\\RAG\\test_files\\post_ocr.pdf"
        },
        "date_created": "1729365233.159691",
        "date_modified": "1727326976.0",
        "date_processed": "1729365755.923535",
        "permissions_data": [
          {
            "mode": 33206
          }
        ]
      },
      "filename": "post_ocr.pdf",
      "filetype": "application/pdf",
      "languages": [
        "eng"
      ],
      "page_number": 9,
      "orig_elements": "eJztl21P3DgQx7/KaF+BtOwlzuZp31FYUfrAIeCq47oVmnUmiY/Ejhxn26Xqd79xWCpaXU/izUlISEgbOxN7Mv7NP38+fp1QQy1pd6OKyQImeToXUY5JIKJMBFgGtA6CMAvDcl0IGYeTKUxacligQ47/OvEXN70ZrKSHMd1IS/wzLhimIo+SWETRLIzzJB9XGINaU6hSfY9KI5HkaTILvgd01kjq+x/WSeN4losojmIf1pFtVd8ro/ubXUYfv054YZ9LFIkg+faJwyxJY4ubxkh0xo5pduhqv+zRYrX6oyfbr1atlRZXq2Pqb53pVquLw5PVylHvbkrVEAd0hq+NtLOuKCffvvHC/obG1u82+eHu7p7bduM97LpG8eac6G+72w3qasCKep/zhHQ18Zl2PHOjh3ZNPs3c7+Hoi/NrvOEaa2z8sw/LXinX0ISDfj5FIdN4nYi4XJdZHmWpnJciL2OilIIC5+LlFP/PUxxn7BN67PGxX5uBi1fCK+QKNYC6gPemxrbFAg6bz6jVDEQQihn8fnQBPv2DXcWVroCsNRa4blw8nzdgUxmrXN3CMAZUxlQNgdGN0gR9R03jp/uh4pfyT8wA7Z9qA52lzirt7oeLUATzWRDm4ewxkGdoLddnQ1c++38Bs1ynJWaiEGkiCwqlLKKkmJdpioQhFvkLmM8GzJNBNTUXiODK49WjZkbv7swUTobe4cbAocSBZ98Zv8XdFI5R6y1cDrzlHXxAW2E/HYH+oDYKGb9zRtuSsuiRFsEMDvl47kF2NYFqO5QOTDmiPqLdg9L8Vxrbjq8Plg7AWUUbbGZwquGw2KDmY/Zxp4/iLmgXtYC54BSWgzUdcbZHRpfECUvfFHB6wZE9oZU17C2PeOgT25+Cr2QPYSBWA3dfFAb5DC59g1Rkn9YS3ALrmII0k0meZHOMowBxnuTcHqHMsvKlJZ5NSyxb1AM1CK+MNcz2WT3A29ognFXDljR3Bq6GgJdo4B39TYOme/4PtTNefo/NIMmN8Itfw89vDNqofgS0HRqnvGQP2ABtOHEoyO3E3mzIQqEqxT3B8QUURg4evd73hiP2Ez6On9yZC7/iMcc7vnyn1ha5R/g9RLQX7S/EPLyHXSTJ0xBnac/KbB1FFGRxOS+zsgzXcZ6nQoRpXAQviD8bxC9HgPM1sjkgVvxhTfJ26tV8YO2smWaLPd2iRcb9wmiOWTYHUPjhG/YtWrNsnlBtb5n9pVUSXhu7Uf7zsGTJfYst2imcM8KWe4Rjrlm4r9DtBvw9uasVszmFS2kcTw+6OAB+s2oKxOakGbsn8mKM9rb3/YLWMRJSMdMVabL8qzR3hLc6lRf6BSzRNlugL3z0auwP+MweCU7Orw7mPxugKeyJKGDwRBqK/SfanzgIcllSJNMoCALJHl3mvvA5Jbkg+dIIz6YRrgddHbxmeWbqGXIv49dDo+Cv2gwPDC41Ay+9gnvN5nKO/sNbC1dbM1Q1nHu/7t2Mr2rTL9ivmM6NxrzZdjUQ51oUfsyP+m+AZU0vHhn6X9hzJjRjIkQingZoEKYJtzfNs3WAMhFJQTJN5ynmyZrZjV8AfTaAvvZ8HTKdqmu9+i6Lz2gLOGX1NbYir868jYMlvJcHcDQ0XJ/63o9c1abFHi7hsmZWmu2DI2nXrKUL7zm8oSi8VPb3/qE12jhWe/ARM/5HYEs9W3p2Nthse8UeIkz3xP4iDuN7DxHP5/9F5qd/ABIe6Oc="
    }
  },
  {
    "type": "CompositeElement",
    "element_id": "09f78fe7d82968a68d12a32ade395a9b",
    "text": "Guillaume Chiron, Antoine Doucet, Micka\u00ebl Coustaty, and Jean-Philippe Moreux. 2017. ICDAR-2017 com- petition on post-OCR text correction. In Proceedings of the 14th IAPR International Conference on Document Analysis and Recognition (ICDAR), vol- ume 1, pages 1423\u20131428. IEEE.\n\nEujeong Choi and Chanjun Park. 2023. Dmops: Data management operation and recipes. arXiv preprint arXiv:2301.01228.\n\nSimon Clematide, Lenz Furrer, and Martin Volk. 2016. Crowdsourcing an OCR gold standard for a ger- man and french heritage corpus. In Proceedings of the Tenth International Conference on Language Resources and Evaluation (LREC\u201916), pages 975\u2013 982.\n\nAlexis Conneau, Kartikay Khandelwal, Naman Goyal, Vishrav Chaudhary, Guillaume Wenzek, Francisco Guzm\u00e1n, Edouard Grave, Myle Ott, Luke Zettle- moyer, and Veselin Stoyanov. 2019. Unsupervised cross-lingual representation learning at scale. arXiv preprint arXiv:1911.02116.\n\nEvgenii Davydkin, Aleksandr Markelov, Egor Iuldashev, Anton Dudkin, and Ivan Krivorotov. 2023. Data gen- eration for post-ocr correction of cyrillic handwriting.\n\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2018. Bert: Pre-training of deep bidirectional transformers for language understand- ing. arXiv preprint, (1810.04805).",
    "metadata": {
      "data_source": {
        "record_locator": {
          "path": "C:\\Users\\mrcra\\Desktop\\RAG\\test_files\\post_ocr.pdf"
        },
        "date_created": "1729365233.159691",
        "date_modified": "1727326976.0",
        "date_processed": "1729365755.923535",
        "permissions_data": [
          {
            "mode": 33206
          }
        ]
      },
      "filename": "post_ocr.pdf",
      "filetype": "application/pdf",
      "languages": [
        "eng"
      ],
      "page_number": 9,
      "orig_elements": "eJztV2tr20oQ/SuDP7VgK9LqZeVbrp2GtElb0tfl1sWsViN7a3lX7K6UuKX//c7KcZsWWgj3AYWAwZJ2NTuPc86M3n8eYYNbVG4pq9ExjFiZlDyswooxFhasKJO6YnUdxzHL0zzjozGMtuh4xR2n/Z9H/mJpdWcEHu5xKQzS32AwylkRZymL4yBKi6yIvIVh01ZXspZfd+Uxy4o8C8KvG1qjBVr7nZ08TYOCxWmc+m0tmq20Vmpll7cevf88IsPeF3I5zL58oG0GhTbVstGCO20GN1vu1t7s7HixeGPR2MVia4Thi8Uc7cbpdrG4OjlbLBxat6xlg7Sh1XSthQnaqh59+UKG/YLiW3/a6LvV2zW3a4c13raNpMPJ0aPb5YarVcdXaL3PI1Srkfe0pSdL1W1L9G4WwxPzrTpFnrC44FnI4ikLeR1iGYbRNIrqsmIijUbeKYc3zm8+62TT8G6LMFtLo9UYTpTTUiHMdSfQjeFSig1fdCGZaWCmO+u4242BqwqeIleTl2vZyLZFuNQGu5sAWBjlAZzP5idXE38NQm8n0KKTPjSgn8/C5MXsCrwXtGwo936N3lLw0hcUK6lWFnQNbo0QJW4N5ycvr2jdoVFDjrj3RtVIkQv0VudadB6kFAFvdlbawccrKutK7Y9+NDj1eAy9bibgg47G4LNp6QgWLzpyN6arKTlyenoa+BIcqvOcG0Pn9vjaZ45S+CMpas6naSaSMKOsI6vziEdllKVYp6lIWfJAiv+RFFH4j1hx2n1ErVbECS0HFM3WXH3sCJzcbDzCWRzAfKtbewxzyh5suaLzB/RpSu3g7/AiJVC2aAPg5k/ZQ2uwNZJ2DbfHLA6jIIwYIe5eWBOiwDCN87ggsCZ1nWA6LcO8pFvGMl4/YO33wdoruSWszKi+dHKFY7hA9QmedCSKZi+zl9w4qeCtbgbsRVkAM6Ovq6GepJO0CbyarnRTAcmzqripoNYGOKzQTDw6B0O118o1rNFIRyF45W07+zPVfU0BrX+puBe32SGR3WNrL7mnPW+6PQUeXVydzgZdLaLs8UFsizzday0UU3Y/5MdFlOQVxiFWiHFU+BTHYVKExAXKdfGA/N8H+ScN3lCXJkwp5N0Ynnmcb/gOnpHaVthc82YMz7lH75ne+Zu30q4N770cd9WaG5pDvg0w74g3uBnDE8OVkFZoWvu0HSaXiOaa00p3nhdnZIBYdrlrEF44GnAuug3CX+hcg0QVvTvQ7i1abIh3rxwdrnQ/cK8I4I2yHRW2l1R5EEZbO6FtlKwGvLrTW8rt0d8gN2ogqAMreIM/aQNEDmoDLCJm368NTLOqYmWBdVlWNc/qkjKeJaLIWJTlyUMb+G/JQFXf2H0UpLqGqkKovfEjeXoH5X4+WKHyZjrT+Cdr59rjoyNubmQfaLM64qU9YjFhIEqnRbav9PcWo/CuydsBgxTexwEToEi+TdG6FjtDpJDC0+iatJ4geJ/j//1xqqcESEmjUr+rNtJ/ZDS4seSd8c1tg43uiaAr6ljnXVNxu8Z+/yFCU323f8Mz8rwnKXhmZK+NdntCDoOYn8DohAkcJi/f+4aPDErMne8L39kOuYE7ybkf6zgmYRVxQYHXRAJBiUimtWAlZiVOefzAut+nBT3lQpcwx77xGLskLEzeoRzG/RU1JBwgeIG4xx9BzxJeOLzWnfMtgQ89gT4X/0DjjmmIwokzXA6aT1ijEaWFUlbyFn/UIWhZWYLnlvI5wPQQJHREdTNMbxPwmPyhVYzhEQURBmEyDdPHv0Lsh78BAbqjfw=="
    }
  },
  {
    "type": "CompositeElement",
    "element_id": "c94cdd62e72e85c2377de9197f75b8be",
    "text": "Eva D\u2019hondt, Cyril Grouin, and Brigitte Grau. 2017. Generating a training corpus for OCR post-correction using encoder-decoder model. In Proceedings of the 8th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 1006\u20131014.\n\nPaula Estrella and Pablo Paliza. 2014. Ocr correc- tion of documents generated during argentina\u2019s na- tional reorganization process. In Proceedings of the First International Conference on Digital Access to Textual Cultural Heritage, pages 119\u2013123.",
    "metadata": {
      "data_source": {
        "record_locator": {
          "path": "C:\\Users\\mrcra\\Desktop\\RAG\\test_files\\post_ocr.pdf"
        },
        "date_created": "1729365233.159691",
        "date_modified": "1727326976.0",
        "date_processed": "1729365755.923535",
        "permissions_data": [
          {
            "mode": 33206
          }
        ]
      },
      "filename": "post_ocr.pdf",
      "filetype": "application/pdf",
      "languages": [
        "eng"
      ],
      "page_number": 10,
      "orig_elements": "eJztU8FunDAQ/ZURp1baUBsvsOSWbtK0VZSsoraXEK0MHlhUsJFtoqZR/r1jdpMqkdp7pV7AzDyex8/v3TxE2OOA2m87FR1DJCq24plQVbHkabrKqhyFTDOuWJPXQrFoAdGAXirpJeEforDYOjPZGp++cVtbpNdMyPOkEFmaCBHztMgKHhhm0GBU13TPqFwkWZFnMXsGjNbU6NwLnjxN4yIRqUgDbEQ7dM51RrvtYaKbh4iIwyxCJCx7vCWYxdpYte1NLb2x85ij9LtAuz4uy68OrSvLwdZWluUpuu/ejGV5fXJelh6d3zZdjwQYDa1NbeNRNdHjIxGHhpZD2C160T30/P049+Q49h1tToO+O7R7qdtJtujCzBHqNgqTjlTZ6mmoMIzJ2Vyyv6+nyJeJKGTGErFKmGwYVozxFedNpZI65VGYyuMPH8BndxJOyylhvNgZrfwC1ve26+HcmqnTC5BawXvbtZ33SEU5xUDYPIZz1GhpWt2CBG9lp8OSNBwnB42xcLW+hnDeI6qRuOFcMLkAQl2T+vZI4fyGcBd9DJ80bMJtoiKQA9OA3yGs/I46Hq2epZE9fDad9rA2ukE6dY1AxJfST5Z6FwfF9kxu3u7NN9NPAwI/hgtD3xtJlnBvFxCEdCQgy2YBBGd8GQfdn67kUtpwxDv8EtQi2V4noUpDClDmTORLSd4rCpYLouEZclFl/5Pw7yRhI6dewpnzFntaBONvZNUbevbdTzn7fhnDVW1h7+gjmD1NPlWmnoIrHLT7VKACNdk5G5ZKlBK5z5gDLff/kVktGttKTeQz0eEC/xSED511/lUUXobgNMSUqid14AFvIPh2Crip3+fjI1qCtPhsfl4cvJ+Iv1n/9hc3be9/"
    }
  },
  {
    "type": "CompositeElement",
    "element_id": "a9475047931377f73bf67f98b435d401",
    "text": "Wikimedia Foundation. 2024. Wikimedia downloads.\n\nYasuhisa Fujii, Karel Driesen, Jonathan Baccash, Ash Hurst, and Ashok C Popat. 2017. Sequence-to-label script identification for multilingual OCR. In 2017 14th IAPR international conference on document analysis and recognition (ICDAR), volume 1, pages 161\u2013168. IEEE.\n\nLenz Furrer and Martin Volk. 2011. Reducing ocr er- rors in gothic-script documents. In Proceedings of the Workshop on Language Technologies for Digital Humanities and Cultural Heritage, pages 97\u2013103.\n\nRapid homo- Avi Ginsberg and Cui Yu. 2018. glyph prediction and detection. In Proc. 1st International Conference on Data Intelligence and Security (ICDIS), pages 17\u201323. IEEE.\n\nRoman Grundkiewicz, Marcin Junczys-Dowmunt, and Kenneth Heafield. 2019. Neural grammatical error correction systems with unsupervised pre-training on synthetic data. In Proceedings of the Fourteenth Workshop on Innovative Use of NLP for Building Educational Applications, pages 252\u2013263.\n\nKaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2016. Deep residual learning for image recog- nition. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 770\u2013 778.\n\nOana Ignat, Jean Maillard, Vishrav Chaudhary, and Francisco Guzm\u00e1n. 2022. OCR improves ma- chine translation for low-resource languages. arXiv preprint arXiv:2202.13274.",
    "metadata": {
      "data_source": {
        "record_locator": {
          "path": "C:\\Users\\mrcra\\Desktop\\RAG\\test_files\\post_ocr.pdf"
        },
        "date_created": "1729365233.159691",
        "date_modified": "1727326976.0",
        "date_processed": "1729365755.923535",
        "permissions_data": [
          {
            "mode": 33206
          }
        ]
      },
      "filename": "post_ocr.pdf",
      "filetype": "application/pdf",
      "languages": [
        "eng"
      ],
      "page_number": 10,
      "orig_elements": "eJztmNtu2zgQhl9l4KstYKs6y8pdmqRJekiDpNvD1oVBkWOJa4lUScmpU+TddyjbaVO0C2SBvQiQq0jiZDjkfPNz6E/fRlhjg6qbSzHag1GcFnGeI0M2FQX3RZ7kguf0sGBhkEyL0RhGDXZMsI6R/beRe5hb3RuOu3ecc4P0Z3AYZGEepUkYRV6Q5GkeOA+DUaOFXMhbqywK0zxLPf/WoDWao7V3/GRJ4uVhlESJM2vRNNJaqZWdbyP69G1Ejl0sURT66c1nMjPItRHzWnPWaTOE2bKucm4P9mazPy0aO5s1hhs2mx2iXXa6nc0u9o9nsw5tN1/IGsmg1fSsufFasRjd3JBjN6BY42Yb3RndjnXrdhhjbVtLmpwCfbodrpkqe1aidTGPUJUjF2kt1dJuVmE7ZigrSuBX+hBOabTDr51z914uZYNCMqGvVK2ZsM5jb2o3WHVda/eePhV901rvamfqaVOOht1oada56psC3VYE/s2vPMNz3SsxROxB6IexB9/Hbqf13Ly7Rb6VXY0j8vYzUz6PEj+Ic8FYIFxSeBzkacCLZOFHYRE/MvW/MvVzvodP5h4l/yMgH5ntK2mJj/5vKcfwkjzVcGgkWlRjeKEVbQJT8Ixxzmw1hn1bwUlvbDcGpoR71Us4gHNNu+XICjIPLvFLj4rjpNOTmhXk0HIj2w6koDApoZtlwkIbaPq6k1QmtNAa3hxceHCqBjcQxF0Fp/vnFyBVh0YN/0NGXKsFGucfyIfQvHdsUjSsXltph7BcNkslh1n+OD043L94MoaVrskUgjG4LbQQpMGsp6miIJ3StEdHR3f4P2PG0JwrfOv26hd1kMfc50EgAj/Kg3CaxSzKkjATAU4TVhT5Yx08nDp4heqaasAYNANAr0mspYJ3ul4OVAceXKDoOYEKFDigmYDRxhKbUOquknyyZXwHpB1IPnd5IZFVpQW9gK5CeK/NkqqmdfS+2q4M3iKvlK51SYU31MWhLGVHtJ/0DXMg4wbsAyqX3rjvaGi8xB3MebZl2Y/uSfGCc5HkUZIEPuYpJnEe+WGSJwxjXKTikeKHQ/EFa6WASjd6AvsrCcdSWXJcbtGR8LEfaCa5K+t1W0FriE0+yKQzEdgh3/QIW3Y9CGxHLz8K8MEdAT6kLAwGdS3L4aPzdIm8J0DXg/qeXj651dwtpmH0XxR3Ok3iNMUwYotFnPiYCN9nYUywYp6H6WM3+5BY1SRscGyoLV1KvJL8euxUlxQWXvSKX6/t5FBfNb3adhovUSmkjuAEGeWlFgPIuQdnOOhhaVjT0Bo4PaMhaaY+gdR8w7Zd2w4bC1eSHPTK9pSalaTcuQKYdIZJNQi7s1Sk0eQGXMZ+J+HUTJsOaeHVHTU/VUqvBoCBsuaMz16dD2r+rJe18wBHdIbs6mj/+77bXX2ESbgtkPSeOs6KJA6DOPSn8UKkflHwQrBFEmCOfMozfKyNh1MbL5lsHC0ndLx/kDTfuoe/qA0vx3BZMf3FjV24/twVxgsygMt+uNcFqQeHiC01wFYK11LXyMwAt8NQNq7XGJrjCWza498h7sT5p1ab66bt6SAAKp3diUHZcEfDjw33DuUs8zco09P0fizHcTEVkZgyP2NZKKKA5WGcirCYZgUXafTI8sNh+Q1dzOC0pO6BrpNIqL5msq6ZEWN4J21l2AoOKtaLipn1BujnhikuLddw3F83s973Mdj8ahF67opIGFNSVoRYwybAK6kQSMOVrb9fK2t9NaEaGIiA21V6wMwHuXKq3xrpLo3udS8k1x5Jbhb/G6af/wHAbjge"
    }
  },
  {
    "type": "CompositeElement",
    "element_id": "68ad9c048c840c6742b27c41068775c0",
    "text": "Svanhv\u00edt Lilja Ing\u00f3lfsd\u00f3ttir, P\u00e9tur Orri Ragnarsson, Haukur P\u00e1ll J\u00f3nsson, Haukur Barri S\u00edmonarson, Vil- hj\u00e1lmur \u00deorsteinsson, and V\u00e9steinn Sn\u00e6bjarnarson. 2023. Byte-level grammatical error correction us- ing synthetic and curated corpora. arXiv preprint arXiv:2305.17906.\n\nEmi Izumi, Kiyotaka Uchimoto, Toyomi Saiga, Thep- chai Supnithi, and Hitoshi Isahara. 2003. Auto- matic error detection in the japanese learners\u2019 en- glish spoken data. In The Companion Volume to the Proceedings of 41st Annual Meeting of the Association for Computational Linguistics, pages 145\u2013148.\n\nPaul Jaccard. 1912. The distribution of flora in the",
    "metadata": {
      "data_source": {
        "record_locator": {
          "path": "C:\\Users\\mrcra\\Desktop\\RAG\\test_files\\post_ocr.pdf"
        },
        "date_created": "1729365233.159691",
        "date_modified": "1727326976.0",
        "date_processed": "1729365755.923535",
        "permissions_data": [
          {
            "mode": 33206
          }
        ]
      },
      "filename": "post_ocr.pdf",
      "filetype": "application/pdf",
      "languages": [
        "eng"
      ],
      "page_number": 10,
      "orig_elements": "eJztVU1v3DYQ/SsDnXdVfawk0zcnLZq0aWvEjlEgChYjcrSiLZECSRndGv7vHWo3aYyeeilQICeRM4/Dp5n3pI9PCY00kQl7rZJLSOq8yUVVdbtmp7pdJ0TeN1hSgU0luqbukg0kEwVUGJDxT0lc7L1dnKTPe9pLR/xYC+ZNIcq6KsoyzStRizxWWEGTVbrXX1BNWdSiqdPsC2B2VpL3L+o0VZWKoqzKKsJmcpP2Xlvj92dGH58SLhy5lGWR1c+fGOZIWqf2o5UYrFtpzhiGWPb1Zdt+8OR8205OOmzb78k/BDu37furH9s2kA/7Xo/EgNny2kqXzqpPnp+5cEwYnOJtyYvsOReO85rDeR41X85EvzunRzSHBQ/kI+eEzCGJTGeO7M0ydRRp5tkacn+PZ1d3OyEICS9UJzMlKqGk4EWPRV5ddElkFeiPEME3j2iGx3bJMlIB3unxHuGtOcRAX469V6dVCNpt4HrFibA4+M05De/xYNB5b80G3uDywPETJB9H+Ol00rxIv8J47uZ032Tj6Zi90+MWhvvz2YmBcanIOh9In0ugUXB3YrBGDdyYdVt39+hOpVIosqJM4dUx0HakRxrh4HCauK0SRyDnrAMeNE87NhoWvwVtDuCPJgzEoPUWubgozQicrcMU0P2uH2F2NDttwml7WZRZleaNyOo0DuvzHH/lV+TrHuk2tph7/Q/7ZEJ0Va0U7giFxKxAVapMSMny7auLb/b5/9jnh0nD2z+XSW/gZ320AR8QPshBTzbYDdzao2XADeoD8m6geQtyQI4ss9Fh0CdRv9HB+oELeRwwyq3IMtbw1RLsFlbpnoWrKJx1qw2wXuEeZzTkCUZiB8QWL0WWCyCzhcOo/QB+tg9kIE4uZWNHEvDaTnwslrmz4zIRBLtWu45iIMV+8GB72OU+wJUxCxvnF2JzsE84HJFX7Eip12ZDz8RixSWsewa/Y+SiPfP2G4jt9pDvqpVame8u/p1bml51eV2KvOB/jkJZldSIush4NFm/K5tvbvlP3fK1+K9x4c88SolOpZDziNJVX4pn73S3rPJgxfQjf0TPkv169rc6jJQ8f/oLVIKz/w=="
    }
  },
  {
    "type": "CompositeElement",
    "element_id": "1b5635b145d85c545dc625d46e6da0cd",
    "text": "alpine zone. New Phytologist, 11(2):37\u201350.\n\nMax Jaderberg, Karen Simonyan, Andrea Vedaldi, and Andrew Zisserman. 2014. Synthetic data and artifi- cial neural networks for natural scene text recognition. arXiv preprint arXiv:1406.2227.\n\nJohan Jarlbrink and Pelle Snickars. 2017. Cultural her- itage as digital noise: nineteenth century newspa- pers in the digital archive. Journal of Documentation, 73(6):1228\u20131243.\n\nAtli Jasonarson, Stein\u00fe\u00f3r Steingr\u00edmsson, Einar Freyr Sigur\u00f0sson, \u00c1rni Dav\u00ed\u00f0 Magn\u00fasson, and Generat- Finnur \u00c1g\u00fast Ingimundarson. 2023. ing Errors: OCR Post-Processing for Icelandic. In 24th Nordic Conference on Computational Linguistics.\n\nAdam Jatowt, Mickael Coustaty, Nhu-Van Nguyen, An- toine Doucet, et al. 2019. Deep statistical analysis of OCR errors for effective post-OCR processing. In 2019 ACM/IEEE Joint Conference on Digital Libraries (JCDL), pages 29\u201338. IEEE.\n\nMatias Jentoft. 2023. Grammatical error correction with byte-level language models. Master\u2019s thesis, University of Oslo.\n\nKimmo Kettunen. 2016. Keep, change or delete? set- ting up a low resource ocr post-correction frame- work for a digitized old finnish newspaper collec- tion. In Digital Libraries on the Move: 11th Italian Research Conference on Digital Libraries, IRCDL 2015, Bolzano, Italy, January 29-30, 2015, Revised Selected Papers 11, pages 95\u2013103. Springer.",
    "metadata": {
      "data_source": {
        "record_locator": {
          "path": "C:\\Users\\mrcra\\Desktop\\RAG\\test_files\\post_ocr.pdf"
        },
        "date_created": "1729365233.159691",
        "date_modified": "1727326976.0",
        "date_processed": "1729365755.923535",
        "permissions_data": [
          {
            "mode": 33206
          }
        ]
      },
      "filename": "post_ocr.pdf",
      "filetype": "application/pdf",
      "languages": [
        "eng"
      ],
      "page_number": 10,
      "orig_elements": "eJztl1Fv2zYQx7/KwU8tYKsSJVmSX4YsSYukdRYkbTGsLgyaOslEJFIgqbhO0e++o+QEzVBsyMuAAHmxJfJ4PB1/d/rry/cJNtiicmtZThYwETzNqzDClBeYiFxkpQhTLHmVzDeiDNlkCpMWHS+542T/feIv1lb3RuD9Pa6FQfobHEYZK+J5yuI4iNJiXkTew2DU6lJW8sEqi9m8yOZB+GDQGS3Q2kd+sjQNChancerNOjSttFZqZdeHiL58n5BjH0scs3D+4yuZGRTalOtGC+60GcLsuNt6t8eL1eqTRWNXq9YIw1erE7Q3Tner1dXRu9XKoXXrSjZIBp2may1M0JXV5McPcuwnFG/9bpNHs4c5t++GOd51jaTNKdA3h+mGq7rnNVof8wRVPfGRdjSyVn27QR9mFPpNHH5zg5OmkwrhTisM4AJ3cLndO93oWlo3hSh6xV4v4mzVszCK0zDwm9zv/1G6Bifk7J/HHcYhi/JNEidZJOZMcF5uYlFuoijMGKfMvxz3/3ncw5B5QjX+zMeSf4NzXqIhb/UU3ntHcC1brfZcTeFIlXRM8JmWN6WcAlflOLaDvyiplFquAiB4kgCu98pt0UkBPs2DKTeOjm8GQvIGFPZm+HM7bW4sVNqA4m4YtAKJUh8U+IOolfR5CMjBn/IWOoOdkcqNt4soCecBYyx7hOsFN4ayd4sf/aP9Ats8jUNRVFU2D4mQJM8J1jyL+YagSsM0fsH2+WB7rrdcEbim2RAYNwNsl9g0CNdKihtu7EBlFsBx34yIbdHMQDqKAriFUtZ0TTRqaXEBipqkQwpmC0QiLdgTpzvb8RnQQViQCojth1XciC2RFsA50aFoQFdwokXvaRtSMYUsfjV/vYgYy8fmGrEkfhqvJavSmOcxZ5hhXnAiray44GwuwqJ64fU58XrkGkm4Wq0ITY/HtUOpVn0YVjj8xmYcqo2/xbK1g9mppAXw1uCe5mXdD7NVOE76axEZJeGE347LxmlY8np0zkdLXx7vqMMScDN4K5XqzWF1fTBzcKZq2faqHAL01cPigLiv4dQYbewC/ji+gkvK7OxyhMHP+R5+JpAyWEoRkA9gCdXQBZ0xvQeOtaqQUiYQtKK7tuvH8qCK+UDLexIhUtinlQWLRImiKqKk2oS8IFiTLJszFgpSIyGPXsriGZVFyVsqC6d3JEaXvnFjQ5z0ljDZT+Fi288+U5+/qPs9DmpkBk57PXuie4G0BkkTNEOrLwI4QezALx2w8m2aQNtbaX179vTiQPIALVYVCo8Z+KzM/Gz3gPUIMvmEo+Plm7PT01Nq9F5/PAb65PA2+CA3hhuJFl6dH598eD0FnyQLrBhbf5yTQ3LyxPbPRbqJyowJFvFMZEmU5QlpbPpJ0gTFC+fPh/MlbUii45yW68rdN9d3hrctH1Ed0ARKjvFYElw7SX10s3c4a/CWquI+SvA5bUjeLKlpoxkIK6xXJwT6FD4pQspY6fYD9LbRT6Muy2Ox4ZssJz54wVkUEjBJmpZMbEg2z1+oez7UvZdtq+E9OtcrHD/T5gHdYzcFQfqZYCLmiCaSvr+BRdIGzr/U+w44NHpHn2LjwQI91tgnfwK0InpxBv5bbuiofFTH8g5L0E0JFckMabcHHU0nRXSTQBd+Ey8wzn7VQPWos5f6lkR5FFEJnJGBpHfAFVr0svu/evAUzq6oCfuHTafwu27uuNLTwQ29Uc656jmJe1bMYkruaHSFt/QRUMI1ZUIQtnDJB9EfRfedvEgPIj6ksr3236I1mn8rrK9/Awj9H6A="
    }
  },
  {
    "type": "CompositeElement",
    "element_id": "4f53f92751237ac5fd4602afd21bbc8d",
    "text": "Philipp Koehn, Vishrav Chaudhary, Ahmed El-Kishky, Naman Goyal, Peng-Jen Chen, and Francisco Guzm\u00e1n. 2020. Findings of the wmt 2020 shared task on parallel corpus filtering and alignment. In Proceedings of the Fifth Conference on Machine Translation, pages 726\u2013742.\n\nCaroline Koudoro-Parfait, Ga\u00ebl Lejeune, and Glenn Roe. 2021. Spatial named entity recognition in literary texts: What is the influence of ocr noise? In Proceedings of the 5th ACM SIGSPATIAL International Workshop on Geospatial Humanities, pages 13\u201321.\n\nAmrith Krishna, Bodhisattwa Prasad Majumder, Ra- jesh Shreedhar Bhat, and Pawan Goyal. 2018. Up- cycle your ocr: Reusing ocrs for post-ocr text correction in romanised sanskrit. arXiv preprint arXiv:1809.02147.\n\nTaku Kudo and John Richardson. 2018. Sentencepiece: A simple and language independent subword tok- enizer and detokenizer for neural text processing. arXiv preprint, (1808.06226).\n\nLouisa Lam and SY Suen. 1997. Application of ma- jority voting to pattern recognition: an analysis of its behavior and performance. IEEE Transactions on Systems, Man, and Cybernetics-Part A: Systems and Humans, 27(5):553\u2013568.\n\nMike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Ves Stoyanov, and Luke Zettlemoyer. 2019. Bart: De- noising sequence-to-sequence pre-training for natural language generation, translation, and comprehension. arXiv preprint arXiv:1910.13461.",
    "metadata": {
      "data_source": {
        "record_locator": {
          "path": "C:\\Users\\mrcra\\Desktop\\RAG\\test_files\\post_ocr.pdf"
        },
        "date_created": "1729365233.159691",
        "date_modified": "1727326976.0",
        "date_processed": "1729365755.923535",
        "permissions_data": [
          {
            "mode": 33206
          }
        ]
      },
      "filename": "post_ocr.pdf",
      "filetype": "application/pdf",
      "languages": [
        "eng"
      ],
      "page_number": 11,
      "orig_elements": "eJztl21v2zYQx7/Kwa9WwNb0YD35zeCmaZbG6YI4bdfVRUCJJ4uxRGok5cwt+t13lO2uLdABeZU3QYJEFE93p+NPfx4/fB5hgy1Keyv4aAYjzqvcD/MswMDPecCjacazLAh5kaVJFhejMYxatIwzy8j+88hd3BrV6xKPY7wtNdK/wWGQhnmUxGEUeUGcJ3ngPAxGreKiEl+t0ihM8jTx/K8GnVYlGvOdnzSOvTyM4ih2Zh3qVhgjlDS3h4w+fB6RY5dLFIV+8uUjmWkslea3jSqZVXpIs2O2dm5PZqvVG4ParFatLjVbrV6g2VjVrVbX87PVyqKxt5VokAw6Rdeq1F7Hq9GXL+TYTUjWumij72YPc3bXDXOs6xpBwSnRXw/TDZPrnq3RuJxHKNcjl2lHd25l3xbo0gwCF8TiP9Y5uapFI7oOLhTWcgxvhak128JJzXpeM70bw7xukcNpM7mguQ3deM1aJuFM7VgzhisKMnmFkp5Aep5JDi81k6UwpYKz/lO76n0fA+lB6Ie+By+F5EKuDagKbI1w39phBgxFoziWmQ0oCR3TrGmwASpy1xugF7eo6ckhBGvEWjrAPDiXcOWWFL9z+1JUtoYTJSvUKEt0Li9ZWQuJcEP5mWao2xhcbQykYbLqQz+I0mnouUIea/yaaU2WW7xx9aLC/Yh2FPOiiKdZnmKKZRRWaeinLC2KPA3S0g+f0H40tE+YVo1b8AvVc6XV5Irpigk7hjM2UFk0sMA77CXuwT2j5CRcKxxgDTxY0lsL1oBLmQMturA7cMVZS+FyAyGhEcQlfSjgwpoZvKuZBWEGCoWsmn6PXwX0qiCVMPjbT5iNidj5ySUsz8+WV/Ob8/mCDMm5HOpAabxTemNq1TmYz1CZQ3a/9/Q9Uj5ojjgH0Z5meocHwYxZVUwTTBj95CxmJM9R5JdBXEZpScMnmB8N5nmrBfFxoUmEJRvDc8VrYZi194xYYoZx0re7vuWox3DNJnCHpoZlrQkyUlZ4TljuKb9i90f5dpwHmQdvugmUu7JB2NFaOlJncI29cXJLA1JfpcG94sRB7FJyskyFPX4EWjkEabHAkLZuKFUPmP5TbKHT2JFs2/1wFmR+7tG3NU0fRmZITQMPCJMiJa1mwTROOWKQsjBIgyqvnsh8NDJv2KaHC1LYga5XqiYJFSUxx42SR8KWtJROCDuBJc5gDka0HfHmHjmGJJA4dkh/CBfTF/dUHLBqMyHlFZ9QD8Yc6c5h7KiU2FOjsGfysDBE7Y/0jeEXIi/z/CQMk2cPQy/wEwzLrCTk/CwpqIX1WZWysohLnuY8eULv0dBbqJ40EBasHdhYvoclbbceBHmeejD/L4TbYlsnikq7LXyrrJM2q2i/tG6H/XZTn5Ev+mXNzohhbxbWQIE12wq1Z5BqTOiR4pXUKZyfnp7uW0o2yKFxu/NyZyy2tB9fskNTfLKjF5BoRWlcH2JhPjtaDfPDJk4PhOkv8bNZHB928DjJHkZrGmZxWPJpxfk0KjnLEx5Qb5oEcZUV6RSfaH00Wi/FBqnhvBe0zO+FrAmzheh/OE9dMn3nRjX7tBWSutc7xukMVnBsNKud4aWqXTs6hj9a0sAFbulI9paavqUlD1Jt97wtegr2F1pLdKgd6kGIcw+eE3szeIGToRd1X4HBv4cedWLV5HjthHNiNXMZrPc6y+wgtF/Feo0S9eEQZb89UbnopWrJA50I3dL+rBXIA98Lomnyv03qx38Be55J9Q=="
    }
  },
  {
    "type": "CompositeElement",
    "element_id": "0b717b0d3534eb9077843e35c46295d4",
    "text": "Bohan Li, Yutai Hou, and Wanxiang Che. 2022. Data augmentation approaches in natural language pro- cessing: A survey. Ai Open, 3:71\u201390.\n\nElvys Linhares Pontes, Ahmed Hamdi, Nicolas Impact of Sidere, and Antoine Doucet. 2019. ocr quality on named entity linking. In Digital Libraries at the Crossroads of Digital Information for International Conference ICADL 2019, on Asia-Pacific Digital Libraries, Kuala Lumpur, Malaysia, November 4\u20137, 2019, Proceedings 21, pages 102\u2013115. Springer.\n\nthe Future:",
    "metadata": {
      "data_source": {
        "record_locator": {
          "path": "C:\\Users\\mrcra\\Desktop\\RAG\\test_files\\post_ocr.pdf"
        },
        "date_created": "1729365233.159691",
        "date_modified": "1727326976.0",
        "date_processed": "1729365755.923535",
        "permissions_data": [
          {
            "mode": 33206
          }
        ]
      },
      "filename": "post_ocr.pdf",
      "filetype": "application/pdf",
      "languages": [
        "eng"
      ],
      "page_number": 11,
      "orig_elements": "eJztlFuP0zAQhf/KKM8hxEmTbPpWWi4rFlhxEUIEVVN70lokdrCd1Var/e+Mu7uIyxNPvNCXejqnZ46dz/l8k9BAI5mw1SpZQlJQq/KiUjtV7RayUVgKIZVsWkXFYlFTkkIyUkCFAVl/k8TF1tvZSXqoaSsd8dfJUDRFW9ZVUZaZqNq6FdHhJBqt0r3+oWrKom6bOst/CCZnJXn/i09TVVlblFVZRdlEbtTea2v89j7R55uEjWOWsizy+vYLyxxJ69R2sBKDdaeYE4ZDtF0vu+6DJ+e7bnTSYddtyH8Nduq6t6vnXRfIh22vB2LBZHltpcsm1Se3t2wcGwbHOC35pXvfC8fp1MNpGjQP56CP79sDmv2Me/Ixc0Jmn8SkE/+yNfO4oxhTiDgk0HWIJk/sAQ1c6BQ+zQE1vLBzCmgUfERzrdkO1gfKoMiLIoMNnwbgvI+P9jQXOIOzKA/kQRswGGaHAzzEAG4+gnjc2uyXsAI/uys6ZrDS8GYik0K5bEQ3F7ko2zyLO3jY3Gt0jkdc0fsYlBP/zlS9qJpe1bUQSiHjxZ96p5qWZHXWyEL+Z+qfMfV0uDp6Zsoc0DEYl9ZwuBRWh5EUvMBRMW2vtbQDejgfJ5QBbA/vtCJHd/CtTLDaEGzsLClE/ESbAWeGbzMOOhzBRtqiHxMR60GbrwxZBucGNnqvA2N4oXcOneYIGCAcCNbOes+8Kh8HPsjOTW/deMczr7gO5Myp5u7amp5zGUlwvl5tLk5Z0jh/5TU+ukTJbMg/Z6bwkqMiXMzjNLsUXnFx5H/w1u0VxXODxR35TXrveRkxIsXb8FCIFOIZexB5cacTosrg3eS4T+7vLos66/tFmUtFJV+StlXtos+xVDVWuzMh8P9l+WeXJXL5bOb3Ji1/fqTvdRgouf3yHf7BVeA="
    }
  },
  {
    "type": "CompositeElement",
    "element_id": "79b6834da82e9d1dddd9fce4ceed9581",
    "text": "21st\n\nLinlin Liu, Bosheng Ding, Lidong Bing, Shafiq Joty, Luo Si, and Chunyan Miao. 2021. MulDA: A multilingual data augmentation framework for low-resource cross-lingual NER. In Proceedings of the 59th Annual Meeting of the Association and the 11th for Computational Linguistics International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 5834\u20135846.\n\nWentao Ma, Yiming Cui, Chenglei Si, Ting Liu, Shijin Wang, and Guoping Hu. 2020. Charbert: character- aware pre-trained language model. arXiv preprint arXiv:2011.01513.\n\nAyush Maheshwari, Nikhil Singh, Amrith Krishna, and Ganesh Ramakrishnan. 2022. A benchmark and dataset for post-OCR text correction in Sanskrit. arXiv preprint arXiv:2211.07980.\n\nMark Mazumder, Colby Banbury, Xiaozhe Yao, Bojan Karla\u0161, William Gaviria Rojas, Sudnya Diamos, Greg Diamos, Lynn He, Alicia Parrish, Hannah Rose Kirk, et al. 2022. Dataperf: Benchmarks for data-centric ai development. arXiv preprint arXiv:2207.10062.\n\nAtul Negi, Chakravarthy Bhagvati, and B Krishna. 2001. An OCR system for Telugu. In Proceedings of 6th International Conference on Document Analysis and Recognition, pages 1110\u20131114. IEEE.\n\nPauline C Ng and Steven Henikoff. 2003. Sift: Predict- ing amino acid changes that affect protein function. Nucleic acids research, 31(13):3812\u20133814.",
    "metadata": {
      "data_source": {
        "record_locator": {
          "path": "C:\\Users\\mrcra\\Desktop\\RAG\\test_files\\post_ocr.pdf"
        },
        "date_created": "1729365233.159691",
        "date_modified": "1727326976.0",
        "date_processed": "1729365755.923535",
        "permissions_data": [
          {
            "mode": 33206
          }
        ]
      },
      "filename": "post_ocr.pdf",
      "filetype": "application/pdf",
      "languages": [
        "eng"
      ],
      "page_number": 11,
      "orig_elements": "eJztl99v2zYQx/+Vg59awNFE6octvzlO0K5N0iDJ1hZ1EZwoymIjkRpJpXOL/u87ynHRDO2AvAwIkKeI5JF35H3u/M2HrxPZyk5qf62qyQImvMg4z8oZT7O4mmGZzFmZxvG8yMu0rpNkMoVJJz1W6JHsv07Cx7UzgxVyP5bXwkr6Mx7IZrxI8ownScSyIi9YOGE06kylavXdapbwvJjlUfzdoLdGSOfunTPLsqjgSZZkwayXtlPOKaPd9V1EH75O6OAQS5LwOP/2kcysFMZW160R6I0dw+zRN+HY1WK9/sNJ69brzgqL6/WRdDfe9Ov1xfLFeu2l89e1aiUZ9Ia+jbBRX9WTb9/o4LCgsQveJvdW79b8th/XsO9bRc4p0N/ullvUmwE30oWYJ1JvJiHSnmau9dCVMoTJWHDi5d9+TA1zPuzcH3qlfCsnZPHvHAqZ14zzWohZkciMMZwXImMy43ldipo95fB/zeE4ZR9QYj8m/UTpVmk4UcMUDo1ryAkcKb2Z0lRlaHA4Di4brNVf8Mr4La0MBi7VFFBXsGoGvUUNpwpNBDzmLILToT1aLmAJ3dB6RcfTJVoIbw84bAJI4y2htvQsn429gdpYaM3nAyt3lICwxrmD/daz44sIftdwHpItK5p1YGrwjYSs8A0stQ5mp1J6WtsvLZ0zQu1chVDDHGNkHrytTNcPuzho50lwpJxXwpEfL63er7wySnuy1rWkJ6bI6LAz9IMNu+7Ss4uLECPfz/407dCRowWchOc7R+LPPZ9CyJqDbJ6k64HHLMnmaR79WG5naC15vZVXITU/KTsu+IyymiRJGieEN7JUiFJKTOtqTuc+ld3jKbu3oQgMnOIU3qsugLMaqKJWof5aqcbyugrTY2FeNuoTFelbDKUYUH4xmD6svhzGmosj2omWIvMLEPSFghg+APxMAUJv5YG3qLSsYH81CIloI0D7Tt0Gi94GzsfhgvBkUcwyljwM0CrniYilzGOs6jJlCc5ljGUxS5MkKyQ+Afp4AF1uB9cQn410DVFEOJ6pm0a1RKbeNFNYdlZRK31tlWs03lGJmqzhAju82c3rEU8e0W9BSd2z6ZCafTAND+6kH1txuPzBm9UFBN9Ar01PPjZtQv4StaOz/K9I5YHUWTGPH0ZqKuIqSQue8nge86oqeZUTuVWW1TW9yBOpj4jU08DUKX4ZukpaaqGmLbdwiLocLGmVd6RLvtAP/3s0QeB8IqnyGm2L6yFmOTl+q9pWYUfs3iqrEC7IxFHHHSqSNaSEsDM0fGHl5vvgZKs1vJRUA3Rb2nJOtBHtU3iJWiPxb5yE18reTIEIx3ZfA0eUOkplvYDDfS24sQBCTg8EXd8qAaigkreyNX3g9Zfcx7OIxXHOHyghCuSzeT0n8ElDFDPq1fSuccbKbF7OWPnE/ePhfukHUsZyM8oGarh4i9Y3hH6Dm1sKZteTD/ctOlAYkzhfagi91m2dl92I35Vsh83wM4GdU4e/L4fvC+EjI4ZAFx2K7dYpN7q8oHxstAo79rKXMRbvZC99peTq+Pj4gR2bGjPnOb3NvM6yPMsylJgj1llZCczlE7mPh9xzHOg/OwkrONuMxFx66nihp2p1Y+p6RDWJSGrUpGfPLQEp/AEEwYuklQ2gUFXQuTqw5RuktljXJBqoTRovSTbUgx4lRARngyA9LcYtDuj/S4lWUK9O2DOWPF9QnHwHJn2l/4Xkx38AsNv0ng=="
    }
  },
  {
    "type": "CompositeElement",
    "element_id": "96a76bddcf81ea220263caf4a33812b9",
    "text": "Thi Tuyet Hai Nguyen, Adam Jatowt, Nhu-Van Nguyen, Mickael Coustaty, and Antoine Doucet. 2020. Neu- ral machine translation with BERT for post-OCR In Proceedings of error detection and correction. the ACM/IEEE joint conference on digital libraries, pages 333\u2013336.\n\nRaul Puri, Ryan Spring, Mostofa Patwary, Mohammad Shoeybi, and Bryan Catanzaro. 2020. Training ques- tion answering models from synthetic data. arXiv preprint arXiv:2002.09599.\n\nColin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J Liu. 2020. Exploring the limits of transfer learning with a unified text-to-text trans- former. The Journal of Machine Learning Research, 21(1):5485\u20135551.\n\nJuan Antonio Ramirez-Orta, Eduardo Xamena, Ana Maguitman, Evangelos Milios, and Axel J Soto. 2022. Post-ocr document correction with large en- sembles of character sequence-to-sequence models. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 36, pages 11192\u201311199.\n\nCaitlin Richter, Matthew Wickes, Deniz Beser, and Mitch Marcus. 2018. Low-resource post process- ing of noisy ocr output for historical corpus digiti- sation. In Proceedings of the Eleventh International Conference on Language Resources and Evaluation (LREC 2018).",
    "metadata": {
      "data_source": {
        "record_locator": {
          "path": "C:\\Users\\mrcra\\Desktop\\RAG\\test_files\\post_ocr.pdf"
        },
        "date_created": "1729365233.159691",
        "date_modified": "1727326976.0",
        "date_processed": "1729365755.923535",
        "permissions_data": [
          {
            "mode": 33206
          }
        ]
      },
      "filename": "post_ocr.pdf",
      "filetype": "application/pdf",
      "languages": [
        "eng"
      ],
      "page_number": 11,
      "orig_elements": "eJztV9tu2zgQ/ZWBn1rAVnW/5M11jd1kkzRwstvu1oVBUSOLW4lUSSqJU/TfO5TtblsUC/QxQF4sShyNhsNzDo/ffZpgix1KuxHV5AQmGIZVkpdxXsUhRjxNkgKLKM+LMi2SKIsmU5h0aFnFLKP4TxM32Bg1aI7He9xwjXQZEwZZWERpEkaRFyRFWgQuwxjUqUrU4mtUFoVpkaWe/zWg14qjMd/lyZLEK8IoiRIX1qPuhDFCSbM5VPTu04QSu1qiKPTTz+8pTCNXutq0ijOr9Fhmz2zj0i5O1us/DWqzXneaa7Zev0Lzwap+vV7Nf1uvLRq7qUWLFNArGiuuvb6qJ58/U2I3IVnnvjb5bvYwZ3f9OMf6vhX0cSr0xWG6ZXI7sC0aV/ME5XbiKu3pyUYOXYmuzCAYH+n/ticskjBMyiyME7/KWBnlQRn7fl6kZVzXUTRxVVm8ty74phFwM+zQwu9MwOWWhnIK84p1cEaNuLNTuGyG2V9Mfp28EPwDwxYWajCW2d0UmKxgLq0SEuGVGjhaD0I/9D24xGEGmrXQMd64aauZNO24SrgTtoGXy9UN1EqD683s9WIFpxKu3K5iJeTWgKoBtaaACi3y8UX3Pdotvb/1wDYI88XFi9Plcgn/UhmWpmWN1BSOQC9UYissVdGKUjMt0EzBddHQ/kfrIfQDuqaea/lxNy6Z1lTlLd64RlHHfiRBEEYE8CBKOI/RL7GuE4wIu5jz0I+D9IkEj4cEKza0cDVoMYXVjpB+3WuCHiGdKlU1gytm75jeuQcN6zpWwXWjcFeKPfRfavfSgtoqH5hWR+zfaCYk5YGPA5oZHJBr7tAlB9f71kCtVQdmJwnCVnBwe+MB02/FLfQaXR12f3sS+n7o+UVSFL8G1LJkQZ3wNOOFnxY8LzHNgjjidRWwnCdPav2IgLpQrZCwYnWNLQmzIpW+btgDoj5o9krRdyzJ2x/UDQc0hHPEqYvSTsLd73aU8MZJ+AVtimRT+JvJjwL+adQwhTco4PyA7CuSXA1ndD8cUb2871s1Itipbis6YUeNHoWdJBdaZHqE/SjvDAY5YgLcGmZWzdx1Hz1zut+hJqpQqjNCnCSNplwXh8Pi/JhqhYaGvJlCGDwLnp8kcZ7sdTtJkuDX+FD4LEzqosrriLGsqFgcYJjnfpJlcZyn/hMfHg8fzgYCtXMeUiiiRSc0Psxea0uQXlYD05WCt1S8g/hcMsLVdhC2Y2RilrdUHbbKEBdaoczBxNwTKc7gWtm9ioceXDlbQouGSvHBwegb57GHeMv0FgHlDAx2JfXRQZg7wnHHHoOk/+RDHPaP44P6ez/xOqOXmc9PyV5962Dm2hKUuCCCnEqLbSu2bmoKt6qlsiBKj5YmCIIi3JPDDX/xtKiqsorTjCGykhqQV6zO8hTJ2FPWMHw6LR4ROxZM2PG8ILW37ogguSd43cEbcvDOA79CKR7gJYmr3uP/QljeUJjmg3EECHIPztXdTON+h0eTDod9mYGTZoKsVMLswHFEDbYf7GjnG0HeSdOiW0eYfjB7Ey6IJWzv2n+O/WWLt7TeZoQ5HQgulrU/sOH80Dx3MIyFmbF8InU77P9bPDtfLRfjCp7/HwHefwHIRcKI"
    }
  },
  {
    "type": "CompositeElement",
    "element_id": "421b8dabd0d7162d35976d575c18a4f0",
    "text": "Christophe Rigaud, Antoine Doucet, Micka\u00ebl Cous- taty, and Jean-Philippe Moreux. 2019. ICDAR- 2019 competition on post-OCR text correction. In Proceedings of the 2019 IAPR International Conference on Document Analysis and Recognition (ICDAR), pages 1588\u20131593. IEEE.\n\nEthan Rublee, Vincent Rabaud, Kurt Konolige, and Gary Bradski. 2011. Orb: An efficient alternative to sift or surf. In 2011 International conference on computer vision, pages 2564\u20132571. Ieee.\n\nRico Sennrich, Barry Haddow, and Alexandra Birch. Improving neural machine translation arXiv preprint\n\n2015. models with monolingual data. arXiv:1511.06709.\n\nConnor Shorten and Taghi M Khoshgoftaar. 2019. A survey on image data augmentation for deep learning. Journal of big data, 6(1):1\u201348.\n\nRay Smith. 2007. An overview of the Tesseract OCR engine. In Proceedings of the 9th International Conference on Document Analysis and Recognition (ICDAR), volume 2, pages 629\u2013633. IEEE.\n\nElizabeth Soper, Stanley Fujimoto, and Yen-Yun Yu. 2021. Bart for post-correction of OCR newspaper text. In Proceedings of the Seventh Workshop on Noisy User-generated Text (W-NUT 2021), pages 284\u2013290.\n\nLukas Stankevi\u02c7cius, Mantas Luko\u0161evi\u02c7cius, Jurgita Kapo\u02c7ci\u00afut\u02d9e-Dzikien\u02d9e, Monika Briedien\u02d9e, and Tomas Krilavi\u02c7cius. 2022. Correcting diacritics and typos with a byt5 transformer model. Applied Sciences, 12(5):2636.\n\nMichael Stubbs. 1996.",
    "metadata": {
      "data_source": {
        "record_locator": {
          "path": "C:\\Users\\mrcra\\Desktop\\RAG\\test_files\\post_ocr.pdf"
        },
        "date_created": "1729365233.159691",
        "date_modified": "1727326976.0",
        "date_processed": "1729365755.923535",
        "permissions_data": [
          {
            "mode": 33206
          }
        ]
      },
      "filename": "post_ocr.pdf",
      "filetype": "application/pdf",
      "languages": [
        "eng"
      ],
      "page_number": 11,
      "orig_elements": "eJztmF9v2zYQwL8K4acUsF2R+p+3NMm6NE1bOOm6oi4CkjranCVSoCinbpHvvqMct02xPmQbCgSwEdiSjjoej7873uXDlxHU0IDx17oaHZJRQWOQBY2qXLCKKZGDytNUlSyWLGJROhqTUQOeV9xzHP9lFC6uO9s7Cbt7uJYO8GdQSHNWxlnK4nhK0zIradAwDGpspZX+OiqPWVbm2TT6OqB1VkLX3dODxkzRmDQeLGnBNbrrtDXd9Z1FH76MUHGwJY5ZlN1+xGEOpHXVdW0l99YNZrbcL4Pa48P5/G0HrpvPGycdn89PoFt5287ns6Pn87mHzl8rXQMOaC1eW+mmbaVGt7eoOAgMb8Jso3vSO5nftIOMt22tcXI09OmduOZm0fMFdMHmEZjFKFja4pNr0zcCgpmUDo/ct+1hZcpYKnKWpLhFXMQFFUkUFWUmEqXieBSs8vDJD2tbOt3hUpZAZnrB+2pMjoy32gA5sb0EPyYXWq74vI8iEDU5tn03IZ77zZhwU5EXwM3kzVLXum2BXFgH/acpYREtp+Ts+ORoNhluiLRNC16H1RH8C46YvD6ekWAHCh26P8jwJUPehD2FSptFR6wiHm0bdJwdvZmh3IMzg5t4MMcowLVLCFpPrOwDp7gEXm863Q0mznBnF2Y79cFg05MxCU7sCE2LYt6j8hi5i3Hy09PTafD8blNecedwrjVcBX+h436MhbxQURwJnhcURJxERcoFjTktFIskz+k+Fh5PLJz6JTdk1osaYEz+0EgVsjTjYgiL8955cm6NrfUCtvA/525DnjledSs9QE+n5LUTh8gfAaW01EEBr++IXQPxlnRaeWId6XqnBtzDez9gLe9hHWKnRzFZ67B1O3hZmiVbeFma48xnAPAweJko8jyP4lxwdIaAKlMiTSFKMBwEL+Qe3l8JL/tP8M60tOQSjHFaLsfkGe79hvzOq8rebGE9quET/jpOnmknl8hLgz5fY5YlBnqH1DVcLkPi946brh4WQLj7U69J66B12vgH0ZUJLpUoopKXKlEJlCJhNKW8yNMSY0rt6Xo8dGGWSackeKPuyI32S7wOmTBMXJPgr+kWlUPcYTqNsjwq7+Wil1hlnHlo/gmUIkmzNKuKOKZMCshoHiEtTKVYaCZU7M/QRwQKFmQGD7fLpXUezJB4rvhiqckFOV/abrmwynPudiXiUTgG17AJx5xu0JCBJcL7ReBjm4IU6qsAWlIDdwaRm5IXuPfhnMTqUOjF8M6YZAf0ySHdnohJ8cAyDmiRq0gmSVIqqUr8xjsaS1qioNi3NI8IwRnfkMsGc1SALMqnoRqza3BrDTe7fuIqONhx6UloQtAMPPd+1nuUmO3+p65jbWscStiuhMtYueU1i/9V91FAUUalBJHnIuWhiSk4NuXAygRUnMR7bB8Ptqe1/swFIGyXFj01JpeemxpT42/9X7qx3m7LuPdgJu97Q973AW+GdT+Wen5IkkNT/a2XDvwGug3cdC1HlUOz/TPKL2GNhi/JO+tW3dK2gexXVncbEhw+WYDBeEFKSGCRHLybvHp7NRjwtZlmxa4dKaOHYUxlVqk0gQphziUvZcZiyGWeU56llYI9xo8H45f9incDuytY63kfMZlL3XdjcsHxRO8IDrD4mGb0B/mL3i00Hv7nvLW75+HfTlz1PtxXJUxOPusVNtV3t6jTGr3Cjsbhln7/fKg7bIPTnTtd8+8nGsKGTTGJbwMF+59Kc+kwVctt6kYH2rsqlxOx8em2I8IQazCIhiIYD5XgXQyHy9DkIzFjdNxB+uSQZXH2wCSe5qpKU06TGD+JFJi9I3QtFJlkRbZP4r+W/u9hvsBemkONOPdCIDm0LO9v7pX2NYxuP/4NeLlLaw=="
    }
  },
  {
    "type": "CompositeElement",
    "element_id": "c2e14670ac675067abf51a91b5240412",
    "text": "Text and corpus analysis: Computer-assisted studies of language and culture. Blackwell Oxford.\n\nYuqing Tang, Chau Tran, Xian Li, Peng-Jen Chen, Na- man Goyal, Vishrav Chaudhary, Jiatao Gu, and An- gela Fan. 2020. Multilingual translation with exten- sible multilingual pretraining and finetuning. arXiv preprint, (2008.00401).\n\nMonideepa Tarafdar, Cynthia M Beath, and Jeanne W Ross. 2019. Using ai to enhance business operations. MIT Sloan Management Review, 60(4).\n\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, \u0141ukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. Advances in neural information processing systems, 30.\n\nDavid Wemhoener, Ismet Zeki Yalniz, and R Manmatha. 2013. Creating an improved version using noisy ocr from multiple editions. In 2013 12th International Conference on Document Analysis and Recognition, pages 160\u2013164. IEEE.\n\nLinting Xue, Aditya Barua, Noah Constant, Rami Al- Rfou, Sharan Narang, Mihir Kale, Adam Roberts, and Colin Raffel. 2022. Byt5: Towards a token- free future with pre-trained byte-to-byte models. Transactions of the Association for Computational Linguistics, 10:291\u2013306.\n\nLinting Xue, Noah Constant, Adam Roberts, Mihir Kale, Rami Al-Rfou, Aditya Siddhant, Aditya Barua, and Colin Raffel. 2020. mt5: A massively multilingual pre-trained text-to-text transformer. arXiv preprint arXiv:2010.11934.",
    "metadata": {
      "data_source": {
        "record_locator": {
          "path": "C:\\Users\\mrcra\\Desktop\\RAG\\test_files\\post_ocr.pdf"
        },
        "date_created": "1729365233.159691",
        "date_modified": "1727326976.0",
        "date_processed": "1729365755.923535",
        "permissions_data": [
          {
            "mode": 33206
          }
        ]
      },
      "filename": "post_ocr.pdf",
      "filetype": "application/pdf",
      "languages": [
        "eng"
      ],
      "page_number": 12,
      "orig_elements": "eJztl91u2zgQhV9l4Ksu4Hgl0ZKl3Llpt0g2SQs3/du6CEbiKCIskVpScuoUffcdSk6RdIsFcrNAgNxYlkgNh+Q3R4efv02opoZ0d6nk5BAmiQxEJBZCiCxMgiCfY5LLaJGHRRpkSVJOpjBpqEOJHXL/bxP/59KZ3hZ0e0+XhSW+DAHDRZSJJI6EmIVxlmShjzB0aoxUpfrRayGiJFsks+BHh9aagpy7F2cRx7MsErGIfbeWbKOcU0a7y31Gn79NOLDPRYgoSL5/4W6WCmPlZW0K7Iwd0myxq3zYo8P1+p0j69brxhYW1+sX5Dadadfr1fLVet2R6y5LVRN3aA3/N4WdtbKcfP/OgX2DxsaPNrnXum/rdu3Qhm1bKx6cE/1931yjvurxipzPeUL6auIzbfnJpe6bnHyaYeQH6ehr54Nc8BVQS+DJtL3jv1jvnHKHcGSatu/IHiCvheOFB9f1UpEDU8LtQOOrfd31lmbwvMZic011Da+/lrw4M5/TbboXqqtpwmP/TEeRhDJOZVrEFAfzQEqcl/k8liiSPC7y4ImO/5WO4ZF9QPHexelT/7fSV3DBI03hqMIeLizqKXxUqOFUTeEND3twQpobiZ+f4wE03PTK7LCewnvlKovb4U1Zod1N4UTxIht41U8H1pb6AK6oRvgD9QyiIApmcMb8qVr5ydXQ8XiuHuYN16qrgDMjfsmpvCZo7nZtLXFvpX3GPnapNHW9v50B2o9q63u0VuluCs+iIEhnAfMZ/nYP63O0lkfbkq+kX+GdSsopzmWShEGBi7DEIuOFy5JUFEU+T5/wfjx4nxmtJFGLTLjFUqJlyne6qxTCGTznLapGTE8ItSb4ACvjnOc0zGbwzg2kKegMkK5QFwR5zw95S8Dwyg/T4e5nxxfwtjZcF2esx1cDTbCiraLrKSTBs/kDEYwwCxELIRdxEJWxLIIS0yRNxbxM4gCLJwQfD4JLV7FIwnt016hZUM8NNvC2whsihvFcbRS8Qdt4Mk9wY3Km7mZjLCkWsdPaq+KJYeCmsFSSATtn6W3oZgrrPgjnYb9BdwN/onI+mif5uK4Z7jemNq7fVGoQ3XAxg2XHsjqorGLXwJ/8nelBE0luklvPtgOl+UlvWWqVZj/QjKq8J8DXgtuxsWg4GRE8jOiyjJI8K0lGmMwpzcIcRZEiw1GkIcZPjvIREf0Ct0rCB2oqQ9pjd+x46+AvYpQ/Ya3VzUjiyqshM1ThwKCYwZHfv/HrDarhfdiyS93yKnnM+oEwbZTbAc8XSmua8fvfshEgqfZie6yHaDwLNgvHmh2vHlaAqT0yuiSeFus0B3xhin5Q4uXeI49Z8aZd6SHYFPy6OOApr3sfM0zmHP/ly5cPg7vIciH54yIEa3Ua50E2z0WSUFSWQmJMT3A/HrhP2T16Dj/2xJLL0O0QnqPtcVDuyiPmOvQOc4WNgmV9AKvSsNllSbden/0ve+kzVSnLwlwPYVjyV4bz69xYGkeGPS1HKEuqB1cc8WFs18WHcGGu0UpGlU3Hxvvg0hJB2fsD2+iP2eMeDDaYayffdXxjDvwV/BbWXCDewTsshnLxZ7+uIlg6Zwo16jkr+/6weFs3p95g85lRFZxfGBxGWTgWhAiSB5rneRyGccrFUCzmqRRZEUkhWPO5AePFk3N5rKXwE/z3kb4L+21ZjFWxr6C3SvLxcHzxbkn9shb4hNj4UljySZM3Z0v17l/nwB8V4JP1FeCv41nSGxeyP58Ix9tDhjqYhWEm5v/F9Zd/AHD+FQM="
    }
  },
  {
    "type": "CompositeElement",
    "element_id": "f6701479337c19a55b32c26df2efdc0d",
    "text": "Ismet Zeki Yalniz and Raghavan Manmatha. 2011. A fast alignment scheme for automatic OCR evalu- ation of books. In 2011 International Conference on Document Analysis and Recognition, pages 754\u2013 758. IEEE.\n\nA Training parameters\n\nDue to the numerous sub-experiments in this study, models were trained on both RTX 4090 24GB and A100 80GB GPUs, without selecting different train- ing parameters for different languages.\n\nThe mT5-base, ByT5-base, mBART-large, Char- BERT, and ResNet50 models were all sourced from Hugging Face. Parameters for mT5-base, ByT5- base, and mBART-large were identical: dropout rate of 0.2, learning rate of 5e-4, batch size of 4, and 6 epochs. For CharBERT-related mod- els, the dropout rate is 0.2, learning rate is 3e-5, batch size is 8, with 12 epochs. The ENSEMBLE and SCRATCH models have the same parameters: dropout rate of 0.1, learning rate of 1e-4, batch size of 32, and 30 epochs. All models use Adam optimizer and are trained in fp32 precision. The best models are selected based on dev loss.",
    "metadata": {
      "data_source": {
        "record_locator": {
          "path": "C:\\Users\\mrcra\\Desktop\\RAG\\test_files\\post_ocr.pdf"
        },
        "date_created": "1729365233.159691",
        "date_modified": "1727326976.0",
        "date_processed": "1729365755.923535",
        "permissions_data": [
          {
            "mode": 33206
          }
        ]
      },
      "filename": "post_ocr.pdf",
      "filetype": "application/pdf",
      "languages": [
        "eng"
      ],
      "page_number": 12,
      "orig_elements": "eJztVt9v2zYQ/lcOerY96reVN8dx0wJrV7gusK0qDIo82UQkUSCptGmQ/71HOXHtItiwlw0D8mSKd/ruvrvvTv50H2CDLXZuq2RwAUEsk5SxOC6KOgl5lqV1VHEh5TzNai6rKJhA0KLjkjtO/veBP2ytHozAp2fcCoP0MwKGeVTEWRrF8SxMi6wIPcLo1GqpanX0yuMoK/Jsxo4OvdECrT3DydN0VkRxGqferUfTKmuV7uz2MaNP9wEB+1ziOGLZw2dyMyi0kdtGC+60GdPsudt72OVFWX60aGxZtkYYXpZXaG+c7styvbguS4fWbWvVIDn0ms5amFkv6+DhgYC9oeOtjxacWR9t7q4fbbzvG0XBKdFfHs0N73YD36H1OQfY7QKfaU83225oK/RphtF4ZX60J5MsjuI8pgaFGWNVwrNKRnkVijkrsozSojccfnXe+Y2lTsGfeKPgD9506hvwTsKa7/b8lnfwlnctVYHPIGJhOIMF1Nw64I3adV4RYMWepAG1NsAHp8lZCfhtuQa85c0whZEP6BoqrW/sDN50IxL9OjTdaOUNLHVXI1EQCOR9pcUwgi/IdmeVPeREDdp1yr8xAV8DC3malAPBxXSaE/ZqtZr5uj2V9B03hkLc4sazJdo/K5kzIWuWcSmlkJwVOYZRmCdFLfNoHon0Rcn/qpJPhbmAjeGqU92Omm0oKunFnjZ3o1yDzzU1LXgSFbKm8pI2snmWFIgV1kIm1TxHfGnqf7qe/nbmTlVwNSA4DW6PQJBo9GDBDtUUv1LdlG+6BdWRnZaEdYO8m4AvXWPhC+0TcF5CKP1SqbTbw3rzOySsYBAl15fjVlmEjMGc0dP1+492Al+U2+uB9hppSjivPurwuJvcAW0K55IcV98Pn2NN/tkiisMsFIgi4vOs4kWRRVHC4kzUc1alJOgXzf5/NLshsbabdFpxixO4vDse28vFejNtuNnRw3LPzRQuV+vN5PHzZt+hS9mZfnnTwKHJEmqjW3g97HZef6+4wBm8P1fhT0HhcPbgJ5EPwEoSOSpNcwHS6N4rngSK/kPNZkS/QW7G3ft0m+I0mRCiE3uw6tt4lxzAM8Beiz193F9REp6XZzU12Hgxej5TIEaTcYrPotHQPhONbmOcpmfR6G5+GE7qzjGer/Tq3YfV28tfV2MqH5brxWb5+qmG9B8Gx6iWynQys8+RDp8hHT5DOo4OrGN2TGNBXXqMOFiEheQt6N6pll4xozM/2UW0ruo+jqCn8VB+hg48KlL8E4p3Pywg8vddHDeYxFtotP3LzfL5OwtLvM4="
    }
  }
]