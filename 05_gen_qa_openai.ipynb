{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json, os, time\n",
        "import copy\n",
        "\n",
        "\n",
        "import pprint\n",
        "\n",
        "# OPENAI\n",
        "from openai import OpenAI\n",
        "\n",
        "# LANGCHAIN\n",
        "from langchain_core.documents import Document\n",
        "from langchain.vectorstores import Pinecone\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_community.vectorstores.utils import filter_complex_metadata\n",
        "from langchain.schema import Document\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain.prompts.prompt import PromptTemplate\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_core.messages import AIMessage, HumanMessage\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_pinecone import PineconeVectorStore\n",
        "\n",
        "# PINECONE\n",
        "import pinecone\n",
        "from pinecone.grpc import PineconeGRPC as Pinecone\n",
        "from pinecone import ServerlessSpec\n",
        "\n",
        "\n",
        "# GENERAL\n",
        "from dotenv import find_dotenv, load_dotenv\n",
        "from rich.console import Console"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Success: .env file found with some environment variables\n",
            "69a6ef84-1e2b-49ad-b93d-c012c8be1ca2 | us-east-1 | test\n",
            "OPENAI_API_KEY is set and is valid: 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\n"
          ]
        }
      ],
      "source": [
        "console = Console()\n",
        "load_dotenv()\n",
        "if load_dotenv():\n",
        "    print(\"Success: .env file found with some environment variables\")\n",
        "else:\n",
        "    print(\n",
        "        \"Caution: No environment variables found. Please create .env file in the root directory or add environment variables in the .env file\"\n",
        "    )\n",
        "api_key = os.environ[\"OPENAI_API_KEY\"]\n",
        "PINECONE_API_KEY = os.environ[\"PINECONE_API_KEY\"]\n",
        "PINECONE_ENV = os.environ[\"PINECONE_ENV\"]\n",
        "PINCONE_INDEX = os.environ[\"PINECONE_INDEX\"]\n",
        "\n",
        "print(f\"{PINECONE_API_KEY} | {PINECONE_ENV} | {PINCONE_INDEX}\")\n",
        "client = OpenAI()\n",
        "\n",
        "\n",
        "if api_key:\n",
        "    try:\n",
        "        client.models.list()\n",
        "        print(\"OPENAI_API_KEY is set and is valid:\", api_key)\n",
        "    except openai.APIError as e:\n",
        "        print(f\"OpenAI API returned an API Error: {e}\")\n",
        "        pass\n",
        "    except openai.APIConnectionError as e:\n",
        "        print(f\"Failed to connect to OpenAI API: {e}\")\n",
        "        pass\n",
        "    except openai.RateLimitError as e:\n",
        "        print(f\"OpenAI API request exceeded rate limit: {e}\")\n",
        "        pass\n",
        "\n",
        "else:\n",
        "    print(\"Please set you OpenAI API key as an environment variable OPENAI_API_KEY\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "AWFjG54mbwoG"
      },
      "outputs": [],
      "source": [
        "cloud = os.environ.get(\"PINECONE_CLOUD\") or \"aws\"\n",
        "region = os.environ.get(\"PINECONE_REGION\") or \"us-east-1\"\n",
        "\n",
        "spec = ServerlessSpec(cloud=cloud, region=region)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "L4C_TQWcFeLY",
        "tags": [
          "parameters"
        ]
      },
      "outputs": [],
      "source": [
        "index_name = os.environ.get(\"PINECONE_INDEX\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPNwQTH0RNcl",
        "outputId": "954a84ba-cc9c-4796-fd12-28920024470c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'dimension': 1536,\n",
              " 'index_fullness': 0.0,\n",
              " 'namespaces': {'': {'vector_count': 872}},\n",
              " 'total_vector_count': 872}"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pc = Pinecone(api_key=PINECONE_API_KEY, environment=PINECONE_ENV)\n",
        "# connect to index\n",
        "index = pc.Index(index_name)\n",
        "# view index stats\n",
        "index.describe_index_stats()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfP0TQVeG1hO"
      },
      "source": [
        "## Retrieval"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2kNh44bEFeLe"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "client = OpenAI()\n",
        "\n",
        "\n",
        "def get_embedding(text, model=\"text-embedding-3-small\"):\n",
        "\n",
        "    # text = text.replace(\"\\n\", \" \")\n",
        "\n",
        "    try:\n",
        "        embedding = (\n",
        "            client.embeddings.create(input=[text], model=model).data[0].embedding\n",
        "        )\n",
        "\n",
        "    except Exception as e:\n",
        "\n",
        "        print(f\"Embedding failed: {text} | {e}\")\n",
        "\n",
        "        embedding = None\n",
        "\n",
        "    return embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "query_embed = get_embedding(\"What is the introduction about?\")\n",
        "res = index.query(\n",
        "    namespace=\"\", vector=query_embed, top_k=5, include_values=True, include_metadata=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 Introduction\n",
            "INTRODUCTION\n",
            "Introduction\n",
            "Introduction\n",
            "Introduction\n"
          ]
        }
      ],
      "source": [
        "for i in res[\"matches\"]:\n",
        "    print(i[\"metadata\"][\"content\"])\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
