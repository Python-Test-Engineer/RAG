{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.timescale.com/blog/combining-semantic-search-and-full-text-search-in-postgresql-with-cohere-pgvector-and-pgai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-- Create a table with a vector column\n",
    "CREATE TABLE vectors (\n",
    "    id SERIAL PRIMARY KEY,\n",
    "    vector vector(1536)\n",
    ");\n",
    "\n",
    "-- Insert some data\n",
    "INSERT INTO vectors (vector) VALUES\n",
    "    (vector(1.0, 2.0, ..., 1536.0)),\n",
    "    (vector(1.0, 2.0, ..., 1536.0)),\n",
    "    (vector(1.0, 2.0, ..., 1536.0));\n",
    "\n",
    "-- Query the table using the vector column\n",
    "SELECT * FROM vectors WHERE vector <-> vector(0.0, ..., 0.0) < 10;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.datacamp.com/tutorial/pgvector-tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create table documents (\n",
    "  id bigserial primary key,\n",
    "  content text,\n",
    "  embedding vector(1536)\n",
    ");\n",
    "\n",
    "create or replace function match_documents (\n",
    "  query_embedding vector(1536),\n",
    "  match_threshold float,\n",
    "  match_count int\n",
    ")\n",
    "returns table (\n",
    "  id bigint,\n",
    "  content text,\n",
    "  similarity float\n",
    ")\n",
    "language sql stable\n",
    "as $$\n",
    "  select\n",
    "    documents.id,\n",
    "    documents.content,\n",
    "    1 - (documents.embedding <=> query_embedding) as similarity\n",
    "  from documents\n",
    "  where documents.embedding <=> query_embedding < 1 - match_threshold\n",
    "  order by documents.embedding <=> query_embedding\n",
    "  limit match_count;\n",
    "$$;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from ast import literal_eval\n",
    "import pandas as pd\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "from openai import OpenAI\n",
    "import openai\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sk-proj-_YC6\n"
     ]
    }
   ],
   "source": [
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "# Set up your OpenAI API key\n",
    "# openai.api_key = OPENAI_API_KEY\n",
    "client = OpenAI()\n",
    "# Choose a model\n",
    "model = \"text-embedding-ada-002\"\n",
    "print(OPENAI_API_KEY[:12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to PostgreSQL...\n",
      "Successfully connected to PostgreSQL.\n"
     ]
    }
   ],
   "source": [
    "print(\"Connecting to PostgreSQL...\")\n",
    "conn = psycopg2.connect(\n",
    "    database=\"postgres\",\n",
    "    user=\"postgres\",\n",
    "    password=\"postgres\",\n",
    "    host=\"host.docker.internal\",\n",
    ")\n",
    "\n",
    "cursor = conn.cursor()\n",
    "\n",
    "print(\"Successfully connected to PostgreSQL.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the prompt to the pgvector embedding\n",
    "def get_embedding(prompt):\n",
    "    response = openai.embeddings.create(input=prompt, model=\"text-embedding-ada-002\")\n",
    "\n",
    "    embedding = response.data[0].embedding\n",
    "\n",
    "    # Converting the embedding to the pgvector and returning it\n",
    "    return \"[\" + \",\".join(map(str, embedding)) + \"]\"\n",
    "\n",
    "\n",
    "# Getting the matching threshold for the similarity search\n",
    "def get_matching_threshold():\n",
    "    return 0.7\n",
    "\n",
    "\n",
    "# Getting the number of matching movies to return\n",
    "def get_matching_count():\n",
    "    return 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, find the most relevant movies for a provided user prompt by calculating the cosine distance (`<=>`) between the prompt's and movies' embeddings:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Fraternity Row', \"Director Thomas J. Tobin's 1977 drama about college freshmen subjected to fraternity hazing stars Gregory Harrison, Peter Fox, Scott Newman, Nancy Morgan and Wendy Phillips.\")\n",
      "('Fraternity Row', \"Director Thomas J. Tobin's 1977 drama about college freshmen subjected to fraternity hazing stars Gregory Harrison, Peter Fox, Scott Newman, Nancy Morgan and Wendy Phillips.\")\n",
      "('Lee Rock', 'The film chronicles the rise and fall of a corrupt police force that Lee Rock becomes a part of.')\n"
     ]
    }
   ],
   "source": [
    "user_prompt = \"A movie about an fraternity.\"\n",
    "\n",
    "prompt_vector = get_embedding(user_prompt)\n",
    "\n",
    "cursor.execute(\n",
    "    \"SELECT title, overview \"\n",
    "    \"FROM movie WHERE 1 - (overview_vector <=> %(prompt_vector)s) >= %(match_threshold)s \"\n",
    "    \"ORDER BY overview_vector <=> %(prompt_vector)s LIMIT %(match_cnt)s\",\n",
    "    {\n",
    "        \"prompt_vector\": prompt_vector,\n",
    "        \"match_threshold\": get_matching_threshold(),\n",
    "        \"match_cnt\": get_matching_count(),\n",
    "    },\n",
    ")\n",
    "\n",
    "result = cursor.fetchall()\n",
    "\n",
    "for row in result:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Filter Data Before Similarity Search\n",
    "\n",
    "As a general-purpose relational database, PostgreSQL allows you to pre-filter data before a vector search is started. You can pre-filter by specifying a condition on non-vector columns in the `WHERE` clause of a query statement.\n",
    "\n",
    "For instance, imagine the user selecting the `Science Fiction` category and asking to suggest movies with a rating of `7` or higher. Then, the user prompts for `A movie about a space adventure`. The final SQL query can look as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = \"A movie about a space adventure.\"\n",
    "\n",
    "prompt_vector = get_embedding(user_prompt)\n",
    "\n",
    "cursor.execute(\n",
    "    \"SELECT title, vote_average, genres \"\n",
    "    \"FROM movie WHERE vote_average >= 7 \"\n",
    "    'AND genres @> \\'[{\"name\": \"Science Fiction\"}]\\' '\n",
    "    \"AND 1 - (overview_vector <=> %(prompt_vector)s) >= %(match_threshold)s \"\n",
    "    \"ORDER BY overview_vector <=> %(prompt_vector)s LIMIT %(match_cnt)s\",\n",
    "    {\n",
    "        \"prompt_vector\": prompt_vector,\n",
    "        \"match_threshold\": get_matching_threshold(),\n",
    "        \"match_cnt\": get_matching_count(),\n",
    "    },\n",
    ")\n",
    "\n",
    "result = cursor.fetchall()\n",
    "\n",
    "for row in result:\n",
    "    print(row)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
